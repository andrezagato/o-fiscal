["^ ","~:resource-id",["~:shadow.build.npm/resource","node_modules/@supabase/storage-js/dist/index.cjs"],"~:js","shadow$provide.module$node_modules$$supabase$storage_js$dist$index_cjs = function(require, module, exports) {\n  function isStorageError(error) {\n    return typeof error === \"object\" && error !== null && \"__isStorageError\" in error;\n  }\n  function _typeof(o) {\n    \"@babel/helpers - typeof\";\n    return _typeof = \"function\" == typeof Symbol && \"symbol\" == typeof Symbol.iterator ? function(o$1) {\n      return typeof o$1;\n    } : function(o$1) {\n      return o$1 && \"function\" == typeof Symbol && o$1.constructor === Symbol && o$1 !== Symbol.prototype ? \"symbol\" : typeof o$1;\n    }, _typeof(o);\n  }\n  function ownKeys(e, r) {\n    var t = Object.keys(e);\n    if (Object.getOwnPropertySymbols) {\n      var o = Object.getOwnPropertySymbols(e);\n      r && (o = o.filter(function(r$1) {\n        return Object.getOwnPropertyDescriptor(e, r$1).enumerable;\n      }));\n      t.push.apply(t, o);\n    }\n    return t;\n  }\n  function _objectSpread2(e$jscomp$0) {\n    for (var r = 1; r < arguments.length; r++) {\n      var t$jscomp$0 = null != arguments[r] ? arguments[r] : {};\n      r % 2 ? ownKeys(Object(t$jscomp$0), !0).forEach(function(r$1) {\n        var r, t = t$jscomp$0[r$1];\n        a: {\n          if (\"object\" == _typeof(r$1) && r$1) {\n            var e = r$1[Symbol.toPrimitive];\n            if (void 0 !== e) {\n              r$1 = e.call(r$1, \"string\");\n              if (\"object\" != _typeof(r$1)) {\n                break a;\n              }\n              throw new TypeError(\"@@toPrimitive must return a primitive value.\");\n            }\n            r$1 = String(r$1);\n          }\n        }\n        (r = \"symbol\" == _typeof(r$1) ? r$1 : r$1 + \"\") in e$jscomp$0 ? Object.defineProperty(e$jscomp$0, r, {value:t, enumerable:!0, configurable:!0, writable:!0}) : e$jscomp$0[r] = t;\n      }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(e$jscomp$0, Object.getOwnPropertyDescriptors(t$jscomp$0)) : ownKeys(Object(t$jscomp$0)).forEach(function(r$1) {\n        Object.defineProperty(e$jscomp$0, r$1, Object.getOwnPropertyDescriptor(t$jscomp$0, r$1));\n      });\n    }\n    return e$jscomp$0;\n  }\n  async function _handleRequest(fetcher, method, url, options, parameters, body, namespace) {\n    return new Promise((resolve, reject) => {\n      fetcher(url, _getRequestParams(method, options, parameters, body)).then(result => {\n        if (!result.ok) {\n          throw result;\n        }\n        if (options === null || options === void 0 ? 0 : options.noResolveJson) {\n          return result;\n        }\n        if (namespace === \"vectors\") {\n          const contentType = result.headers.get(\"content-type\");\n          if (result.headers.get(\"content-length\") === \"0\" || result.status === 204 || !contentType || !contentType.includes(\"application/json\")) {\n            return {};\n          }\n        }\n        return result.json();\n      }).then(data => resolve(data)).catch(error => handleError(error, reject, options, namespace));\n    });\n  }\n  function createFetchApi(namespace = \"storage\") {\n    return {get:async(fetcher, url, options, parameters) => _handleRequest(fetcher, \"GET\", url, options, parameters, void 0, namespace), post:async(fetcher, url, body, options, parameters) => _handleRequest(fetcher, \"POST\", url, options, parameters, body, namespace), put:async(fetcher, url, body, options, parameters) => _handleRequest(fetcher, \"PUT\", url, options, parameters, body, namespace), head:async(fetcher, url, options, parameters) => _handleRequest(fetcher, \"HEAD\", url, _objectSpread2(_objectSpread2({}, \n    options), {}, {noResolveJson:!0}), parameters, void 0, namespace), remove:async(fetcher, url, body, options, parameters) => _handleRequest(fetcher, \"DELETE\", url, options, parameters, body, namespace)};\n  }\n  var Buffer = require(\"module$node_modules$buffer$index\").Buffer;\n  let iceberg_js = require(\"module$node_modules$iceberg_js$dist$index_cjs\");\n  var StorageError = class extends Error {\n    constructor(message, namespace = \"storage\", status, statusCode) {\n      super(message);\n      this.__isStorageError = !0;\n      this.namespace = namespace;\n      this.name = namespace === \"vectors\" ? \"StorageVectorsError\" : \"StorageError\";\n      this.status = status;\n      this.statusCode = statusCode;\n    }\n  }, StorageApiError = class extends StorageError {\n    constructor(message, status, statusCode, namespace = \"storage\") {\n      super(message, namespace, status, statusCode);\n      this.name = namespace === \"vectors\" ? \"StorageVectorsApiError\" : \"StorageApiError\";\n      this.status = status;\n      this.statusCode = statusCode;\n    }\n    toJSON() {\n      return {name:this.name, message:this.message, status:this.status, statusCode:this.statusCode};\n    }\n  }, StorageUnknownError = class extends StorageError {\n    constructor(message, originalError, namespace = \"storage\") {\n      super(message, namespace);\n      this.name = namespace === \"vectors\" ? \"StorageVectorsUnknownError\" : \"StorageUnknownError\";\n      this.originalError = originalError;\n    }\n  };\n  require = class extends StorageError {\n    constructor(message) {\n      super(message, \"vectors\");\n    }\n  };\n  module = class extends StorageApiError {\n    constructor(message, status, statusCode) {\n      super(message, status, statusCode, \"vectors\");\n    }\n  };\n  var StorageVectorsUnknownError = class extends StorageUnknownError {\n    constructor(message, originalError) {\n      super(message, originalError, \"vectors\");\n    }\n  };\n  let StorageVectorsErrorCode = function(StorageVectorsErrorCode$1) {\n    StorageVectorsErrorCode$1.InternalError = \"InternalError\";\n    StorageVectorsErrorCode$1.S3VectorConflictException = \"S3VectorConflictException\";\n    StorageVectorsErrorCode$1.S3VectorNotFoundException = \"S3VectorNotFoundException\";\n    StorageVectorsErrorCode$1.S3VectorBucketNotEmpty = \"S3VectorBucketNotEmpty\";\n    StorageVectorsErrorCode$1.S3VectorMaxBucketsExceeded = \"S3VectorMaxBucketsExceeded\";\n    StorageVectorsErrorCode$1.S3VectorMaxIndexesExceeded = \"S3VectorMaxIndexesExceeded\";\n    return StorageVectorsErrorCode$1;\n  }({});\n  const resolveFetch = customFetch => customFetch ? (...args) => customFetch(...args) : (...args) => fetch(...args), recursiveToCamel = item => {\n    if (Array.isArray(item)) {\n      return item.map(el => recursiveToCamel(el));\n    }\n    if (typeof item === \"function\" || item !== Object(item)) {\n      return item;\n    }\n    const result = {};\n    Object.entries(item).forEach(([key, value]) => {\n      key = key.replace(/([-_][a-z])/gi, c => c.toUpperCase().replace(/[-_]/g, \"\"));\n      result[key] = recursiveToCamel(value);\n    });\n    return result;\n  }, isValidBucketName = bucketName => !bucketName || typeof bucketName !== \"string\" || bucketName.length === 0 || bucketName.length > 100 || bucketName.trim() !== bucketName || bucketName.includes(\"/\") || bucketName.includes(\"\\\\\") ? !1 : /^[\\w!.\\*'() &$@=;:+,?-]+$/.test(bucketName), _getErrorMessage = err => {\n    var _err$error;\n    return err.msg || err.message || err.error_description || (typeof err.error === \"string\" ? err.error : (_err$error = err.error) === null || _err$error === void 0 ? void 0 : _err$error.message) || JSON.stringify(err);\n  }, handleError = async(error, reject, options, namespace) => {\n    if (error && typeof error === \"object\" && \"status\" in error && \"ok\" in error && typeof error.status === \"number\" && (options === null || options === void 0 || !options.noResolveJson)) {\n      const status = error.status || 500;\n      typeof error.json === \"function\" ? error.json().then(err => {\n        const statusCode = (err === null || err === void 0 ? void 0 : err.statusCode) || (err === null || err === void 0 ? void 0 : err.code) || status + \"\";\n        reject(new StorageApiError(_getErrorMessage(err), status, statusCode, namespace));\n      }).catch(() => {\n        reject(new StorageApiError(error.statusText || `HTTP ${status} error`, status, status + \"\", namespace));\n      }) : reject(new StorageApiError(error.statusText || `HTTP ${status} error`, status, status + \"\", namespace));\n    } else {\n      reject(new StorageUnknownError(_getErrorMessage(error), error, namespace));\n    }\n  }, _getRequestParams = (method, options, parameters, body) => {\n    const params = {method, headers:(options === null || options === void 0 ? void 0 : options.headers) || {}};\n    if (method === \"GET\" || method === \"HEAD\" || !body) {\n      return _objectSpread2(_objectSpread2({}, params), parameters);\n    }\n    typeof body !== \"object\" || body === null ? method = !1 : (method = Object.getPrototypeOf(body), method = (method === null || method === Object.prototype || Object.getPrototypeOf(method) === null) && !(Symbol.toStringTag in body) && !(Symbol.iterator in body));\n    method ? (params.headers = _objectSpread2({\"Content-Type\":\"application/json\"}, options === null || options === void 0 ? void 0 : options.headers), params.body = JSON.stringify(body)) : params.body = body;\n    if (options === null || options === void 0 ? 0 : options.duplex) {\n      params.duplex = options.duplex;\n    }\n    return _objectSpread2(_objectSpread2({}, params), parameters);\n  };\n  var defaultApi = createFetchApi(\"storage\");\n  const {get, post, put, head, remove} = defaultApi, vectorsApi = createFetchApi(\"vectors\");\n  var BaseApiClient = class {\n    constructor(url, headers = {}, fetch$1, namespace = \"storage\") {\n      this.shouldThrowOnError = !1;\n      this.url = url;\n      this.headers = headers;\n      this.fetch = resolveFetch(fetch$1);\n      this.namespace = namespace;\n    }\n    throwOnError() {\n      this.shouldThrowOnError = !0;\n      return this;\n    }\n    setHeader(name, value) {\n      this.headers = _objectSpread2(_objectSpread2({}, this.headers), {}, {[name]:value});\n      return this;\n    }\n    async handleOperation(operation) {\n      try {\n        return {data:await operation(), error:null};\n      } catch (error) {\n        if (this.shouldThrowOnError) {\n          throw error;\n        }\n        if (isStorageError(error)) {\n          return {data:null, error};\n        }\n        throw error;\n      }\n    }\n  }, StreamDownloadBuilder = class {\n    constructor(downloadFn, shouldThrowOnError) {\n      this.downloadFn = downloadFn;\n      this.shouldThrowOnError = shouldThrowOnError;\n    }\n    then(onfulfilled, onrejected) {\n      return this.execute().then(onfulfilled, onrejected);\n    }\n    async execute() {\n      try {\n        return {data:(await this.downloadFn()).body, error:null};\n      } catch (error) {\n        if (this.shouldThrowOnError) {\n          throw error;\n        }\n        if (isStorageError(error)) {\n          return {data:null, error};\n        }\n        throw error;\n      }\n    }\n  };\n  let _Symbol$toStringTag;\n  _Symbol$toStringTag = Symbol.toStringTag;\n  var BlobDownloadBuilder = class {\n    constructor(downloadFn, shouldThrowOnError) {\n      this.downloadFn = downloadFn;\n      this.shouldThrowOnError = shouldThrowOnError;\n      this[_Symbol$toStringTag] = \"BlobDownloadBuilder\";\n      this.promise = null;\n    }\n    asStream() {\n      return new StreamDownloadBuilder(this.downloadFn, this.shouldThrowOnError);\n    }\n    then(onfulfilled, onrejected) {\n      return this.getPromise().then(onfulfilled, onrejected);\n    }\n    catch(onrejected) {\n      return this.getPromise().catch(onrejected);\n    }\n    finally(onfinally) {\n      return this.getPromise().finally(onfinally);\n    }\n    getPromise() {\n      this.promise || (this.promise = this.execute());\n      return this.promise;\n    }\n    async execute() {\n      try {\n        return {data:await (await this.downloadFn()).blob(), error:null};\n      } catch (error) {\n        if (this.shouldThrowOnError) {\n          throw error;\n        }\n        if (isStorageError(error)) {\n          return {data:null, error};\n        }\n        throw error;\n      }\n    }\n  };\n  const DEFAULT_SEARCH_OPTIONS = {limit:100, offset:0, sortBy:{column:\"name\", order:\"asc\"}}, DEFAULT_FILE_OPTIONS = {cacheControl:\"3600\", contentType:\"text/plain;charset\\x3dUTF-8\", upsert:!1};\n  var StorageFileApi = class extends BaseApiClient {\n    constructor(url, headers = {}, bucketId, fetch$1) {\n      super(url, headers, fetch$1, \"storage\");\n      this.bucketId = bucketId;\n    }\n    async uploadOrUpdate(method, path, fileBody, fileOptions) {\n      var _this = this;\n      return _this.handleOperation(async() => {\n        const options = _objectSpread2(_objectSpread2({}, DEFAULT_FILE_OPTIONS), fileOptions);\n        let headers = _objectSpread2(_objectSpread2({}, _this.headers), method === \"POST\" && {\"x-upsert\":String(options.upsert)});\n        var metadata = options.metadata;\n        if (typeof Blob !== \"undefined\" && fileBody instanceof Blob) {\n          var body = new FormData();\n          body.append(\"cacheControl\", options.cacheControl);\n          metadata && body.append(\"metadata\", _this.encodeMetadata(metadata));\n          body.append(\"\", fileBody);\n        } else {\n          typeof FormData !== \"undefined\" && fileBody instanceof FormData ? (body = fileBody, body.has(\"cacheControl\") || body.append(\"cacheControl\", options.cacheControl), metadata && !body.has(\"metadata\") && body.append(\"metadata\", _this.encodeMetadata(metadata))) : (body = fileBody, headers[\"cache-control\"] = `max-age=${options.cacheControl}`, headers[\"content-type\"] = options.contentType, metadata && (headers[\"x-metadata\"] = _this.toBase64(_this.encodeMetadata(metadata))), (typeof ReadableStream !== \n          \"undefined\" && body instanceof ReadableStream || body && typeof body === \"object\" && \"pipe\" in body && typeof body.pipe === \"function\") && !options.duplex && (options.duplex = \"half\"));\n        }\n        if (fileOptions === null || fileOptions === void 0 ? 0 : fileOptions.headers) {\n          headers = _objectSpread2(_objectSpread2({}, headers), fileOptions.headers);\n        }\n        metadata = _this._removeEmptyFolders(path);\n        const _path = _this._getFinalPath(metadata);\n        body = await (method == \"PUT\" ? put : post)(_this.fetch, `${_this.url}/object/${_path}`, body, _objectSpread2({headers}, (options === null || options === void 0 ? 0 : options.duplex) ? {duplex:options.duplex} : {}));\n        return {path:metadata, id:body.Id, fullPath:body.Key};\n      });\n    }\n    async upload(path, fileBody, fileOptions) {\n      return this.uploadOrUpdate(\"POST\", path, fileBody, fileOptions);\n    }\n    async uploadToSignedUrl(path, token, fileBody, fileOptions) {\n      var _this3 = this;\n      const cleanPath = _this3._removeEmptyFolders(path);\n      path = _this3._getFinalPath(cleanPath);\n      const url = new URL(_this3.url + `/object/upload/sign/${path}`);\n      url.searchParams.set(\"token\", token);\n      return _this3.handleOperation(async() => {\n        let body;\n        const options = _objectSpread2({upsert:DEFAULT_FILE_OPTIONS.upsert}, fileOptions), headers = _objectSpread2(_objectSpread2({}, _this3.headers), {\"x-upsert\":String(options.upsert)});\n        typeof Blob !== \"undefined\" && fileBody instanceof Blob ? (body = new FormData(), body.append(\"cacheControl\", options.cacheControl), body.append(\"\", fileBody)) : typeof FormData !== \"undefined\" && fileBody instanceof FormData ? (body = fileBody, body.append(\"cacheControl\", options.cacheControl)) : (body = fileBody, headers[\"cache-control\"] = `max-age=${options.cacheControl}`, headers[\"content-type\"] = options.contentType);\n        return {path:cleanPath, fullPath:(await put(_this3.fetch, url.toString(), body, {headers})).Key};\n      });\n    }\n    async createSignedUploadUrl(path, options) {\n      var _this4 = this;\n      return _this4.handleOperation(async() => {\n        var _path = _this4._getFinalPath(path), headers = _objectSpread2({}, _this4.headers);\n        if (options === null || options === void 0 ? 0 : options.upsert) {\n          headers[\"x-upsert\"] = \"true\";\n        }\n        _path = await post(_this4.fetch, `${_this4.url}/object/upload/sign/${_path}`, {}, {headers});\n        _path = new URL(_this4.url + _path.url);\n        headers = _path.searchParams.get(\"token\");\n        if (!headers) {\n          throw new StorageError(\"No token returned by API\");\n        }\n        return {signedUrl:_path.toString(), path, token:headers};\n      });\n    }\n    async update(path, fileBody, fileOptions) {\n      return this.uploadOrUpdate(\"PUT\", path, fileBody, fileOptions);\n    }\n    async move(fromPath, toPath, options) {\n      var _this6 = this;\n      return _this6.handleOperation(async() => await post(_this6.fetch, `${_this6.url}/object/move`, {bucketId:_this6.bucketId, sourceKey:fromPath, destinationKey:toPath, destinationBucket:options === null || options === void 0 ? void 0 : options.destinationBucket}, {headers:_this6.headers}));\n    }\n    async copy(fromPath, toPath, options) {\n      var _this7 = this;\n      return _this7.handleOperation(async() => ({path:(await post(_this7.fetch, `${_this7.url}/object/copy`, {bucketId:_this7.bucketId, sourceKey:fromPath, destinationKey:toPath, destinationBucket:options === null || options === void 0 ? void 0 : options.destinationBucket}, {headers:_this7.headers})).Key}));\n    }\n    async createSignedUrl(path, expiresIn, options) {\n      var _this8 = this;\n      return _this8.handleOperation(async() => {\n        var _path = _this8._getFinalPath(path);\n        _path = await post(_this8.fetch, `${_this8.url}/object/sign/${_path}`, _objectSpread2({expiresIn}, (options === null || options === void 0 ? 0 : options.transform) ? {transform:options.transform} : {}), {headers:_this8.headers});\n        return {signedUrl:encodeURI(`${_this8.url}${_path.signedURL}${(options === null || options === void 0 ? 0 : options.download) ? `&download=${options.download === !0 ? \"\" : options.download}` : \"\"}`)};\n      });\n    }\n    async createSignedUrls(paths, expiresIn, options) {\n      var _this9 = this;\n      return _this9.handleOperation(async() => {\n        const data = await post(_this9.fetch, `${_this9.url}/object/sign/${_this9.bucketId}`, {expiresIn, paths}, {headers:_this9.headers}), downloadQueryParam = (options === null || options === void 0 ? 0 : options.download) ? `&download=${options.download === !0 ? \"\" : options.download}` : \"\";\n        return data.map(datum => _objectSpread2(_objectSpread2({}, datum), {}, {signedUrl:datum.signedURL ? encodeURI(`${_this9.url}${datum.signedURL}${downloadQueryParam}`) : null}));\n      });\n    }\n    download(path, options, parameters) {\n      const renderPath = typeof(options === null || options === void 0 ? void 0 : options.transform) !== \"undefined\" ? \"render/image/authenticated\" : \"object\", queryString = (options = this.transformOptsToQueryString((options === null || options === void 0 ? void 0 : options.transform) || {})) ? `?${options}` : \"\", _path = this._getFinalPath(path);\n      return new BlobDownloadBuilder(() => get(this.fetch, `${this.url}/${renderPath}/${_path}${queryString}`, {headers:this.headers, noResolveJson:!0}, parameters), this.shouldThrowOnError);\n    }\n    async info(path) {\n      var _this10 = this;\n      const _path = _this10._getFinalPath(path);\n      return _this10.handleOperation(async() => recursiveToCamel(await get(_this10.fetch, `${_this10.url}/object/info/${_path}`, {headers:_this10.headers})));\n    }\n    async exists(path) {\n      path = this._getFinalPath(path);\n      try {\n        return await head(this.fetch, `${this.url}/object/${path}`, {headers:this.headers}), {data:!0, error:null};\n      } catch (error) {\n        if (this.shouldThrowOnError) {\n          throw error;\n        }\n        if (isStorageError(error) && error instanceof StorageUnknownError && (path = error.originalError, [400, 404].includes(path === null || path === void 0 ? void 0 : path.status))) {\n          return {data:!1, error};\n        }\n        throw error;\n      }\n    }\n    getPublicUrl(path, options) {\n      path = this._getFinalPath(path);\n      const _queryString = [];\n      var downloadQueryParam = (options === null || options === void 0 ? 0 : options.download) ? `download=${options.download === !0 ? \"\" : options.download}` : \"\";\n      downloadQueryParam !== \"\" && _queryString.push(downloadQueryParam);\n      downloadQueryParam = typeof(options === null || options === void 0 ? void 0 : options.transform) !== \"undefined\" ? \"render/image\" : \"object\";\n      options = this.transformOptsToQueryString((options === null || options === void 0 ? void 0 : options.transform) || {});\n      options !== \"\" && _queryString.push(options);\n      options = _queryString.join(\"\\x26\");\n      options !== \"\" && (options = `?${options}`);\n      return {data:{publicUrl:encodeURI(`${this.url}/${downloadQueryParam}/public/${path}${options}`)}};\n    }\n    async remove(paths) {\n      var _this12 = this;\n      return _this12.handleOperation(async() => await remove(_this12.fetch, `${_this12.url}/object/${_this12.bucketId}`, {prefixes:paths}, {headers:_this12.headers}));\n    }\n    async list(path, options, parameters) {\n      var _this13 = this;\n      return _this13.handleOperation(async() => {\n        const body = _objectSpread2(_objectSpread2(_objectSpread2({}, DEFAULT_SEARCH_OPTIONS), options), {}, {prefix:path || \"\"});\n        return await post(_this13.fetch, `${_this13.url}/object/list/${_this13.bucketId}`, body, {headers:_this13.headers}, parameters);\n      });\n    }\n    async listV2(options, parameters) {\n      var _this14 = this;\n      return _this14.handleOperation(async() => {\n        const body = _objectSpread2({}, options);\n        return await post(_this14.fetch, `${_this14.url}/object/list-v2/${_this14.bucketId}`, body, {headers:_this14.headers}, parameters);\n      });\n    }\n    encodeMetadata(metadata) {\n      return JSON.stringify(metadata);\n    }\n    toBase64(data) {\n      return typeof Buffer !== \"undefined\" ? Buffer.from(data).toString(\"base64\") : btoa(data);\n    }\n    _getFinalPath(path) {\n      return `${this.bucketId}/${path.replace(/^\\/+/, \"\")}`;\n    }\n    _removeEmptyFolders(path) {\n      return path.replace(/^\\/|\\/$/g, \"\").replace(/\\/+/g, \"/\");\n    }\n    transformOptsToQueryString(transform) {\n      const params = [];\n      transform.width && params.push(`width=${transform.width}`);\n      transform.height && params.push(`height=${transform.height}`);\n      transform.resize && params.push(`resize=${transform.resize}`);\n      transform.format && params.push(`format=${transform.format}`);\n      transform.quality && params.push(`quality=${transform.quality}`);\n      return params.join(\"\\x26\");\n    }\n  };\n  const DEFAULT_HEADERS = {\"X-Client-Info\":\"storage-js/2.97.0\"};\n  var StorageBucketApi = class extends BaseApiClient {\n    constructor(url, headers = {}, fetch$1, opts) {\n      url = new URL(url);\n      (opts === null || opts === void 0 ? 0 : opts.useNewHostname) && /supabase\\.(co|in|red)$/.test(url.hostname) && !url.hostname.includes(\"storage.supabase.\") && (url.hostname = url.hostname.replace(\"supabase.\", \"storage.supabase.\"));\n      opts = url.href.replace(/\\/$/, \"\");\n      headers = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), headers);\n      super(opts, headers, fetch$1, \"storage\");\n    }\n    async listBuckets(options) {\n      var _this = this;\n      return _this.handleOperation(async() => {\n        const queryString = _this.listBucketOptionsToQueryString(options);\n        return await get(_this.fetch, `${_this.url}/bucket${queryString}`, {headers:_this.headers});\n      });\n    }\n    async getBucket(id) {\n      var _this2 = this;\n      return _this2.handleOperation(async() => await get(_this2.fetch, `${_this2.url}/bucket/${id}`, {headers:_this2.headers}));\n    }\n    async createBucket(id, options = {public:!1}) {\n      var _this3 = this;\n      return _this3.handleOperation(async() => await post(_this3.fetch, `${_this3.url}/bucket`, {id, name:id, type:options.type, public:options.public, file_size_limit:options.fileSizeLimit, allowed_mime_types:options.allowedMimeTypes}, {headers:_this3.headers}));\n    }\n    async updateBucket(id, options) {\n      var _this4 = this;\n      return _this4.handleOperation(async() => await put(_this4.fetch, `${_this4.url}/bucket/${id}`, {id, name:id, public:options.public, file_size_limit:options.fileSizeLimit, allowed_mime_types:options.allowedMimeTypes}, {headers:_this4.headers}));\n    }\n    async emptyBucket(id) {\n      var _this5 = this;\n      return _this5.handleOperation(async() => await post(_this5.fetch, `${_this5.url}/bucket/${id}/empty`, {}, {headers:_this5.headers}));\n    }\n    async deleteBucket(id) {\n      var _this6 = this;\n      return _this6.handleOperation(async() => await remove(_this6.fetch, `${_this6.url}/bucket/${id}`, {}, {headers:_this6.headers}));\n    }\n    listBucketOptionsToQueryString(options) {\n      const params = {};\n      options && (\"limit\" in options && (params.limit = String(options.limit)), \"offset\" in options && (params.offset = String(options.offset)), options.search && (params.search = options.search), options.sortColumn && (params.sortColumn = options.sortColumn), options.sortOrder && (params.sortOrder = options.sortOrder));\n      return Object.keys(params).length > 0 ? \"?\" + (new URLSearchParams(params)).toString() : \"\";\n    }\n  }, StorageAnalyticsClient = class extends BaseApiClient {\n    constructor(url, headers = {}, fetch$1) {\n      url = url.replace(/\\/$/, \"\");\n      headers = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), headers);\n      super(url, headers, fetch$1, \"storage\");\n    }\n    async createBucket(name) {\n      var _this = this;\n      return _this.handleOperation(async() => await post(_this.fetch, `${_this.url}/bucket`, {name}, {headers:_this.headers}));\n    }\n    async listBuckets(options) {\n      var _this2 = this;\n      return _this2.handleOperation(async() => {\n        var queryParams = new URLSearchParams();\n        (options === null || options === void 0 ? void 0 : options.limit) !== void 0 && queryParams.set(\"limit\", options.limit.toString());\n        (options === null || options === void 0 ? void 0 : options.offset) !== void 0 && queryParams.set(\"offset\", options.offset.toString());\n        (options === null || options === void 0 ? 0 : options.sortColumn) && queryParams.set(\"sortColumn\", options.sortColumn);\n        (options === null || options === void 0 ? 0 : options.sortOrder) && queryParams.set(\"sortOrder\", options.sortOrder);\n        (options === null || options === void 0 ? 0 : options.search) && queryParams.set(\"search\", options.search);\n        queryParams = queryParams.toString();\n        return await get(_this2.fetch, queryParams ? `${_this2.url}/bucket?${queryParams}` : `${_this2.url}/bucket`, {headers:_this2.headers});\n      });\n    }\n    async deleteBucket(bucketName) {\n      var _this3 = this;\n      return _this3.handleOperation(async() => await remove(_this3.fetch, `${_this3.url}/bucket/${bucketName}`, {}, {headers:_this3.headers}));\n    }\n    from(bucketName) {\n      var _this4 = this;\n      if (!isValidBucketName(bucketName)) {\n        throw new StorageError(\"Invalid bucket name: File, folder, and bucket names must follow AWS object key naming guidelines and should avoid the use of any other characters.\");\n      }\n      bucketName = new iceberg_js.IcebergRestCatalog({baseUrl:this.url, catalogName:bucketName, auth:{type:\"custom\", getHeaders:async() => _this4.headers}, fetch:this.fetch});\n      const shouldThrowOnError = this.shouldThrowOnError;\n      return new Proxy(bucketName, {get(target, prop) {\n        const value = target[prop];\n        return typeof value !== \"function\" ? value : async(...args) => {\n          try {\n            return {data:await value.apply(target, args), error:null};\n          } catch (error) {\n            if (shouldThrowOnError) {\n              throw error;\n            }\n            return {data:null, error};\n          }\n        };\n      }});\n    }\n  };\n  defaultApi = class extends BaseApiClient {\n    constructor(url, headers = {}, fetch$1) {\n      url = url.replace(/\\/$/, \"\");\n      headers = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), {}, {\"Content-Type\":\"application/json\"}, headers);\n      super(url, headers, fetch$1, \"vectors\");\n    }\n    async createIndex(options) {\n      var _this = this;\n      return _this.handleOperation(async() => await vectorsApi.post(_this.fetch, `${_this.url}/CreateIndex`, options, {headers:_this.headers}) || {});\n    }\n    async getIndex(vectorBucketName, indexName) {\n      var _this2 = this;\n      return _this2.handleOperation(async() => await vectorsApi.post(_this2.fetch, `${_this2.url}/GetIndex`, {vectorBucketName, indexName}, {headers:_this2.headers}));\n    }\n    async listIndexes(options) {\n      var _this3 = this;\n      return _this3.handleOperation(async() => await vectorsApi.post(_this3.fetch, `${_this3.url}/ListIndexes`, options, {headers:_this3.headers}));\n    }\n    async deleteIndex(vectorBucketName, indexName) {\n      var _this4 = this;\n      return _this4.handleOperation(async() => await vectorsApi.post(_this4.fetch, `${_this4.url}/DeleteIndex`, {vectorBucketName, indexName}, {headers:_this4.headers}) || {});\n    }\n  };\n  var VectorDataApi = class extends BaseApiClient {\n    constructor(url, headers = {}, fetch$1) {\n      url = url.replace(/\\/$/, \"\");\n      headers = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), {}, {\"Content-Type\":\"application/json\"}, headers);\n      super(url, headers, fetch$1, \"vectors\");\n    }\n    async putVectors(options) {\n      var _this = this;\n      if (options.vectors.length < 1 || options.vectors.length > 500) {\n        throw Error(\"Vector batch size must be between 1 and 500 items\");\n      }\n      return _this.handleOperation(async() => await vectorsApi.post(_this.fetch, `${_this.url}/PutVectors`, options, {headers:_this.headers}) || {});\n    }\n    async getVectors(options) {\n      var _this2 = this;\n      return _this2.handleOperation(async() => await vectorsApi.post(_this2.fetch, `${_this2.url}/GetVectors`, options, {headers:_this2.headers}));\n    }\n    async listVectors(options) {\n      var _this3 = this;\n      if (options.segmentCount !== void 0) {\n        if (options.segmentCount < 1 || options.segmentCount > 16) {\n          throw Error(\"segmentCount must be between 1 and 16\");\n        }\n        if (options.segmentIndex !== void 0 && (options.segmentIndex < 0 || options.segmentIndex >= options.segmentCount)) {\n          throw Error(`segmentIndex must be between 0 and ${options.segmentCount - 1}`);\n        }\n      }\n      return _this3.handleOperation(async() => await vectorsApi.post(_this3.fetch, `${_this3.url}/ListVectors`, options, {headers:_this3.headers}));\n    }\n    async queryVectors(options) {\n      var _this4 = this;\n      return _this4.handleOperation(async() => await vectorsApi.post(_this4.fetch, `${_this4.url}/QueryVectors`, options, {headers:_this4.headers}));\n    }\n    async deleteVectors(options) {\n      var _this5 = this;\n      if (options.keys.length < 1 || options.keys.length > 500) {\n        throw Error(\"Keys batch size must be between 1 and 500 items\");\n      }\n      return _this5.handleOperation(async() => await vectorsApi.post(_this5.fetch, `${_this5.url}/DeleteVectors`, options, {headers:_this5.headers}) || {});\n    }\n  };\n  BaseApiClient = class extends BaseApiClient {\n    constructor(url, headers = {}, fetch$1) {\n      url = url.replace(/\\/$/, \"\");\n      headers = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), {}, {\"Content-Type\":\"application/json\"}, headers);\n      super(url, headers, fetch$1, \"vectors\");\n    }\n    async createBucket(vectorBucketName) {\n      var _this = this;\n      return _this.handleOperation(async() => await vectorsApi.post(_this.fetch, `${_this.url}/CreateVectorBucket`, {vectorBucketName}, {headers:_this.headers}) || {});\n    }\n    async getBucket(vectorBucketName) {\n      var _this2 = this;\n      return _this2.handleOperation(async() => await vectorsApi.post(_this2.fetch, `${_this2.url}/GetVectorBucket`, {vectorBucketName}, {headers:_this2.headers}));\n    }\n    async listBuckets(options = {}) {\n      var _this3 = this;\n      return _this3.handleOperation(async() => await vectorsApi.post(_this3.fetch, `${_this3.url}/ListVectorBuckets`, options, {headers:_this3.headers}));\n    }\n    async deleteBucket(vectorBucketName) {\n      var _this4 = this;\n      return _this4.handleOperation(async() => await vectorsApi.post(_this4.fetch, `${_this4.url}/DeleteVectorBucket`, {vectorBucketName}, {headers:_this4.headers}) || {});\n    }\n  };\n  var StorageVectorsClient = class extends BaseApiClient {\n    constructor(url, options = {}) {\n      super(url, options.headers || {}, options.fetch);\n    }\n    from(vectorBucketName) {\n      return new VectorBucketScope(this.url, this.headers, vectorBucketName, this.fetch);\n    }\n    async createBucket(vectorBucketName) {\n      return (() => super.createBucket)().call(this, vectorBucketName);\n    }\n    async getBucket(vectorBucketName) {\n      return (() => super.getBucket)().call(this, vectorBucketName);\n    }\n    async listBuckets(options = {}) {\n      return (() => super.listBuckets)().call(this, options);\n    }\n    async deleteBucket(vectorBucketName) {\n      return (() => super.deleteBucket)().call(this, vectorBucketName);\n    }\n  }, VectorBucketScope = class extends defaultApi {\n    constructor(url, headers, vectorBucketName, fetch$1) {\n      super(url, headers, fetch$1);\n      this.vectorBucketName = vectorBucketName;\n    }\n    async createIndex(options) {\n      return (() => super.createIndex)().call(this, _objectSpread2(_objectSpread2({}, options), {}, {vectorBucketName:this.vectorBucketName}));\n    }\n    async listIndexes(options = {}) {\n      return (() => super.listIndexes)().call(this, _objectSpread2(_objectSpread2({}, options), {}, {vectorBucketName:this.vectorBucketName}));\n    }\n    async getIndex(indexName) {\n      return (() => super.getIndex)().call(this, this.vectorBucketName, indexName);\n    }\n    async deleteIndex(indexName) {\n      return (() => super.deleteIndex)().call(this, this.vectorBucketName, indexName);\n    }\n    index(indexName) {\n      return new VectorIndexScope(this.url, this.headers, this.vectorBucketName, indexName, this.fetch);\n    }\n  }, VectorIndexScope = class extends VectorDataApi {\n    constructor(url, headers, vectorBucketName, indexName, fetch$1) {\n      super(url, headers, fetch$1);\n      this.vectorBucketName = vectorBucketName;\n      this.indexName = indexName;\n    }\n    async putVectors(options) {\n      return (() => super.putVectors)().call(this, _objectSpread2(_objectSpread2({}, options), {}, {vectorBucketName:this.vectorBucketName, indexName:this.indexName}));\n    }\n    async getVectors(options) {\n      return (() => super.getVectors)().call(this, _objectSpread2(_objectSpread2({}, options), {}, {vectorBucketName:this.vectorBucketName, indexName:this.indexName}));\n    }\n    async listVectors(options = {}) {\n      return (() => super.listVectors)().call(this, _objectSpread2(_objectSpread2({}, options), {}, {vectorBucketName:this.vectorBucketName, indexName:this.indexName}));\n    }\n    async queryVectors(options) {\n      return (() => super.queryVectors)().call(this, _objectSpread2(_objectSpread2({}, options), {}, {vectorBucketName:this.vectorBucketName, indexName:this.indexName}));\n    }\n    async deleteVectors(options) {\n      return (() => super.deleteVectors)().call(this, _objectSpread2(_objectSpread2({}, options), {}, {vectorBucketName:this.vectorBucketName, indexName:this.indexName}));\n    }\n  };\n  StorageBucketApi = class extends StorageBucketApi {\n    constructor(url, headers = {}, fetch$1, opts) {\n      super(url, headers, fetch$1, opts);\n    }\n    from(id) {\n      return new StorageFileApi(this.url, this.headers, id, this.fetch);\n    }\n    get vectors() {\n      return new StorageVectorsClient(this.url + \"/vector\", {headers:this.headers, fetch:this.fetch});\n    }\n    get analytics() {\n      return new StorageAnalyticsClient(this.url + \"/iceberg\", this.headers, this.fetch);\n    }\n  };\n  exports.StorageAnalyticsClient = StorageAnalyticsClient;\n  exports.StorageApiError = StorageApiError;\n  exports.StorageClient = StorageBucketApi;\n  exports.StorageError = StorageError;\n  exports.StorageUnknownError = StorageUnknownError;\n  exports.StorageVectorsApiError = module;\n  exports.StorageVectorsClient = StorageVectorsClient;\n  exports.StorageVectorsError = require;\n  exports.StorageVectorsErrorCode = StorageVectorsErrorCode;\n  exports.StorageVectorsUnknownError = StorageVectorsUnknownError;\n  exports.VectorBucketApi = BaseApiClient;\n  exports.VectorBucketScope = VectorBucketScope;\n  exports.VectorDataApi = VectorDataApi;\n  exports.VectorIndexApi = defaultApi;\n  exports.VectorIndexScope = VectorIndexScope;\n  exports.isStorageError = isStorageError;\n  exports.isStorageVectorsError = function(error) {\n    return isStorageError(error) && error.namespace === \"vectors\";\n  };\n};\n","~:source","shadow$provide[\"module$node_modules$$supabase$storage_js$dist$index_cjs\"] = function(require,module,exports) {\nvar Buffer = require('buffer').Buffer;\nlet iceberg_js = require(\"iceberg-js\");\n\n//#region src/lib/common/errors.ts\n/**\n* Base error class for all Storage errors\n* Supports both 'storage' and 'vectors' namespaces\n*/\nvar StorageError = class extends Error {\n\tconstructor(message, namespace = \"storage\", status, statusCode) {\n\t\tsuper(message);\n\t\tthis.__isStorageError = true;\n\t\tthis.namespace = namespace;\n\t\tthis.name = namespace === \"vectors\" ? \"StorageVectorsError\" : \"StorageError\";\n\t\tthis.status = status;\n\t\tthis.statusCode = statusCode;\n\t}\n};\n/**\n* Type guard to check if an error is a StorageError\n* @param error - The error to check\n* @returns True if the error is a StorageError\n*/\nfunction isStorageError(error) {\n\treturn typeof error === \"object\" && error !== null && \"__isStorageError\" in error;\n}\n/**\n* API error returned from Storage service\n* Includes HTTP status code and service-specific error code\n*/\nvar StorageApiError = class extends StorageError {\n\tconstructor(message, status, statusCode, namespace = \"storage\") {\n\t\tsuper(message, namespace, status, statusCode);\n\t\tthis.name = namespace === \"vectors\" ? \"StorageVectorsApiError\" : \"StorageApiError\";\n\t\tthis.status = status;\n\t\tthis.statusCode = statusCode;\n\t}\n\ttoJSON() {\n\t\treturn {\n\t\t\tname: this.name,\n\t\t\tmessage: this.message,\n\t\t\tstatus: this.status,\n\t\t\tstatusCode: this.statusCode\n\t\t};\n\t}\n};\n/**\n* Unknown error that doesn't match expected error patterns\n* Wraps the original error for debugging\n*/\nvar StorageUnknownError = class extends StorageError {\n\tconstructor(message, originalError, namespace = \"storage\") {\n\t\tsuper(message, namespace);\n\t\tthis.name = namespace === \"vectors\" ? \"StorageVectorsUnknownError\" : \"StorageUnknownError\";\n\t\tthis.originalError = originalError;\n\t}\n};\n/**\n* @deprecated Use StorageError with namespace='vectors' instead\n* Alias for backward compatibility with existing vector storage code\n*/\nvar StorageVectorsError = class extends StorageError {\n\tconstructor(message) {\n\t\tsuper(message, \"vectors\");\n\t}\n};\n/**\n* Type guard to check if an error is a StorageVectorsError\n* @param error - The error to check\n* @returns True if the error is a StorageVectorsError\n*/\nfunction isStorageVectorsError(error) {\n\treturn isStorageError(error) && error[\"namespace\"] === \"vectors\";\n}\n/**\n* @deprecated Use StorageApiError with namespace='vectors' instead\n* Alias for backward compatibility with existing vector storage code\n*/\nvar StorageVectorsApiError = class extends StorageApiError {\n\tconstructor(message, status, statusCode) {\n\t\tsuper(message, status, statusCode, \"vectors\");\n\t}\n};\n/**\n* @deprecated Use StorageUnknownError with namespace='vectors' instead\n* Alias for backward compatibility with existing vector storage code\n*/\nvar StorageVectorsUnknownError = class extends StorageUnknownError {\n\tconstructor(message, originalError) {\n\t\tsuper(message, originalError, \"vectors\");\n\t}\n};\n/**\n* Error codes specific to S3 Vectors API\n* Maps AWS service errors to application-friendly error codes\n*/\nlet StorageVectorsErrorCode = /* @__PURE__ */ function(StorageVectorsErrorCode$1) {\n\t/** Internal server fault (HTTP 500) */\n\tStorageVectorsErrorCode$1[\"InternalError\"] = \"InternalError\";\n\t/** Resource already exists / conflict (HTTP 409) */\n\tStorageVectorsErrorCode$1[\"S3VectorConflictException\"] = \"S3VectorConflictException\";\n\t/** Resource not found (HTTP 404) */\n\tStorageVectorsErrorCode$1[\"S3VectorNotFoundException\"] = \"S3VectorNotFoundException\";\n\t/** Delete bucket while not empty (HTTP 400) */\n\tStorageVectorsErrorCode$1[\"S3VectorBucketNotEmpty\"] = \"S3VectorBucketNotEmpty\";\n\t/** Exceeds bucket quota/limit (HTTP 400) */\n\tStorageVectorsErrorCode$1[\"S3VectorMaxBucketsExceeded\"] = \"S3VectorMaxBucketsExceeded\";\n\t/** Exceeds index quota/limit (HTTP 400) */\n\tStorageVectorsErrorCode$1[\"S3VectorMaxIndexesExceeded\"] = \"S3VectorMaxIndexesExceeded\";\n\treturn StorageVectorsErrorCode$1;\n}({});\n\n//#endregion\n//#region src/lib/common/helpers.ts\n/**\n* Resolves the fetch implementation to use\n* Uses custom fetch if provided, otherwise uses native fetch\n*\n* @param customFetch - Optional custom fetch implementation\n* @returns Resolved fetch function\n*/\nconst resolveFetch = (customFetch) => {\n\tif (customFetch) return (...args) => customFetch(...args);\n\treturn (...args) => fetch(...args);\n};\n/**\n* Determine if input is a plain object\n* An object is plain if it's created by either {}, new Object(), or Object.create(null)\n*\n* @param value - Value to check\n* @returns True if value is a plain object\n* @source https://github.com/sindresorhus/is-plain-obj\n*/\nconst isPlainObject = (value) => {\n\tif (typeof value !== \"object\" || value === null) return false;\n\tconst prototype = Object.getPrototypeOf(value);\n\treturn (prototype === null || prototype === Object.prototype || Object.getPrototypeOf(prototype) === null) && !(Symbol.toStringTag in value) && !(Symbol.iterator in value);\n};\n/**\n* Recursively converts object keys from snake_case to camelCase\n* Used for normalizing API responses\n*\n* @param item - Object to convert\n* @returns Converted object with camelCase keys\n*/\nconst recursiveToCamel = (item) => {\n\tif (Array.isArray(item)) return item.map((el) => recursiveToCamel(el));\n\telse if (typeof item === \"function\" || item !== Object(item)) return item;\n\tconst result = {};\n\tObject.entries(item).forEach(([key, value]) => {\n\t\tconst newKey = key.replace(/([-_][a-z])/gi, (c) => c.toUpperCase().replace(/[-_]/g, \"\"));\n\t\tresult[newKey] = recursiveToCamel(value);\n\t});\n\treturn result;\n};\n/**\n* Validates if a given bucket name is valid according to Supabase Storage API rules\n* Mirrors backend validation from: storage/src/storage/limits.ts:isValidBucketName()\n*\n* Rules:\n* - Length: 1-100 characters\n* - Allowed characters: alphanumeric (a-z, A-Z, 0-9), underscore (_), and safe special characters\n* - Safe special characters: ! - . * ' ( ) space & $ @ = ; : + , ?\n* - Forbidden: path separators (/, \\), path traversal (..), leading/trailing whitespace\n*\n* AWS S3 Reference: https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-keys.html\n*\n* @param bucketName - The bucket name to validate\n* @returns true if valid, false otherwise\n*/\nconst isValidBucketName = (bucketName) => {\n\tif (!bucketName || typeof bucketName !== \"string\") return false;\n\tif (bucketName.length === 0 || bucketName.length > 100) return false;\n\tif (bucketName.trim() !== bucketName) return false;\n\tif (bucketName.includes(\"/\") || bucketName.includes(\"\\\\\")) return false;\n\treturn /^[\\w!.\\*'() &$@=;:+,?-]+$/.test(bucketName);\n};\n\n//#endregion\n//#region \\0@oxc-project+runtime@0.101.0/helpers/typeof.js\nfunction _typeof(o) {\n\t\"@babel/helpers - typeof\";\n\treturn _typeof = \"function\" == typeof Symbol && \"symbol\" == typeof Symbol.iterator ? function(o$1) {\n\t\treturn typeof o$1;\n\t} : function(o$1) {\n\t\treturn o$1 && \"function\" == typeof Symbol && o$1.constructor === Symbol && o$1 !== Symbol.prototype ? \"symbol\" : typeof o$1;\n\t}, _typeof(o);\n}\n\n//#endregion\n//#region \\0@oxc-project+runtime@0.101.0/helpers/toPrimitive.js\nfunction toPrimitive(t, r) {\n\tif (\"object\" != _typeof(t) || !t) return t;\n\tvar e = t[Symbol.toPrimitive];\n\tif (void 0 !== e) {\n\t\tvar i = e.call(t, r || \"default\");\n\t\tif (\"object\" != _typeof(i)) return i;\n\t\tthrow new TypeError(\"@@toPrimitive must return a primitive value.\");\n\t}\n\treturn (\"string\" === r ? String : Number)(t);\n}\n\n//#endregion\n//#region \\0@oxc-project+runtime@0.101.0/helpers/toPropertyKey.js\nfunction toPropertyKey(t) {\n\tvar i = toPrimitive(t, \"string\");\n\treturn \"symbol\" == _typeof(i) ? i : i + \"\";\n}\n\n//#endregion\n//#region \\0@oxc-project+runtime@0.101.0/helpers/defineProperty.js\nfunction _defineProperty(e, r, t) {\n\treturn (r = toPropertyKey(r)) in e ? Object.defineProperty(e, r, {\n\t\tvalue: t,\n\t\tenumerable: !0,\n\t\tconfigurable: !0,\n\t\twritable: !0\n\t}) : e[r] = t, e;\n}\n\n//#endregion\n//#region \\0@oxc-project+runtime@0.101.0/helpers/objectSpread2.js\nfunction ownKeys(e, r) {\n\tvar t = Object.keys(e);\n\tif (Object.getOwnPropertySymbols) {\n\t\tvar o = Object.getOwnPropertySymbols(e);\n\t\tr && (o = o.filter(function(r$1) {\n\t\t\treturn Object.getOwnPropertyDescriptor(e, r$1).enumerable;\n\t\t})), t.push.apply(t, o);\n\t}\n\treturn t;\n}\nfunction _objectSpread2(e) {\n\tfor (var r = 1; r < arguments.length; r++) {\n\t\tvar t = null != arguments[r] ? arguments[r] : {};\n\t\tr % 2 ? ownKeys(Object(t), !0).forEach(function(r$1) {\n\t\t\t_defineProperty(e, r$1, t[r$1]);\n\t\t}) : Object.getOwnPropertyDescriptors ? Object.defineProperties(e, Object.getOwnPropertyDescriptors(t)) : ownKeys(Object(t)).forEach(function(r$1) {\n\t\t\tObject.defineProperty(e, r$1, Object.getOwnPropertyDescriptor(t, r$1));\n\t\t});\n\t}\n\treturn e;\n}\n\n//#endregion\n//#region src/lib/common/fetch.ts\n/**\n* Extracts error message from various error response formats\n* @param err - Error object from API\n* @returns Human-readable error message\n*/\nconst _getErrorMessage = (err) => {\n\tvar _err$error;\n\treturn err.msg || err.message || err.error_description || (typeof err.error === \"string\" ? err.error : (_err$error = err.error) === null || _err$error === void 0 ? void 0 : _err$error.message) || JSON.stringify(err);\n};\n/**\n* Handles fetch errors and converts them to Storage error types\n* @param error - The error caught from fetch\n* @param reject - Promise rejection function\n* @param options - Fetch options that may affect error handling\n* @param namespace - Error namespace ('storage' or 'vectors')\n*/\nconst handleError = async (error, reject, options, namespace) => {\n\tif (error && typeof error === \"object\" && \"status\" in error && \"ok\" in error && typeof error.status === \"number\" && !(options === null || options === void 0 ? void 0 : options.noResolveJson)) {\n\t\tconst responseError = error;\n\t\tconst status = responseError.status || 500;\n\t\tif (typeof responseError.json === \"function\") responseError.json().then((err) => {\n\t\t\tconst statusCode = (err === null || err === void 0 ? void 0 : err.statusCode) || (err === null || err === void 0 ? void 0 : err.code) || status + \"\";\n\t\t\treject(new StorageApiError(_getErrorMessage(err), status, statusCode, namespace));\n\t\t}).catch(() => {\n\t\t\tif (namespace === \"vectors\") {\n\t\t\t\tconst statusCode = status + \"\";\n\t\t\t\treject(new StorageApiError(responseError.statusText || `HTTP ${status} error`, status, statusCode, namespace));\n\t\t\t} else {\n\t\t\t\tconst statusCode = status + \"\";\n\t\t\t\treject(new StorageApiError(responseError.statusText || `HTTP ${status} error`, status, statusCode, namespace));\n\t\t\t}\n\t\t});\n\t\telse {\n\t\t\tconst statusCode = status + \"\";\n\t\t\treject(new StorageApiError(responseError.statusText || `HTTP ${status} error`, status, statusCode, namespace));\n\t\t}\n\t} else reject(new StorageUnknownError(_getErrorMessage(error), error, namespace));\n};\n/**\n* Builds request parameters for fetch calls\n* @param method - HTTP method\n* @param options - Custom fetch options\n* @param parameters - Additional fetch parameters like AbortSignal\n* @param body - Request body (will be JSON stringified if plain object)\n* @returns Complete fetch request parameters\n*/\nconst _getRequestParams = (method, options, parameters, body) => {\n\tconst params = {\n\t\tmethod,\n\t\theaders: (options === null || options === void 0 ? void 0 : options.headers) || {}\n\t};\n\tif (method === \"GET\" || method === \"HEAD\" || !body) return _objectSpread2(_objectSpread2({}, params), parameters);\n\tif (isPlainObject(body)) {\n\t\tparams.headers = _objectSpread2({ \"Content-Type\": \"application/json\" }, options === null || options === void 0 ? void 0 : options.headers);\n\t\tparams.body = JSON.stringify(body);\n\t} else params.body = body;\n\tif (options === null || options === void 0 ? void 0 : options.duplex) params.duplex = options.duplex;\n\treturn _objectSpread2(_objectSpread2({}, params), parameters);\n};\n/**\n* Internal request handler that wraps fetch with error handling\n* @param fetcher - Fetch function to use\n* @param method - HTTP method\n* @param url - Request URL\n* @param options - Custom fetch options\n* @param parameters - Additional fetch parameters\n* @param body - Request body\n* @param namespace - Error namespace ('storage' or 'vectors')\n* @returns Promise with parsed response or error\n*/\nasync function _handleRequest(fetcher, method, url, options, parameters, body, namespace) {\n\treturn new Promise((resolve, reject) => {\n\t\tfetcher(url, _getRequestParams(method, options, parameters, body)).then((result) => {\n\t\t\tif (!result.ok) throw result;\n\t\t\tif (options === null || options === void 0 ? void 0 : options.noResolveJson) return result;\n\t\t\tif (namespace === \"vectors\") {\n\t\t\t\tconst contentType = result.headers.get(\"content-type\");\n\t\t\t\tif (result.headers.get(\"content-length\") === \"0\" || result.status === 204) return {};\n\t\t\t\tif (!contentType || !contentType.includes(\"application/json\")) return {};\n\t\t\t}\n\t\t\treturn result.json();\n\t\t}).then((data) => resolve(data)).catch((error) => handleError(error, reject, options, namespace));\n\t});\n}\n/**\n* Creates a fetch API with the specified namespace\n* @param namespace - Error namespace ('storage' or 'vectors')\n* @returns Object with HTTP method functions\n*/\nfunction createFetchApi(namespace = \"storage\") {\n\treturn {\n\t\tget: async (fetcher, url, options, parameters) => {\n\t\t\treturn _handleRequest(fetcher, \"GET\", url, options, parameters, void 0, namespace);\n\t\t},\n\t\tpost: async (fetcher, url, body, options, parameters) => {\n\t\t\treturn _handleRequest(fetcher, \"POST\", url, options, parameters, body, namespace);\n\t\t},\n\t\tput: async (fetcher, url, body, options, parameters) => {\n\t\t\treturn _handleRequest(fetcher, \"PUT\", url, options, parameters, body, namespace);\n\t\t},\n\t\thead: async (fetcher, url, options, parameters) => {\n\t\t\treturn _handleRequest(fetcher, \"HEAD\", url, _objectSpread2(_objectSpread2({}, options), {}, { noResolveJson: true }), parameters, void 0, namespace);\n\t\t},\n\t\tremove: async (fetcher, url, body, options, parameters) => {\n\t\t\treturn _handleRequest(fetcher, \"DELETE\", url, options, parameters, body, namespace);\n\t\t}\n\t};\n}\nconst defaultApi = createFetchApi(\"storage\");\nconst { get, post, put, head, remove } = defaultApi;\nconst vectorsApi = createFetchApi(\"vectors\");\n\n//#endregion\n//#region src/lib/common/BaseApiClient.ts\n/**\n* @ignore\n* Base API client class for all Storage API classes\n* Provides common infrastructure for error handling and configuration\n*\n* @typeParam TError - The error type (StorageError or subclass)\n*/\nvar BaseApiClient = class {\n\t/**\n\t* Creates a new BaseApiClient instance\n\t* @param url - Base URL for API requests\n\t* @param headers - Default headers for API requests\n\t* @param fetch - Optional custom fetch implementation\n\t* @param namespace - Error namespace ('storage' or 'vectors')\n\t*/\n\tconstructor(url, headers = {}, fetch$1, namespace = \"storage\") {\n\t\tthis.shouldThrowOnError = false;\n\t\tthis.url = url;\n\t\tthis.headers = headers;\n\t\tthis.fetch = resolveFetch(fetch$1);\n\t\tthis.namespace = namespace;\n\t}\n\t/**\n\t* Enable throwing errors instead of returning them.\n\t* When enabled, errors are thrown instead of returned in { data, error } format.\n\t*\n\t* @returns this - For method chaining\n\t*/\n\tthrowOnError() {\n\t\tthis.shouldThrowOnError = true;\n\t\treturn this;\n\t}\n\t/**\n\t* Set an HTTP header for the request.\n\t* Creates a shallow copy of headers to avoid mutating shared state.\n\t*\n\t* @param name - Header name\n\t* @param value - Header value\n\t* @returns this - For method chaining\n\t*/\n\tsetHeader(name, value) {\n\t\tthis.headers = _objectSpread2(_objectSpread2({}, this.headers), {}, { [name]: value });\n\t\treturn this;\n\t}\n\t/**\n\t* Handles API operation with standardized error handling\n\t* Eliminates repetitive try-catch blocks across all API methods\n\t*\n\t* This wrapper:\n\t* 1. Executes the operation\n\t* 2. Returns { data, error: null } on success\n\t* 3. Returns { data: null, error } on failure (if shouldThrowOnError is false)\n\t* 4. Throws error on failure (if shouldThrowOnError is true)\n\t*\n\t* @typeParam T - The expected data type from the operation\n\t* @param operation - Async function that performs the API call\n\t* @returns Promise with { data, error } tuple\n\t*\n\t* @example\n\t* ```typescript\n\t* async listBuckets() {\n\t*   return this.handleOperation(async () => {\n\t*     return await get(this.fetch, `${this.url}/bucket`, {\n\t*       headers: this.headers,\n\t*     })\n\t*   })\n\t* }\n\t* ```\n\t*/\n\tasync handleOperation(operation) {\n\t\tvar _this = this;\n\t\ttry {\n\t\t\treturn {\n\t\t\t\tdata: await operation(),\n\t\t\t\terror: null\n\t\t\t};\n\t\t} catch (error) {\n\t\t\tif (_this.shouldThrowOnError) throw error;\n\t\t\tif (isStorageError(error)) return {\n\t\t\t\tdata: null,\n\t\t\t\terror\n\t\t\t};\n\t\t\tthrow error;\n\t\t}\n\t}\n};\n\n//#endregion\n//#region src/packages/StreamDownloadBuilder.ts\nvar StreamDownloadBuilder = class {\n\tconstructor(downloadFn, shouldThrowOnError) {\n\t\tthis.downloadFn = downloadFn;\n\t\tthis.shouldThrowOnError = shouldThrowOnError;\n\t}\n\tthen(onfulfilled, onrejected) {\n\t\treturn this.execute().then(onfulfilled, onrejected);\n\t}\n\tasync execute() {\n\t\tvar _this = this;\n\t\ttry {\n\t\t\treturn {\n\t\t\t\tdata: (await _this.downloadFn()).body,\n\t\t\t\terror: null\n\t\t\t};\n\t\t} catch (error) {\n\t\t\tif (_this.shouldThrowOnError) throw error;\n\t\t\tif (isStorageError(error)) return {\n\t\t\t\tdata: null,\n\t\t\t\terror\n\t\t\t};\n\t\t\tthrow error;\n\t\t}\n\t}\n};\n\n//#endregion\n//#region src/packages/BlobDownloadBuilder.ts\nlet _Symbol$toStringTag;\n_Symbol$toStringTag = Symbol.toStringTag;\nvar BlobDownloadBuilder = class {\n\tconstructor(downloadFn, shouldThrowOnError) {\n\t\tthis.downloadFn = downloadFn;\n\t\tthis.shouldThrowOnError = shouldThrowOnError;\n\t\tthis[_Symbol$toStringTag] = \"BlobDownloadBuilder\";\n\t\tthis.promise = null;\n\t}\n\tasStream() {\n\t\treturn new StreamDownloadBuilder(this.downloadFn, this.shouldThrowOnError);\n\t}\n\tthen(onfulfilled, onrejected) {\n\t\treturn this.getPromise().then(onfulfilled, onrejected);\n\t}\n\tcatch(onrejected) {\n\t\treturn this.getPromise().catch(onrejected);\n\t}\n\tfinally(onfinally) {\n\t\treturn this.getPromise().finally(onfinally);\n\t}\n\tgetPromise() {\n\t\tif (!this.promise) this.promise = this.execute();\n\t\treturn this.promise;\n\t}\n\tasync execute() {\n\t\tvar _this = this;\n\t\ttry {\n\t\t\treturn {\n\t\t\t\tdata: await (await _this.downloadFn()).blob(),\n\t\t\t\terror: null\n\t\t\t};\n\t\t} catch (error) {\n\t\t\tif (_this.shouldThrowOnError) throw error;\n\t\t\tif (isStorageError(error)) return {\n\t\t\t\tdata: null,\n\t\t\t\terror\n\t\t\t};\n\t\t\tthrow error;\n\t\t}\n\t}\n};\n\n//#endregion\n//#region src/packages/StorageFileApi.ts\nconst DEFAULT_SEARCH_OPTIONS = {\n\tlimit: 100,\n\toffset: 0,\n\tsortBy: {\n\t\tcolumn: \"name\",\n\t\torder: \"asc\"\n\t}\n};\nconst DEFAULT_FILE_OPTIONS = {\n\tcacheControl: \"3600\",\n\tcontentType: \"text/plain;charset=UTF-8\",\n\tupsert: false\n};\nvar StorageFileApi = class extends BaseApiClient {\n\tconstructor(url, headers = {}, bucketId, fetch$1) {\n\t\tsuper(url, headers, fetch$1, \"storage\");\n\t\tthis.bucketId = bucketId;\n\t}\n\t/**\n\t* Uploads a file to an existing bucket or replaces an existing file at the specified path with a new one.\n\t*\n\t* @param method HTTP method.\n\t* @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n\t* @param fileBody The body of the file to be stored in the bucket.\n\t*/\n\tasync uploadOrUpdate(method, path, fileBody, fileOptions) {\n\t\tvar _this = this;\n\t\treturn _this.handleOperation(async () => {\n\t\t\tlet body;\n\t\t\tconst options = _objectSpread2(_objectSpread2({}, DEFAULT_FILE_OPTIONS), fileOptions);\n\t\t\tlet headers = _objectSpread2(_objectSpread2({}, _this.headers), method === \"POST\" && { \"x-upsert\": String(options.upsert) });\n\t\t\tconst metadata = options.metadata;\n\t\t\tif (typeof Blob !== \"undefined\" && fileBody instanceof Blob) {\n\t\t\t\tbody = new FormData();\n\t\t\t\tbody.append(\"cacheControl\", options.cacheControl);\n\t\t\t\tif (metadata) body.append(\"metadata\", _this.encodeMetadata(metadata));\n\t\t\t\tbody.append(\"\", fileBody);\n\t\t\t} else if (typeof FormData !== \"undefined\" && fileBody instanceof FormData) {\n\t\t\t\tbody = fileBody;\n\t\t\t\tif (!body.has(\"cacheControl\")) body.append(\"cacheControl\", options.cacheControl);\n\t\t\t\tif (metadata && !body.has(\"metadata\")) body.append(\"metadata\", _this.encodeMetadata(metadata));\n\t\t\t} else {\n\t\t\t\tbody = fileBody;\n\t\t\t\theaders[\"cache-control\"] = `max-age=${options.cacheControl}`;\n\t\t\t\theaders[\"content-type\"] = options.contentType;\n\t\t\t\tif (metadata) headers[\"x-metadata\"] = _this.toBase64(_this.encodeMetadata(metadata));\n\t\t\t\tif ((typeof ReadableStream !== \"undefined\" && body instanceof ReadableStream || body && typeof body === \"object\" && \"pipe\" in body && typeof body.pipe === \"function\") && !options.duplex) options.duplex = \"half\";\n\t\t\t}\n\t\t\tif (fileOptions === null || fileOptions === void 0 ? void 0 : fileOptions.headers) headers = _objectSpread2(_objectSpread2({}, headers), fileOptions.headers);\n\t\t\tconst cleanPath = _this._removeEmptyFolders(path);\n\t\t\tconst _path = _this._getFinalPath(cleanPath);\n\t\t\tconst data = await (method == \"PUT\" ? put : post)(_this.fetch, `${_this.url}/object/${_path}`, body, _objectSpread2({ headers }, (options === null || options === void 0 ? void 0 : options.duplex) ? { duplex: options.duplex } : {}));\n\t\t\treturn {\n\t\t\t\tpath: cleanPath,\n\t\t\t\tid: data.Id,\n\t\t\t\tfullPath: data.Key\n\t\t\t};\n\t\t});\n\t}\n\t/**\n\t* Uploads a file to an existing bucket.\n\t*\n\t* @category File Buckets\n\t* @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n\t* @param fileBody The body of the file to be stored in the bucket.\n\t* @param fileOptions Optional file upload options including cacheControl, contentType, upsert, and metadata.\n\t* @returns Promise with response containing file path, id, and fullPath or error\n\t*\n\t* @example Upload file\n\t* ```js\n\t* const avatarFile = event.target.files[0]\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .upload('public/avatar1.png', avatarFile, {\n\t*     cacheControl: '3600',\n\t*     upsert: false\n\t*   })\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"path\": \"public/avatar1.png\",\n\t*     \"fullPath\": \"avatars/public/avatar1.png\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*\n\t* @example Upload file using `ArrayBuffer` from base64 file data\n\t* ```js\n\t* import { decode } from 'base64-arraybuffer'\n\t*\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .upload('public/avatar1.png', decode('base64FileData'), {\n\t*     contentType: 'image/png'\n\t*   })\n\t* ```\n\t*/\n\tasync upload(path, fileBody, fileOptions) {\n\t\treturn this.uploadOrUpdate(\"POST\", path, fileBody, fileOptions);\n\t}\n\t/**\n\t* Upload a file with a token generated from `createSignedUploadUrl`.\n\t*\n\t* @category File Buckets\n\t* @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n\t* @param token The token generated from `createSignedUploadUrl`\n\t* @param fileBody The body of the file to be stored in the bucket.\n\t* @param fileOptions HTTP headers (cacheControl, contentType, etc.).\n\t* **Note:** The `upsert` option has no effect here. To enable upsert behavior,\n\t* pass `{ upsert: true }` when calling `createSignedUploadUrl()` instead.\n\t* @returns Promise with response containing file path and fullPath or error\n\t*\n\t* @example Upload to a signed URL\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .uploadToSignedUrl('folder/cat.jpg', 'token-from-createSignedUploadUrl', file)\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"path\": \"folder/cat.jpg\",\n\t*     \"fullPath\": \"avatars/folder/cat.jpg\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync uploadToSignedUrl(path, token, fileBody, fileOptions) {\n\t\tvar _this3 = this;\n\t\tconst cleanPath = _this3._removeEmptyFolders(path);\n\t\tconst _path = _this3._getFinalPath(cleanPath);\n\t\tconst url = new URL(_this3.url + `/object/upload/sign/${_path}`);\n\t\turl.searchParams.set(\"token\", token);\n\t\treturn _this3.handleOperation(async () => {\n\t\t\tlet body;\n\t\t\tconst options = _objectSpread2({ upsert: DEFAULT_FILE_OPTIONS.upsert }, fileOptions);\n\t\t\tconst headers = _objectSpread2(_objectSpread2({}, _this3.headers), { \"x-upsert\": String(options.upsert) });\n\t\t\tif (typeof Blob !== \"undefined\" && fileBody instanceof Blob) {\n\t\t\t\tbody = new FormData();\n\t\t\t\tbody.append(\"cacheControl\", options.cacheControl);\n\t\t\t\tbody.append(\"\", fileBody);\n\t\t\t} else if (typeof FormData !== \"undefined\" && fileBody instanceof FormData) {\n\t\t\t\tbody = fileBody;\n\t\t\t\tbody.append(\"cacheControl\", options.cacheControl);\n\t\t\t} else {\n\t\t\t\tbody = fileBody;\n\t\t\t\theaders[\"cache-control\"] = `max-age=${options.cacheControl}`;\n\t\t\t\theaders[\"content-type\"] = options.contentType;\n\t\t\t}\n\t\t\treturn {\n\t\t\t\tpath: cleanPath,\n\t\t\t\tfullPath: (await put(_this3.fetch, url.toString(), body, { headers })).Key\n\t\t\t};\n\t\t});\n\t}\n\t/**\n\t* Creates a signed upload URL.\n\t* Signed upload URLs can be used to upload files to the bucket without further authentication.\n\t* They are valid for 2 hours.\n\t*\n\t* @category File Buckets\n\t* @param path The file path, including the current file name. For example `folder/image.png`.\n\t* @param options.upsert If set to true, allows the file to be overwritten if it already exists.\n\t* @returns Promise with response containing signed upload URL, token, and path or error\n\t*\n\t* @example Create Signed Upload URL\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .createSignedUploadUrl('folder/cat.jpg')\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"signedUrl\": \"https://example.supabase.co/storage/v1/object/upload/sign/avatars/folder/cat.jpg?token=<TOKEN>\",\n\t*     \"path\": \"folder/cat.jpg\",\n\t*     \"token\": \"<TOKEN>\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync createSignedUploadUrl(path, options) {\n\t\tvar _this4 = this;\n\t\treturn _this4.handleOperation(async () => {\n\t\t\tlet _path = _this4._getFinalPath(path);\n\t\t\tconst headers = _objectSpread2({}, _this4.headers);\n\t\t\tif (options === null || options === void 0 ? void 0 : options.upsert) headers[\"x-upsert\"] = \"true\";\n\t\t\tconst data = await post(_this4.fetch, `${_this4.url}/object/upload/sign/${_path}`, {}, { headers });\n\t\t\tconst url = new URL(_this4.url + data.url);\n\t\t\tconst token = url.searchParams.get(\"token\");\n\t\t\tif (!token) throw new StorageError(\"No token returned by API\");\n\t\t\treturn {\n\t\t\t\tsignedUrl: url.toString(),\n\t\t\t\tpath,\n\t\t\t\ttoken\n\t\t\t};\n\t\t});\n\t}\n\t/**\n\t* Replaces an existing file at the specified path with a new one.\n\t*\n\t* @category File Buckets\n\t* @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to update.\n\t* @param fileBody The body of the file to be stored in the bucket.\n\t* @param fileOptions Optional file upload options including cacheControl, contentType, upsert, and metadata.\n\t* @returns Promise with response containing file path, id, and fullPath or error\n\t*\n\t* @example Update file\n\t* ```js\n\t* const avatarFile = event.target.files[0]\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .update('public/avatar1.png', avatarFile, {\n\t*     cacheControl: '3600',\n\t*     upsert: true\n\t*   })\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"path\": \"public/avatar1.png\",\n\t*     \"fullPath\": \"avatars/public/avatar1.png\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*\n\t* @example Update file using `ArrayBuffer` from base64 file data\n\t* ```js\n\t* import {decode} from 'base64-arraybuffer'\n\t*\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .update('public/avatar1.png', decode('base64FileData'), {\n\t*     contentType: 'image/png'\n\t*   })\n\t* ```\n\t*/\n\tasync update(path, fileBody, fileOptions) {\n\t\treturn this.uploadOrUpdate(\"PUT\", path, fileBody, fileOptions);\n\t}\n\t/**\n\t* Moves an existing file to a new path in the same bucket.\n\t*\n\t* @category File Buckets\n\t* @param fromPath The original file path, including the current file name. For example `folder/image.png`.\n\t* @param toPath The new file path, including the new file name. For example `folder/image-new.png`.\n\t* @param options The destination options.\n\t* @returns Promise with response containing success message or error\n\t*\n\t* @example Move file\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .move('public/avatar1.png', 'private/avatar2.png')\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"message\": \"Successfully moved\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync move(fromPath, toPath, options) {\n\t\tvar _this6 = this;\n\t\treturn _this6.handleOperation(async () => {\n\t\t\treturn await post(_this6.fetch, `${_this6.url}/object/move`, {\n\t\t\t\tbucketId: _this6.bucketId,\n\t\t\t\tsourceKey: fromPath,\n\t\t\t\tdestinationKey: toPath,\n\t\t\t\tdestinationBucket: options === null || options === void 0 ? void 0 : options.destinationBucket\n\t\t\t}, { headers: _this6.headers });\n\t\t});\n\t}\n\t/**\n\t* Copies an existing file to a new path in the same bucket.\n\t*\n\t* @category File Buckets\n\t* @param fromPath The original file path, including the current file name. For example `folder/image.png`.\n\t* @param toPath The new file path, including the new file name. For example `folder/image-copy.png`.\n\t* @param options The destination options.\n\t* @returns Promise with response containing copied file path or error\n\t*\n\t* @example Copy file\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .copy('public/avatar1.png', 'private/avatar2.png')\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"path\": \"avatars/private/avatar2.png\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync copy(fromPath, toPath, options) {\n\t\tvar _this7 = this;\n\t\treturn _this7.handleOperation(async () => {\n\t\t\treturn { path: (await post(_this7.fetch, `${_this7.url}/object/copy`, {\n\t\t\t\tbucketId: _this7.bucketId,\n\t\t\t\tsourceKey: fromPath,\n\t\t\t\tdestinationKey: toPath,\n\t\t\t\tdestinationBucket: options === null || options === void 0 ? void 0 : options.destinationBucket\n\t\t\t}, { headers: _this7.headers })).Key };\n\t\t});\n\t}\n\t/**\n\t* Creates a signed URL. Use a signed URL to share a file for a fixed amount of time.\n\t*\n\t* @category File Buckets\n\t* @param path The file path, including the current file name. For example `folder/image.png`.\n\t* @param expiresIn The number of seconds until the signed URL expires. For example, `60` for a URL which is valid for one minute.\n\t* @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n\t* @param options.transform Transform the asset before serving it to the client.\n\t* @returns Promise with response containing signed URL or error\n\t*\n\t* @example Create Signed URL\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .createSignedUrl('folder/avatar1.png', 60)\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*\n\t* @example Create a signed URL for an asset with transformations\n\t* ```js\n\t* const { data } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .createSignedUrl('folder/avatar1.png', 60, {\n\t*     transform: {\n\t*       width: 100,\n\t*       height: 100,\n\t*     }\n\t*   })\n\t* ```\n\t*\n\t* @example Create a signed URL which triggers the download of the asset\n\t* ```js\n\t* const { data } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .createSignedUrl('folder/avatar1.png', 60, {\n\t*     download: true,\n\t*   })\n\t* ```\n\t*/\n\tasync createSignedUrl(path, expiresIn, options) {\n\t\tvar _this8 = this;\n\t\treturn _this8.handleOperation(async () => {\n\t\t\tlet _path = _this8._getFinalPath(path);\n\t\t\tlet data = await post(_this8.fetch, `${_this8.url}/object/sign/${_path}`, _objectSpread2({ expiresIn }, (options === null || options === void 0 ? void 0 : options.transform) ? { transform: options.transform } : {}), { headers: _this8.headers });\n\t\t\tconst downloadQueryParam = (options === null || options === void 0 ? void 0 : options.download) ? `&download=${options.download === true ? \"\" : options.download}` : \"\";\n\t\t\treturn { signedUrl: encodeURI(`${_this8.url}${data.signedURL}${downloadQueryParam}`) };\n\t\t});\n\t}\n\t/**\n\t* Creates multiple signed URLs. Use a signed URL to share a file for a fixed amount of time.\n\t*\n\t* @category File Buckets\n\t* @param paths The file paths to be downloaded, including the current file names. For example `['folder/image.png', 'folder2/image2.png']`.\n\t* @param expiresIn The number of seconds until the signed URLs expire. For example, `60` for URLs which are valid for one minute.\n\t* @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n\t* @returns Promise with response containing array of objects with signedUrl, path, and error or error\n\t*\n\t* @example Create Signed URLs\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .createSignedUrls(['folder/avatar1.png', 'folder/avatar2.png'], 60)\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": [\n\t*     {\n\t*       \"error\": null,\n\t*       \"path\": \"folder/avatar1.png\",\n\t*       \"signedURL\": \"/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\",\n\t*       \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\"\n\t*     },\n\t*     {\n\t*       \"error\": null,\n\t*       \"path\": \"folder/avatar2.png\",\n\t*       \"signedURL\": \"/object/sign/avatars/folder/avatar2.png?token=<TOKEN>\",\n\t*       \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar2.png?token=<TOKEN>\"\n\t*     }\n\t*   ],\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync createSignedUrls(paths, expiresIn, options) {\n\t\tvar _this9 = this;\n\t\treturn _this9.handleOperation(async () => {\n\t\t\tconst data = await post(_this9.fetch, `${_this9.url}/object/sign/${_this9.bucketId}`, {\n\t\t\t\texpiresIn,\n\t\t\t\tpaths\n\t\t\t}, { headers: _this9.headers });\n\t\t\tconst downloadQueryParam = (options === null || options === void 0 ? void 0 : options.download) ? `&download=${options.download === true ? \"\" : options.download}` : \"\";\n\t\t\treturn data.map((datum) => _objectSpread2(_objectSpread2({}, datum), {}, { signedUrl: datum.signedURL ? encodeURI(`${_this9.url}${datum.signedURL}${downloadQueryParam}`) : null }));\n\t\t});\n\t}\n\t/**\n\t* Downloads a file from a private bucket. For public buckets, make a request to the URL returned from `getPublicUrl` instead.\n\t*\n\t* @category File Buckets\n\t* @param path The full path and file name of the file to be downloaded. For example `folder/image.png`.\n\t* @param options.transform Transform the asset before serving it to the client.\n\t* @param parameters Additional fetch parameters like signal for cancellation. Supports standard fetch options including cache control.\n\t* @returns BlobDownloadBuilder instance for downloading the file\n\t*\n\t* @example Download file\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .download('folder/avatar1.png')\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": <BLOB>,\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*\n\t* @example Download file with transformations\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .download('folder/avatar1.png', {\n\t*     transform: {\n\t*       width: 100,\n\t*       height: 100,\n\t*       quality: 80\n\t*     }\n\t*   })\n\t* ```\n\t*\n\t* @example Download with cache control (useful in Edge Functions)\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .download('folder/avatar1.png', {}, { cache: 'no-store' })\n\t* ```\n\t*\n\t* @example Download with abort signal\n\t* ```js\n\t* const controller = new AbortController()\n\t* setTimeout(() => controller.abort(), 5000)\n\t*\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .download('folder/avatar1.png', {}, { signal: controller.signal })\n\t* ```\n\t*/\n\tdownload(path, options, parameters) {\n\t\tconst renderPath = typeof (options === null || options === void 0 ? void 0 : options.transform) !== \"undefined\" ? \"render/image/authenticated\" : \"object\";\n\t\tconst transformationQuery = this.transformOptsToQueryString((options === null || options === void 0 ? void 0 : options.transform) || {});\n\t\tconst queryString = transformationQuery ? `?${transformationQuery}` : \"\";\n\t\tconst _path = this._getFinalPath(path);\n\t\tconst downloadFn = () => get(this.fetch, `${this.url}/${renderPath}/${_path}${queryString}`, {\n\t\t\theaders: this.headers,\n\t\t\tnoResolveJson: true\n\t\t}, parameters);\n\t\treturn new BlobDownloadBuilder(downloadFn, this.shouldThrowOnError);\n\t}\n\t/**\n\t* Retrieves the details of an existing file.\n\t*\n\t* @category File Buckets\n\t* @param path The file path, including the file name. For example `folder/image.png`.\n\t* @returns Promise with response containing file metadata or error\n\t*\n\t* @example Get file info\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .info('folder/avatar1.png')\n\t* ```\n\t*/\n\tasync info(path) {\n\t\tvar _this10 = this;\n\t\tconst _path = _this10._getFinalPath(path);\n\t\treturn _this10.handleOperation(async () => {\n\t\t\treturn recursiveToCamel(await get(_this10.fetch, `${_this10.url}/object/info/${_path}`, { headers: _this10.headers }));\n\t\t});\n\t}\n\t/**\n\t* Checks the existence of a file.\n\t*\n\t* @category File Buckets\n\t* @param path The file path, including the file name. For example `folder/image.png`.\n\t* @returns Promise with response containing boolean indicating file existence or error\n\t*\n\t* @example Check file existence\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .exists('folder/avatar1.png')\n\t* ```\n\t*/\n\tasync exists(path) {\n\t\tvar _this11 = this;\n\t\tconst _path = _this11._getFinalPath(path);\n\t\ttry {\n\t\t\tawait head(_this11.fetch, `${_this11.url}/object/${_path}`, { headers: _this11.headers });\n\t\t\treturn {\n\t\t\t\tdata: true,\n\t\t\t\terror: null\n\t\t\t};\n\t\t} catch (error) {\n\t\t\tif (_this11.shouldThrowOnError) throw error;\n\t\t\tif (isStorageError(error) && error instanceof StorageUnknownError) {\n\t\t\t\tconst originalError = error.originalError;\n\t\t\t\tif ([400, 404].includes(originalError === null || originalError === void 0 ? void 0 : originalError.status)) return {\n\t\t\t\t\tdata: false,\n\t\t\t\t\terror\n\t\t\t\t};\n\t\t\t}\n\t\t\tthrow error;\n\t\t}\n\t}\n\t/**\n\t* A simple convenience function to get the URL for an asset in a public bucket. If you do not want to use this function, you can construct the public URL by concatenating the bucket URL with the path to the asset.\n\t* This function does not verify if the bucket is public. If a public URL is created for a bucket which is not public, you will not be able to download the asset.\n\t*\n\t* @category File Buckets\n\t* @param path The path and name of the file to generate the public URL for. For example `folder/image.png`.\n\t* @param options.download Triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n\t* @param options.transform Transform the asset before serving it to the client.\n\t* @returns Object with public URL\n\t*\n\t* @example Returns the URL for an asset in a public bucket\n\t* ```js\n\t* const { data } = supabase\n\t*   .storage\n\t*   .from('public-bucket')\n\t*   .getPublicUrl('folder/avatar1.png')\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"publicUrl\": \"https://example.supabase.co/storage/v1/object/public/public-bucket/folder/avatar1.png\"\n\t*   }\n\t* }\n\t* ```\n\t*\n\t* @example Returns the URL for an asset in a public bucket with transformations\n\t* ```js\n\t* const { data } = supabase\n\t*   .storage\n\t*   .from('public-bucket')\n\t*   .getPublicUrl('folder/avatar1.png', {\n\t*     transform: {\n\t*       width: 100,\n\t*       height: 100,\n\t*     }\n\t*   })\n\t* ```\n\t*\n\t* @example Returns the URL which triggers the download of an asset in a public bucket\n\t* ```js\n\t* const { data } = supabase\n\t*   .storage\n\t*   .from('public-bucket')\n\t*   .getPublicUrl('folder/avatar1.png', {\n\t*     download: true,\n\t*   })\n\t* ```\n\t*/\n\tgetPublicUrl(path, options) {\n\t\tconst _path = this._getFinalPath(path);\n\t\tconst _queryString = [];\n\t\tconst downloadQueryParam = (options === null || options === void 0 ? void 0 : options.download) ? `download=${options.download === true ? \"\" : options.download}` : \"\";\n\t\tif (downloadQueryParam !== \"\") _queryString.push(downloadQueryParam);\n\t\tconst renderPath = typeof (options === null || options === void 0 ? void 0 : options.transform) !== \"undefined\" ? \"render/image\" : \"object\";\n\t\tconst transformationQuery = this.transformOptsToQueryString((options === null || options === void 0 ? void 0 : options.transform) || {});\n\t\tif (transformationQuery !== \"\") _queryString.push(transformationQuery);\n\t\tlet queryString = _queryString.join(\"&\");\n\t\tif (queryString !== \"\") queryString = `?${queryString}`;\n\t\treturn { data: { publicUrl: encodeURI(`${this.url}/${renderPath}/public/${_path}${queryString}`) } };\n\t}\n\t/**\n\t* Deletes files within the same bucket\n\t*\n\t* @category File Buckets\n\t* @param paths An array of files to delete, including the path and file name. For example [`'folder/image.png'`].\n\t* @returns Promise with response containing array of deleted file objects or error\n\t*\n\t* @example Delete file\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .remove(['folder/avatar1.png'])\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": [],\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync remove(paths) {\n\t\tvar _this12 = this;\n\t\treturn _this12.handleOperation(async () => {\n\t\t\treturn await remove(_this12.fetch, `${_this12.url}/object/${_this12.bucketId}`, { prefixes: paths }, { headers: _this12.headers });\n\t\t});\n\t}\n\t/**\n\t* Get file metadata\n\t* @param id the file id to retrieve metadata\n\t*/\n\t/**\n\t* Update file metadata\n\t* @param id the file id to update metadata\n\t* @param meta the new file metadata\n\t*/\n\t/**\n\t* Lists all the files and folders within a path of the bucket.\n\t*\n\t* @category File Buckets\n\t* @param path The folder path.\n\t* @param options Search options including limit (defaults to 100), offset, sortBy, and search\n\t* @param parameters Optional fetch parameters including signal for cancellation\n\t* @returns Promise with response containing array of files or error\n\t*\n\t* @example List files in a bucket\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .list('folder', {\n\t*     limit: 100,\n\t*     offset: 0,\n\t*     sortBy: { column: 'name', order: 'asc' },\n\t*   })\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": [\n\t*     {\n\t*       \"name\": \"avatar1.png\",\n\t*       \"id\": \"e668cf7f-821b-4a2f-9dce-7dfa5dd1cfd2\",\n\t*       \"updated_at\": \"2024-05-22T23:06:05.580Z\",\n\t*       \"created_at\": \"2024-05-22T23:04:34.443Z\",\n\t*       \"last_accessed_at\": \"2024-05-22T23:04:34.443Z\",\n\t*       \"metadata\": {\n\t*         \"eTag\": \"\\\"c5e8c553235d9af30ef4f6e280790b92\\\"\",\n\t*         \"size\": 32175,\n\t*         \"mimetype\": \"image/png\",\n\t*         \"cacheControl\": \"max-age=3600\",\n\t*         \"lastModified\": \"2024-05-22T23:06:05.574Z\",\n\t*         \"contentLength\": 32175,\n\t*         \"httpStatusCode\": 200\n\t*       }\n\t*     }\n\t*   ],\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*\n\t* @example Search files in a bucket\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .list('folder', {\n\t*     limit: 100,\n\t*     offset: 0,\n\t*     sortBy: { column: 'name', order: 'asc' },\n\t*     search: 'jon'\n\t*   })\n\t* ```\n\t*/\n\tasync list(path, options, parameters) {\n\t\tvar _this13 = this;\n\t\treturn _this13.handleOperation(async () => {\n\t\t\tconst body = _objectSpread2(_objectSpread2(_objectSpread2({}, DEFAULT_SEARCH_OPTIONS), options), {}, { prefix: path || \"\" });\n\t\t\treturn await post(_this13.fetch, `${_this13.url}/object/list/${_this13.bucketId}`, body, { headers: _this13.headers }, parameters);\n\t\t});\n\t}\n\t/**\n\t* @experimental this method signature might change in the future\n\t*\n\t* @category File Buckets\n\t* @param options search options\n\t* @param parameters\n\t*/\n\tasync listV2(options, parameters) {\n\t\tvar _this14 = this;\n\t\treturn _this14.handleOperation(async () => {\n\t\t\tconst body = _objectSpread2({}, options);\n\t\t\treturn await post(_this14.fetch, `${_this14.url}/object/list-v2/${_this14.bucketId}`, body, { headers: _this14.headers }, parameters);\n\t\t});\n\t}\n\tencodeMetadata(metadata) {\n\t\treturn JSON.stringify(metadata);\n\t}\n\ttoBase64(data) {\n\t\tif (typeof Buffer !== \"undefined\") return Buffer.from(data).toString(\"base64\");\n\t\treturn btoa(data);\n\t}\n\t_getFinalPath(path) {\n\t\treturn `${this.bucketId}/${path.replace(/^\\/+/, \"\")}`;\n\t}\n\t_removeEmptyFolders(path) {\n\t\treturn path.replace(/^\\/|\\/$/g, \"\").replace(/\\/+/g, \"/\");\n\t}\n\ttransformOptsToQueryString(transform) {\n\t\tconst params = [];\n\t\tif (transform.width) params.push(`width=${transform.width}`);\n\t\tif (transform.height) params.push(`height=${transform.height}`);\n\t\tif (transform.resize) params.push(`resize=${transform.resize}`);\n\t\tif (transform.format) params.push(`format=${transform.format}`);\n\t\tif (transform.quality) params.push(`quality=${transform.quality}`);\n\t\treturn params.join(\"&\");\n\t}\n};\n\n//#endregion\n//#region src/lib/version.ts\nconst version = \"2.97.0\";\n\n//#endregion\n//#region src/lib/constants.ts\nconst DEFAULT_HEADERS = { \"X-Client-Info\": `storage-js/${version}` };\n\n//#endregion\n//#region src/packages/StorageBucketApi.ts\nvar StorageBucketApi = class extends BaseApiClient {\n\tconstructor(url, headers = {}, fetch$1, opts) {\n\t\tconst baseUrl = new URL(url);\n\t\tif (opts === null || opts === void 0 ? void 0 : opts.useNewHostname) {\n\t\t\tif (/supabase\\.(co|in|red)$/.test(baseUrl.hostname) && !baseUrl.hostname.includes(\"storage.supabase.\")) baseUrl.hostname = baseUrl.hostname.replace(\"supabase.\", \"storage.supabase.\");\n\t\t}\n\t\tconst finalUrl = baseUrl.href.replace(/\\/$/, \"\");\n\t\tconst finalHeaders = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), headers);\n\t\tsuper(finalUrl, finalHeaders, fetch$1, \"storage\");\n\t}\n\t/**\n\t* Retrieves the details of all Storage buckets within an existing project.\n\t*\n\t* @category File Buckets\n\t* @param options Query parameters for listing buckets\n\t* @param options.limit Maximum number of buckets to return\n\t* @param options.offset Number of buckets to skip\n\t* @param options.sortColumn Column to sort by ('id', 'name', 'created_at', 'updated_at')\n\t* @param options.sortOrder Sort order ('asc' or 'desc')\n\t* @param options.search Search term to filter bucket names\n\t* @returns Promise with response containing array of buckets or error\n\t*\n\t* @example List buckets\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .listBuckets()\n\t* ```\n\t*\n\t* @example List buckets with options\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .listBuckets({\n\t*     limit: 10,\n\t*     offset: 0,\n\t*     sortColumn: 'created_at',\n\t*     sortOrder: 'desc',\n\t*     search: 'prod'\n\t*   })\n\t* ```\n\t*/\n\tasync listBuckets(options) {\n\t\tvar _this = this;\n\t\treturn _this.handleOperation(async () => {\n\t\t\tconst queryString = _this.listBucketOptionsToQueryString(options);\n\t\t\treturn await get(_this.fetch, `${_this.url}/bucket${queryString}`, { headers: _this.headers });\n\t\t});\n\t}\n\t/**\n\t* Retrieves the details of an existing Storage bucket.\n\t*\n\t* @category File Buckets\n\t* @param id The unique identifier of the bucket you would like to retrieve.\n\t* @returns Promise with response containing bucket details or error\n\t*\n\t* @example Get bucket\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .getBucket('avatars')\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"id\": \"avatars\",\n\t*     \"name\": \"avatars\",\n\t*     \"owner\": \"\",\n\t*     \"public\": false,\n\t*     \"file_size_limit\": 1024,\n\t*     \"allowed_mime_types\": [\n\t*       \"image/png\"\n\t*     ],\n\t*     \"created_at\": \"2024-05-22T22:26:05.100Z\",\n\t*     \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync getBucket(id) {\n\t\tvar _this2 = this;\n\t\treturn _this2.handleOperation(async () => {\n\t\t\treturn await get(_this2.fetch, `${_this2.url}/bucket/${id}`, { headers: _this2.headers });\n\t\t});\n\t}\n\t/**\n\t* Creates a new Storage bucket\n\t*\n\t* @category File Buckets\n\t* @param id A unique identifier for the bucket you are creating.\n\t* @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations. By default, buckets are private.\n\t* @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\n\t* The global file size limit takes precedence over this value.\n\t* The default value is null, which doesn't set a per bucket file size limit.\n\t* @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\n\t* The default value is null, which allows files with all mime types to be uploaded.\n\t* Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\n\t* @param options.type (private-beta) specifies the bucket type. see `BucketType` for more details.\n\t*   - default bucket type is `STANDARD`\n\t* @returns Promise with response containing newly created bucket name or error\n\t*\n\t* @example Create bucket\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .createBucket('avatars', {\n\t*     public: false,\n\t*     allowedMimeTypes: ['image/png'],\n\t*     fileSizeLimit: 1024\n\t*   })\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"name\": \"avatars\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync createBucket(id, options = { public: false }) {\n\t\tvar _this3 = this;\n\t\treturn _this3.handleOperation(async () => {\n\t\t\treturn await post(_this3.fetch, `${_this3.url}/bucket`, {\n\t\t\t\tid,\n\t\t\t\tname: id,\n\t\t\t\ttype: options.type,\n\t\t\t\tpublic: options.public,\n\t\t\t\tfile_size_limit: options.fileSizeLimit,\n\t\t\t\tallowed_mime_types: options.allowedMimeTypes\n\t\t\t}, { headers: _this3.headers });\n\t\t});\n\t}\n\t/**\n\t* Updates a Storage bucket\n\t*\n\t* @category File Buckets\n\t* @param id A unique identifier for the bucket you are updating.\n\t* @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations.\n\t* @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\n\t* The global file size limit takes precedence over this value.\n\t* The default value is null, which doesn't set a per bucket file size limit.\n\t* @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\n\t* The default value is null, which allows files with all mime types to be uploaded.\n\t* Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\n\t* @returns Promise with response containing success message or error\n\t*\n\t* @example Update bucket\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .updateBucket('avatars', {\n\t*     public: false,\n\t*     allowedMimeTypes: ['image/png'],\n\t*     fileSizeLimit: 1024\n\t*   })\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"message\": \"Successfully updated\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync updateBucket(id, options) {\n\t\tvar _this4 = this;\n\t\treturn _this4.handleOperation(async () => {\n\t\t\treturn await put(_this4.fetch, `${_this4.url}/bucket/${id}`, {\n\t\t\t\tid,\n\t\t\t\tname: id,\n\t\t\t\tpublic: options.public,\n\t\t\t\tfile_size_limit: options.fileSizeLimit,\n\t\t\t\tallowed_mime_types: options.allowedMimeTypes\n\t\t\t}, { headers: _this4.headers });\n\t\t});\n\t}\n\t/**\n\t* Removes all objects inside a single bucket.\n\t*\n\t* @category File Buckets\n\t* @param id The unique identifier of the bucket you would like to empty.\n\t* @returns Promise with success message or error\n\t*\n\t* @example Empty bucket\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .emptyBucket('avatars')\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"message\": \"Successfully emptied\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync emptyBucket(id) {\n\t\tvar _this5 = this;\n\t\treturn _this5.handleOperation(async () => {\n\t\t\treturn await post(_this5.fetch, `${_this5.url}/bucket/${id}/empty`, {}, { headers: _this5.headers });\n\t\t});\n\t}\n\t/**\n\t* Deletes an existing bucket. A bucket can't be deleted with existing objects inside it.\n\t* You must first `empty()` the bucket.\n\t*\n\t* @category File Buckets\n\t* @param id The unique identifier of the bucket you would like to delete.\n\t* @returns Promise with success message or error\n\t*\n\t* @example Delete bucket\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .deleteBucket('avatars')\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"message\": \"Successfully deleted\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync deleteBucket(id) {\n\t\tvar _this6 = this;\n\t\treturn _this6.handleOperation(async () => {\n\t\t\treturn await remove(_this6.fetch, `${_this6.url}/bucket/${id}`, {}, { headers: _this6.headers });\n\t\t});\n\t}\n\tlistBucketOptionsToQueryString(options) {\n\t\tconst params = {};\n\t\tif (options) {\n\t\t\tif (\"limit\" in options) params.limit = String(options.limit);\n\t\t\tif (\"offset\" in options) params.offset = String(options.offset);\n\t\t\tif (options.search) params.search = options.search;\n\t\t\tif (options.sortColumn) params.sortColumn = options.sortColumn;\n\t\t\tif (options.sortOrder) params.sortOrder = options.sortOrder;\n\t\t}\n\t\treturn Object.keys(params).length > 0 ? \"?\" + new URLSearchParams(params).toString() : \"\";\n\t}\n};\n\n//#endregion\n//#region src/packages/StorageAnalyticsClient.ts\n/**\n* Client class for managing Analytics Buckets using Iceberg tables\n* Provides methods for creating, listing, and deleting analytics buckets\n*/\nvar StorageAnalyticsClient = class extends BaseApiClient {\n\t/**\n\t* @alpha\n\t*\n\t* Creates a new StorageAnalyticsClient instance\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Analytics Buckets\n\t* @param url - The base URL for the storage API\n\t* @param headers - HTTP headers to include in requests\n\t* @param fetch - Optional custom fetch implementation\n\t*\n\t* @example\n\t* ```typescript\n\t* const client = new StorageAnalyticsClient(url, headers)\n\t* ```\n\t*/\n\tconstructor(url, headers = {}, fetch$1) {\n\t\tconst finalUrl = url.replace(/\\/$/, \"\");\n\t\tconst finalHeaders = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), headers);\n\t\tsuper(finalUrl, finalHeaders, fetch$1, \"storage\");\n\t}\n\t/**\n\t* @alpha\n\t*\n\t* Creates a new analytics bucket using Iceberg tables\n\t* Analytics buckets are optimized for analytical queries and data processing\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Analytics Buckets\n\t* @param name A unique name for the bucket you are creating\n\t* @returns Promise with response containing newly created analytics bucket or error\n\t*\n\t* @example Create analytics bucket\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .analytics\n\t*   .createBucket('analytics-data')\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"name\": \"analytics-data\",\n\t*     \"type\": \"ANALYTICS\",\n\t*     \"format\": \"iceberg\",\n\t*     \"created_at\": \"2024-05-22T22:26:05.100Z\",\n\t*     \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync createBucket(name) {\n\t\tvar _this = this;\n\t\treturn _this.handleOperation(async () => {\n\t\t\treturn await post(_this.fetch, `${_this.url}/bucket`, { name }, { headers: _this.headers });\n\t\t});\n\t}\n\t/**\n\t* @alpha\n\t*\n\t* Retrieves the details of all Analytics Storage buckets within an existing project\n\t* Only returns buckets of type 'ANALYTICS'\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Analytics Buckets\n\t* @param options Query parameters for listing buckets\n\t* @param options.limit Maximum number of buckets to return\n\t* @param options.offset Number of buckets to skip\n\t* @param options.sortColumn Column to sort by ('name', 'created_at', 'updated_at')\n\t* @param options.sortOrder Sort order ('asc' or 'desc')\n\t* @param options.search Search term to filter bucket names\n\t* @returns Promise with response containing array of analytics buckets or error\n\t*\n\t* @example List analytics buckets\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .analytics\n\t*   .listBuckets({\n\t*     limit: 10,\n\t*     offset: 0,\n\t*     sortColumn: 'created_at',\n\t*     sortOrder: 'desc'\n\t*   })\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": [\n\t*     {\n\t*       \"name\": \"analytics-data\",\n\t*       \"type\": \"ANALYTICS\",\n\t*       \"format\": \"iceberg\",\n\t*       \"created_at\": \"2024-05-22T22:26:05.100Z\",\n\t*       \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n\t*     }\n\t*   ],\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync listBuckets(options) {\n\t\tvar _this2 = this;\n\t\treturn _this2.handleOperation(async () => {\n\t\t\tconst queryParams = new URLSearchParams();\n\t\t\tif ((options === null || options === void 0 ? void 0 : options.limit) !== void 0) queryParams.set(\"limit\", options.limit.toString());\n\t\t\tif ((options === null || options === void 0 ? void 0 : options.offset) !== void 0) queryParams.set(\"offset\", options.offset.toString());\n\t\t\tif (options === null || options === void 0 ? void 0 : options.sortColumn) queryParams.set(\"sortColumn\", options.sortColumn);\n\t\t\tif (options === null || options === void 0 ? void 0 : options.sortOrder) queryParams.set(\"sortOrder\", options.sortOrder);\n\t\t\tif (options === null || options === void 0 ? void 0 : options.search) queryParams.set(\"search\", options.search);\n\t\t\tconst queryString = queryParams.toString();\n\t\t\tconst url = queryString ? `${_this2.url}/bucket?${queryString}` : `${_this2.url}/bucket`;\n\t\t\treturn await get(_this2.fetch, url, { headers: _this2.headers });\n\t\t});\n\t}\n\t/**\n\t* @alpha\n\t*\n\t* Deletes an existing analytics bucket\n\t* A bucket can't be deleted with existing objects inside it\n\t* You must first empty the bucket before deletion\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Analytics Buckets\n\t* @param bucketName The unique identifier of the bucket you would like to delete\n\t* @returns Promise with response containing success message or error\n\t*\n\t* @example Delete analytics bucket\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .analytics\n\t*   .deleteBucket('analytics-data')\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"message\": \"Successfully deleted\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync deleteBucket(bucketName) {\n\t\tvar _this3 = this;\n\t\treturn _this3.handleOperation(async () => {\n\t\t\treturn await remove(_this3.fetch, `${_this3.url}/bucket/${bucketName}`, {}, { headers: _this3.headers });\n\t\t});\n\t}\n\t/**\n\t* @alpha\n\t*\n\t* Get an Iceberg REST Catalog client configured for a specific analytics bucket\n\t* Use this to perform advanced table and namespace operations within the bucket\n\t* The returned client provides full access to the Apache Iceberg REST Catalog API\n\t* with the Supabase `{ data, error }` pattern for consistent error handling on all operations.\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Analytics Buckets\n\t* @param bucketName - The name of the analytics bucket (warehouse) to connect to\n\t* @returns The wrapped Iceberg catalog client\n\t* @throws {StorageError} If the bucket name is invalid\n\t*\n\t* @example Get catalog and create table\n\t* ```js\n\t* // First, create an analytics bucket\n\t* const { data: bucket, error: bucketError } = await supabase\n\t*   .storage\n\t*   .analytics\n\t*   .createBucket('analytics-data')\n\t*\n\t* // Get the Iceberg catalog for that bucket\n\t* const catalog = supabase.storage.analytics.from('analytics-data')\n\t*\n\t* // Create a namespace\n\t* const { error: nsError } = await catalog.createNamespace({ namespace: ['default'] })\n\t*\n\t* // Create a table with schema\n\t* const { data: tableMetadata, error: tableError } = await catalog.createTable(\n\t*   { namespace: ['default'] },\n\t*   {\n\t*     name: 'events',\n\t*     schema: {\n\t*       type: 'struct',\n\t*       fields: [\n\t*         { id: 1, name: 'id', type: 'long', required: true },\n\t*         { id: 2, name: 'timestamp', type: 'timestamp', required: true },\n\t*         { id: 3, name: 'user_id', type: 'string', required: false }\n\t*       ],\n\t*       'schema-id': 0,\n\t*       'identifier-field-ids': [1]\n\t*     },\n\t*     'partition-spec': {\n\t*       'spec-id': 0,\n\t*       fields: []\n\t*     },\n\t*     'write-order': {\n\t*       'order-id': 0,\n\t*       fields: []\n\t*     },\n\t*     properties: {\n\t*       'write.format.default': 'parquet'\n\t*     }\n\t*   }\n\t* )\n\t* ```\n\t*\n\t* @example List tables in namespace\n\t* ```js\n\t* const catalog = supabase.storage.analytics.from('analytics-data')\n\t*\n\t* // List all tables in the default namespace\n\t* const { data: tables, error: listError } = await catalog.listTables({ namespace: ['default'] })\n\t* if (listError) {\n\t*   if (listError.isNotFound()) {\n\t*     console.log('Namespace not found')\n\t*   }\n\t*   return\n\t* }\n\t* console.log(tables) // [{ namespace: ['default'], name: 'events' }]\n\t* ```\n\t*\n\t* @example Working with namespaces\n\t* ```js\n\t* const catalog = supabase.storage.analytics.from('analytics-data')\n\t*\n\t* // List all namespaces\n\t* const { data: namespaces } = await catalog.listNamespaces()\n\t*\n\t* // Create namespace with properties\n\t* await catalog.createNamespace(\n\t*   { namespace: ['production'] },\n\t*   { properties: { owner: 'data-team', env: 'prod' } }\n\t* )\n\t* ```\n\t*\n\t* @example Cleanup operations\n\t* ```js\n\t* const catalog = supabase.storage.analytics.from('analytics-data')\n\t*\n\t* // Drop table with purge option (removes all data)\n\t* const { error: dropError } = await catalog.dropTable(\n\t*   { namespace: ['default'], name: 'events' },\n\t*   { purge: true }\n\t* )\n\t*\n\t* if (dropError?.isNotFound()) {\n\t*   console.log('Table does not exist')\n\t* }\n\t*\n\t* // Drop namespace (must be empty)\n\t* await catalog.dropNamespace({ namespace: ['default'] })\n\t* ```\n\t*\n\t* @remarks\n\t* This method provides a bridge between Supabase's bucket management and the standard\n\t* Apache Iceberg REST Catalog API. The bucket name maps to the Iceberg warehouse parameter.\n\t* All authentication and configuration is handled automatically using your Supabase credentials.\n\t*\n\t* **Error Handling**: Invalid bucket names throw immediately. All catalog\n\t* operations return `{ data, error }` where errors are `IcebergError` instances from iceberg-js.\n\t* Use helper methods like `error.isNotFound()` or check `error.status` for specific error handling.\n\t* Use `.throwOnError()` on the analytics client if you prefer exceptions for catalog operations.\n\t*\n\t* **Cleanup Operations**: When using `dropTable`, the `purge: true` option permanently\n\t* deletes all table data. Without it, the table is marked as deleted but data remains.\n\t*\n\t* **Library Dependency**: The returned catalog wraps `IcebergRestCatalog` from iceberg-js.\n\t* For complete API documentation and advanced usage, refer to the\n\t* [iceberg-js documentation](https://supabase.github.io/iceberg-js/).\n\t*/\n\tfrom(bucketName) {\n\t\tvar _this4 = this;\n\t\tif (!isValidBucketName(bucketName)) throw new StorageError(\"Invalid bucket name: File, folder, and bucket names must follow AWS object key naming guidelines and should avoid the use of any other characters.\");\n\t\tconst catalog = new iceberg_js.IcebergRestCatalog({\n\t\t\tbaseUrl: this.url,\n\t\t\tcatalogName: bucketName,\n\t\t\tauth: {\n\t\t\t\ttype: \"custom\",\n\t\t\t\tgetHeaders: async () => _this4.headers\n\t\t\t},\n\t\t\tfetch: this.fetch\n\t\t});\n\t\tconst shouldThrowOnError = this.shouldThrowOnError;\n\t\treturn new Proxy(catalog, { get(target, prop) {\n\t\t\tconst value = target[prop];\n\t\t\tif (typeof value !== \"function\") return value;\n\t\t\treturn async (...args) => {\n\t\t\t\ttry {\n\t\t\t\t\treturn {\n\t\t\t\t\t\tdata: await value.apply(target, args),\n\t\t\t\t\t\terror: null\n\t\t\t\t\t};\n\t\t\t\t} catch (error) {\n\t\t\t\t\tif (shouldThrowOnError) throw error;\n\t\t\t\t\treturn {\n\t\t\t\t\t\tdata: null,\n\t\t\t\t\t\terror\n\t\t\t\t\t};\n\t\t\t\t}\n\t\t\t};\n\t\t} });\n\t}\n};\n\n//#endregion\n//#region src/packages/VectorIndexApi.ts\n/**\n* @hidden\n* Base implementation for vector index operations.\n* Use {@link VectorBucketScope} via `supabase.storage.vectors.from('bucket')` instead.\n*/\nvar VectorIndexApi = class extends BaseApiClient {\n\t/** Creates a new VectorIndexApi instance */\n\tconstructor(url, headers = {}, fetch$1) {\n\t\tconst finalUrl = url.replace(/\\/$/, \"\");\n\t\tconst finalHeaders = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), {}, { \"Content-Type\": \"application/json\" }, headers);\n\t\tsuper(finalUrl, finalHeaders, fetch$1, \"vectors\");\n\t}\n\t/** Creates a new vector index within a bucket */\n\tasync createIndex(options) {\n\t\tvar _this = this;\n\t\treturn _this.handleOperation(async () => {\n\t\t\treturn await vectorsApi.post(_this.fetch, `${_this.url}/CreateIndex`, options, { headers: _this.headers }) || {};\n\t\t});\n\t}\n\t/** Retrieves metadata for a specific vector index */\n\tasync getIndex(vectorBucketName, indexName) {\n\t\tvar _this2 = this;\n\t\treturn _this2.handleOperation(async () => {\n\t\t\treturn await vectorsApi.post(_this2.fetch, `${_this2.url}/GetIndex`, {\n\t\t\t\tvectorBucketName,\n\t\t\t\tindexName\n\t\t\t}, { headers: _this2.headers });\n\t\t});\n\t}\n\t/** Lists vector indexes within a bucket with optional filtering and pagination */\n\tasync listIndexes(options) {\n\t\tvar _this3 = this;\n\t\treturn _this3.handleOperation(async () => {\n\t\t\treturn await vectorsApi.post(_this3.fetch, `${_this3.url}/ListIndexes`, options, { headers: _this3.headers });\n\t\t});\n\t}\n\t/** Deletes a vector index and all its data */\n\tasync deleteIndex(vectorBucketName, indexName) {\n\t\tvar _this4 = this;\n\t\treturn _this4.handleOperation(async () => {\n\t\t\treturn await vectorsApi.post(_this4.fetch, `${_this4.url}/DeleteIndex`, {\n\t\t\t\tvectorBucketName,\n\t\t\t\tindexName\n\t\t\t}, { headers: _this4.headers }) || {};\n\t\t});\n\t}\n};\n\n//#endregion\n//#region src/packages/VectorDataApi.ts\n/**\n* @hidden\n* Base implementation for vector data operations.\n* Use {@link VectorIndexScope} via `supabase.storage.vectors.from('bucket').index('idx')` instead.\n*/\nvar VectorDataApi = class extends BaseApiClient {\n\t/** Creates a new VectorDataApi instance */\n\tconstructor(url, headers = {}, fetch$1) {\n\t\tconst finalUrl = url.replace(/\\/$/, \"\");\n\t\tconst finalHeaders = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), {}, { \"Content-Type\": \"application/json\" }, headers);\n\t\tsuper(finalUrl, finalHeaders, fetch$1, \"vectors\");\n\t}\n\t/** Inserts or updates vectors in batch (1-500 per request) */\n\tasync putVectors(options) {\n\t\tvar _this = this;\n\t\tif (options.vectors.length < 1 || options.vectors.length > 500) throw new Error(\"Vector batch size must be between 1 and 500 items\");\n\t\treturn _this.handleOperation(async () => {\n\t\t\treturn await vectorsApi.post(_this.fetch, `${_this.url}/PutVectors`, options, { headers: _this.headers }) || {};\n\t\t});\n\t}\n\t/** Retrieves vectors by their keys in batch */\n\tasync getVectors(options) {\n\t\tvar _this2 = this;\n\t\treturn _this2.handleOperation(async () => {\n\t\t\treturn await vectorsApi.post(_this2.fetch, `${_this2.url}/GetVectors`, options, { headers: _this2.headers });\n\t\t});\n\t}\n\t/** Lists vectors in an index with pagination */\n\tasync listVectors(options) {\n\t\tvar _this3 = this;\n\t\tif (options.segmentCount !== void 0) {\n\t\t\tif (options.segmentCount < 1 || options.segmentCount > 16) throw new Error(\"segmentCount must be between 1 and 16\");\n\t\t\tif (options.segmentIndex !== void 0) {\n\t\t\t\tif (options.segmentIndex < 0 || options.segmentIndex >= options.segmentCount) throw new Error(`segmentIndex must be between 0 and ${options.segmentCount - 1}`);\n\t\t\t}\n\t\t}\n\t\treturn _this3.handleOperation(async () => {\n\t\t\treturn await vectorsApi.post(_this3.fetch, `${_this3.url}/ListVectors`, options, { headers: _this3.headers });\n\t\t});\n\t}\n\t/** Queries for similar vectors using approximate nearest neighbor search */\n\tasync queryVectors(options) {\n\t\tvar _this4 = this;\n\t\treturn _this4.handleOperation(async () => {\n\t\t\treturn await vectorsApi.post(_this4.fetch, `${_this4.url}/QueryVectors`, options, { headers: _this4.headers });\n\t\t});\n\t}\n\t/** Deletes vectors by their keys in batch (1-500 per request) */\n\tasync deleteVectors(options) {\n\t\tvar _this5 = this;\n\t\tif (options.keys.length < 1 || options.keys.length > 500) throw new Error(\"Keys batch size must be between 1 and 500 items\");\n\t\treturn _this5.handleOperation(async () => {\n\t\t\treturn await vectorsApi.post(_this5.fetch, `${_this5.url}/DeleteVectors`, options, { headers: _this5.headers }) || {};\n\t\t});\n\t}\n};\n\n//#endregion\n//#region src/packages/VectorBucketApi.ts\n/**\n* @hidden\n* Base implementation for vector bucket operations.\n* Use {@link StorageVectorsClient} via `supabase.storage.vectors` instead.\n*/\nvar VectorBucketApi = class extends BaseApiClient {\n\t/** Creates a new VectorBucketApi instance */\n\tconstructor(url, headers = {}, fetch$1) {\n\t\tconst finalUrl = url.replace(/\\/$/, \"\");\n\t\tconst finalHeaders = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), {}, { \"Content-Type\": \"application/json\" }, headers);\n\t\tsuper(finalUrl, finalHeaders, fetch$1, \"vectors\");\n\t}\n\t/** Creates a new vector bucket */\n\tasync createBucket(vectorBucketName) {\n\t\tvar _this = this;\n\t\treturn _this.handleOperation(async () => {\n\t\t\treturn await vectorsApi.post(_this.fetch, `${_this.url}/CreateVectorBucket`, { vectorBucketName }, { headers: _this.headers }) || {};\n\t\t});\n\t}\n\t/** Retrieves metadata for a specific vector bucket */\n\tasync getBucket(vectorBucketName) {\n\t\tvar _this2 = this;\n\t\treturn _this2.handleOperation(async () => {\n\t\t\treturn await vectorsApi.post(_this2.fetch, `${_this2.url}/GetVectorBucket`, { vectorBucketName }, { headers: _this2.headers });\n\t\t});\n\t}\n\t/** Lists vector buckets with optional filtering and pagination */\n\tasync listBuckets(options = {}) {\n\t\tvar _this3 = this;\n\t\treturn _this3.handleOperation(async () => {\n\t\t\treturn await vectorsApi.post(_this3.fetch, `${_this3.url}/ListVectorBuckets`, options, { headers: _this3.headers });\n\t\t});\n\t}\n\t/** Deletes a vector bucket (must be empty first) */\n\tasync deleteBucket(vectorBucketName) {\n\t\tvar _this4 = this;\n\t\treturn _this4.handleOperation(async () => {\n\t\t\treturn await vectorsApi.post(_this4.fetch, `${_this4.url}/DeleteVectorBucket`, { vectorBucketName }, { headers: _this4.headers }) || {};\n\t\t});\n\t}\n};\n\n//#endregion\n//#region src/packages/StorageVectorsClient.ts\n/**\n*\n* @alpha\n*\n* Main client for interacting with S3 Vectors API\n* Provides access to bucket, index, and vector data operations\n*\n* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n*\n* **Usage Patterns:**\n*\n* ```typescript\n* const { data, error } = await supabase\n*  .storage\n*  .vectors\n*  .createBucket('embeddings-prod')\n*\n* // Access index operations via buckets\n* const bucket = supabase.storage.vectors.from('embeddings-prod')\n* await bucket.createIndex({\n*   indexName: 'documents',\n*   dataType: 'float32',\n*   dimension: 1536,\n*   distanceMetric: 'cosine'\n* })\n*\n* // Access vector operations via index\n* const index = bucket.index('documents')\n* await index.putVectors({\n*   vectors: [\n*     { key: 'doc-1', data: { float32: [...] }, metadata: { title: 'Intro' } }\n*   ]\n* })\n*\n* // Query similar vectors\n* const { data } = await index.queryVectors({\n*   queryVector: { float32: [...] },\n*   topK: 5,\n*   returnDistance: true\n* })\n* ```\n*/\nvar StorageVectorsClient = class extends VectorBucketApi {\n\t/**\n\t* @alpha\n\t*\n\t* Creates a StorageVectorsClient that can manage buckets, indexes, and vectors.\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param url - Base URL of the Storage Vectors REST API.\n\t* @param options.headers - Optional headers (for example `Authorization`) applied to every request.\n\t* @param options.fetch - Optional custom `fetch` implementation for non-browser runtimes.\n\t*\n\t* @example\n\t* ```typescript\n\t* const client = new StorageVectorsClient(url, options)\n\t* ```\n\t*/\n\tconstructor(url, options = {}) {\n\t\tsuper(url, options.headers || {}, options.fetch);\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Access operations for a specific vector bucket\n\t* Returns a scoped client for index and vector operations within the bucket\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param vectorBucketName - Name of the vector bucket\n\t* @returns Bucket-scoped client with index and vector operations\n\t*\n\t* @example\n\t* ```typescript\n\t* const bucket = supabase.storage.vectors.from('embeddings-prod')\n\t* ```\n\t*/\n\tfrom(vectorBucketName) {\n\t\treturn new VectorBucketScope(this.url, this.headers, vectorBucketName, this.fetch);\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Creates a new vector bucket\n\t* Vector buckets are containers for vector indexes and their data\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param vectorBucketName - Unique name for the vector bucket\n\t* @returns Promise with empty response on success or error\n\t*\n\t* @example\n\t* ```typescript\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .vectors\n\t*   .createBucket('embeddings-prod')\n\t* ```\n\t*/\n\tasync createBucket(vectorBucketName) {\n\t\tvar _superprop_getCreateBucket = () => super.createBucket, _this = this;\n\t\treturn _superprop_getCreateBucket().call(_this, vectorBucketName);\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Retrieves metadata for a specific vector bucket\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param vectorBucketName - Name of the vector bucket\n\t* @returns Promise with bucket metadata or error\n\t*\n\t* @example\n\t* ```typescript\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .vectors\n\t*   .getBucket('embeddings-prod')\n\t*\n\t* console.log('Bucket created:', data?.vectorBucket.creationTime)\n\t* ```\n\t*/\n\tasync getBucket(vectorBucketName) {\n\t\tvar _superprop_getGetBucket = () => super.getBucket, _this2 = this;\n\t\treturn _superprop_getGetBucket().call(_this2, vectorBucketName);\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Lists all vector buckets with optional filtering and pagination\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param options - Optional filters (prefix, maxResults, nextToken)\n\t* @returns Promise with list of buckets or error\n\t*\n\t* @example\n\t* ```typescript\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .vectors\n\t*   .listBuckets({ prefix: 'embeddings-' })\n\t*\n\t* data?.vectorBuckets.forEach(bucket => {\n\t*   console.log(bucket.vectorBucketName)\n\t* })\n\t* ```\n\t*/\n\tasync listBuckets(options = {}) {\n\t\tvar _superprop_getListBuckets = () => super.listBuckets, _this3 = this;\n\t\treturn _superprop_getListBuckets().call(_this3, options);\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Deletes a vector bucket (bucket must be empty)\n\t* All indexes must be deleted before deleting the bucket\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param vectorBucketName - Name of the vector bucket to delete\n\t* @returns Promise with empty response on success or error\n\t*\n\t* @example\n\t* ```typescript\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .vectors\n\t*   .deleteBucket('embeddings-old')\n\t* ```\n\t*/\n\tasync deleteBucket(vectorBucketName) {\n\t\tvar _superprop_getDeleteBucket = () => super.deleteBucket, _this4 = this;\n\t\treturn _superprop_getDeleteBucket().call(_this4, vectorBucketName);\n\t}\n};\n/**\n*\n* @alpha\n*\n* Scoped client for operations within a specific vector bucket\n* Provides index management and access to vector operations\n*\n* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n*/\nvar VectorBucketScope = class extends VectorIndexApi {\n\t/**\n\t* @alpha\n\t*\n\t* Creates a helper that automatically scopes all index operations to the provided bucket.\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @example\n\t* ```typescript\n\t* const bucket = supabase.storage.vectors.from('embeddings-prod')\n\t* ```\n\t*/\n\tconstructor(url, headers, vectorBucketName, fetch$1) {\n\t\tsuper(url, headers, fetch$1);\n\t\tthis.vectorBucketName = vectorBucketName;\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Creates a new vector index in this bucket\n\t* Convenience method that automatically includes the bucket name\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param options - Index configuration (vectorBucketName is automatically set)\n\t* @returns Promise with empty response on success or error\n\t*\n\t* @example\n\t* ```typescript\n\t* const bucket = supabase.storage.vectors.from('embeddings-prod')\n\t* await bucket.createIndex({\n\t*   indexName: 'documents-openai',\n\t*   dataType: 'float32',\n\t*   dimension: 1536,\n\t*   distanceMetric: 'cosine',\n\t*   metadataConfiguration: {\n\t*     nonFilterableMetadataKeys: ['raw_text']\n\t*   }\n\t* })\n\t* ```\n\t*/\n\tasync createIndex(options) {\n\t\tvar _superprop_getCreateIndex = () => super.createIndex, _this5 = this;\n\t\treturn _superprop_getCreateIndex().call(_this5, _objectSpread2(_objectSpread2({}, options), {}, { vectorBucketName: _this5.vectorBucketName }));\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Lists indexes in this bucket\n\t* Convenience method that automatically includes the bucket name\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param options - Listing options (vectorBucketName is automatically set)\n\t* @returns Promise with response containing indexes array and pagination token or error\n\t*\n\t* @example\n\t* ```typescript\n\t* const bucket = supabase.storage.vectors.from('embeddings-prod')\n\t* const { data } = await bucket.listIndexes({ prefix: 'documents-' })\n\t* ```\n\t*/\n\tasync listIndexes(options = {}) {\n\t\tvar _superprop_getListIndexes = () => super.listIndexes, _this6 = this;\n\t\treturn _superprop_getListIndexes().call(_this6, _objectSpread2(_objectSpread2({}, options), {}, { vectorBucketName: _this6.vectorBucketName }));\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Retrieves metadata for a specific index in this bucket\n\t* Convenience method that automatically includes the bucket name\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param indexName - Name of the index to retrieve\n\t* @returns Promise with index metadata or error\n\t*\n\t* @example\n\t* ```typescript\n\t* const bucket = supabase.storage.vectors.from('embeddings-prod')\n\t* const { data } = await bucket.getIndex('documents-openai')\n\t* console.log('Dimension:', data?.index.dimension)\n\t* ```\n\t*/\n\tasync getIndex(indexName) {\n\t\tvar _superprop_getGetIndex = () => super.getIndex, _this7 = this;\n\t\treturn _superprop_getGetIndex().call(_this7, _this7.vectorBucketName, indexName);\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Deletes an index from this bucket\n\t* Convenience method that automatically includes the bucket name\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param indexName - Name of the index to delete\n\t* @returns Promise with empty response on success or error\n\t*\n\t* @example\n\t* ```typescript\n\t* const bucket = supabase.storage.vectors.from('embeddings-prod')\n\t* await bucket.deleteIndex('old-index')\n\t* ```\n\t*/\n\tasync deleteIndex(indexName) {\n\t\tvar _superprop_getDeleteIndex = () => super.deleteIndex, _this8 = this;\n\t\treturn _superprop_getDeleteIndex().call(_this8, _this8.vectorBucketName, indexName);\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Access operations for a specific index within this bucket\n\t* Returns a scoped client for vector data operations\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param indexName - Name of the index\n\t* @returns Index-scoped client with vector data operations\n\t*\n\t* @example\n\t* ```typescript\n\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n\t*\n\t* // Insert vectors\n\t* await index.putVectors({\n\t*   vectors: [\n\t*     { key: 'doc-1', data: { float32: [...] }, metadata: { title: 'Intro' } }\n\t*   ]\n\t* })\n\t*\n\t* // Query similar vectors\n\t* const { data } = await index.queryVectors({\n\t*   queryVector: { float32: [...] },\n\t*   topK: 5\n\t* })\n\t* ```\n\t*/\n\tindex(indexName) {\n\t\treturn new VectorIndexScope(this.url, this.headers, this.vectorBucketName, indexName, this.fetch);\n\t}\n};\n/**\n*\n* @alpha\n*\n* Scoped client for operations within a specific vector index\n* Provides vector data operations (put, get, list, query, delete)\n*\n* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n*/\nvar VectorIndexScope = class extends VectorDataApi {\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Creates a helper that automatically scopes all vector operations to the provided bucket/index names.\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @example\n\t* ```typescript\n\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n\t* ```\n\t*/\n\tconstructor(url, headers, vectorBucketName, indexName, fetch$1) {\n\t\tsuper(url, headers, fetch$1);\n\t\tthis.vectorBucketName = vectorBucketName;\n\t\tthis.indexName = indexName;\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Inserts or updates vectors in this index\n\t* Convenience method that automatically includes bucket and index names\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param options - Vector insertion options (bucket and index names automatically set)\n\t* @returns Promise with empty response on success or error\n\t*\n\t* @example\n\t* ```typescript\n\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n\t* await index.putVectors({\n\t*   vectors: [\n\t*     {\n\t*       key: 'doc-1',\n\t*       data: { float32: [0.1, 0.2, ...] },\n\t*       metadata: { title: 'Introduction', page: 1 }\n\t*     }\n\t*   ]\n\t* })\n\t* ```\n\t*/\n\tasync putVectors(options) {\n\t\tvar _superprop_getPutVectors = () => super.putVectors, _this9 = this;\n\t\treturn _superprop_getPutVectors().call(_this9, _objectSpread2(_objectSpread2({}, options), {}, {\n\t\t\tvectorBucketName: _this9.vectorBucketName,\n\t\t\tindexName: _this9.indexName\n\t\t}));\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Retrieves vectors by keys from this index\n\t* Convenience method that automatically includes bucket and index names\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param options - Vector retrieval options (bucket and index names automatically set)\n\t* @returns Promise with response containing vectors array or error\n\t*\n\t* @example\n\t* ```typescript\n\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n\t* const { data } = await index.getVectors({\n\t*   keys: ['doc-1', 'doc-2'],\n\t*   returnMetadata: true\n\t* })\n\t* ```\n\t*/\n\tasync getVectors(options) {\n\t\tvar _superprop_getGetVectors = () => super.getVectors, _this10 = this;\n\t\treturn _superprop_getGetVectors().call(_this10, _objectSpread2(_objectSpread2({}, options), {}, {\n\t\t\tvectorBucketName: _this10.vectorBucketName,\n\t\t\tindexName: _this10.indexName\n\t\t}));\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Lists vectors in this index with pagination\n\t* Convenience method that automatically includes bucket and index names\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param options - Listing options (bucket and index names automatically set)\n\t* @returns Promise with response containing vectors array and pagination token or error\n\t*\n\t* @example\n\t* ```typescript\n\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n\t* const { data } = await index.listVectors({\n\t*   maxResults: 500,\n\t*   returnMetadata: true\n\t* })\n\t* ```\n\t*/\n\tasync listVectors(options = {}) {\n\t\tvar _superprop_getListVectors = () => super.listVectors, _this11 = this;\n\t\treturn _superprop_getListVectors().call(_this11, _objectSpread2(_objectSpread2({}, options), {}, {\n\t\t\tvectorBucketName: _this11.vectorBucketName,\n\t\t\tindexName: _this11.indexName\n\t\t}));\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Queries for similar vectors in this index\n\t* Convenience method that automatically includes bucket and index names\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param options - Query options (bucket and index names automatically set)\n\t* @returns Promise with response containing matches array of similar vectors ordered by distance or error\n\t*\n\t* @example\n\t* ```typescript\n\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n\t* const { data } = await index.queryVectors({\n\t*   queryVector: { float32: [0.1, 0.2, ...] },\n\t*   topK: 5,\n\t*   filter: { category: 'technical' },\n\t*   returnDistance: true,\n\t*   returnMetadata: true\n\t* })\n\t* ```\n\t*/\n\tasync queryVectors(options) {\n\t\tvar _superprop_getQueryVectors = () => super.queryVectors, _this12 = this;\n\t\treturn _superprop_getQueryVectors().call(_this12, _objectSpread2(_objectSpread2({}, options), {}, {\n\t\t\tvectorBucketName: _this12.vectorBucketName,\n\t\t\tindexName: _this12.indexName\n\t\t}));\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Deletes vectors by keys from this index\n\t* Convenience method that automatically includes bucket and index names\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param options - Deletion options (bucket and index names automatically set)\n\t* @returns Promise with empty response on success or error\n\t*\n\t* @example\n\t* ```typescript\n\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n\t* await index.deleteVectors({\n\t*   keys: ['doc-1', 'doc-2', 'doc-3']\n\t* })\n\t* ```\n\t*/\n\tasync deleteVectors(options) {\n\t\tvar _superprop_getDeleteVectors = () => super.deleteVectors, _this13 = this;\n\t\treturn _superprop_getDeleteVectors().call(_this13, _objectSpread2(_objectSpread2({}, options), {}, {\n\t\t\tvectorBucketName: _this13.vectorBucketName,\n\t\t\tindexName: _this13.indexName\n\t\t}));\n\t}\n};\n\n//#endregion\n//#region src/StorageClient.ts\nvar StorageClient = class extends StorageBucketApi {\n\t/**\n\t* Creates a client for Storage buckets, files, analytics, and vectors.\n\t*\n\t* @category File Buckets\n\t* @example\n\t* ```ts\n\t* import { StorageClient } from '@supabase/storage-js'\n\t*\n\t* const storage = new StorageClient('https://xyzcompany.supabase.co/storage/v1', {\n\t*   apikey: 'public-anon-key',\n\t* })\n\t* const avatars = storage.from('avatars')\n\t* ```\n\t*/\n\tconstructor(url, headers = {}, fetch$1, opts) {\n\t\tsuper(url, headers, fetch$1, opts);\n\t}\n\t/**\n\t* Perform file operation in a bucket.\n\t*\n\t* @category File Buckets\n\t* @param id The bucket id to operate on.\n\t*\n\t* @example\n\t* ```typescript\n\t* const avatars = supabase.storage.from('avatars')\n\t* ```\n\t*/\n\tfrom(id) {\n\t\treturn new StorageFileApi(this.url, this.headers, id, this.fetch);\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Access vector storage operations.\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @returns A StorageVectorsClient instance configured with the current storage settings.\n\t*/\n\tget vectors() {\n\t\treturn new StorageVectorsClient(this.url + \"/vector\", {\n\t\t\theaders: this.headers,\n\t\t\tfetch: this.fetch\n\t\t});\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Access analytics storage operations using Iceberg tables.\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Analytics Buckets\n\t* @returns A StorageAnalyticsClient instance configured with the current storage settings.\n\t*/\n\tget analytics() {\n\t\treturn new StorageAnalyticsClient(this.url + \"/iceberg\", this.headers, this.fetch);\n\t}\n};\n\n//#endregion\nexports.StorageAnalyticsClient = StorageAnalyticsClient;\nexports.StorageApiError = StorageApiError;\nexports.StorageClient = StorageClient;\nexports.StorageError = StorageError;\nexports.StorageUnknownError = StorageUnknownError;\nexports.StorageVectorsApiError = StorageVectorsApiError;\nexports.StorageVectorsClient = StorageVectorsClient;\nexports.StorageVectorsError = StorageVectorsError;\nexports.StorageVectorsErrorCode = StorageVectorsErrorCode;\nexports.StorageVectorsUnknownError = StorageVectorsUnknownError;\nexports.VectorBucketApi = VectorBucketApi;\nexports.VectorBucketScope = VectorBucketScope;\nexports.VectorDataApi = VectorDataApi;\nexports.VectorIndexApi = VectorIndexApi;\nexports.VectorIndexScope = VectorIndexScope;\nexports.isStorageError = isStorageError;\nexports.isStorageVectorsError = isStorageVectorsError;\n//# sourceMappingURL=index.cjs.map\n};","~:removed-requires",["~#set",[]],"~:actual-requires",["^5",["~$shadow.js","~$module$node_modules$iceberg_js$dist$index_cjs","~$module$node_modules$buffer$index"]],"~:properties",["^5",["sortBy","message","destinationKey","VectorBucketScope","fetch","promise","hostname","noResolveJson","StorageVectorsErrorCode","url","VectorIndexScope","token","indexName","__isStorageError","body","prefixes","StorageVectorsUnknownError","offset","originalError","vectorBucketName","isStorageVectorsError","prefix","put","StorageVectorsError","VectorDataApi","duplex","method","catalogName","file_size_limit","auth","path","StorageAnalyticsClient","destinationBucket","error","id","upsert","transform","post","fullPath","paths","name","configurable","limit","value","StorageVectorsClient","enumerable","baseUrl","statusCode","VectorBucketApi","status","sourceKey","remove","writable","StorageError","shouldThrowOnError","sortColumn","StorageApiError","StorageClient","head","isStorageError","order","column","StorageUnknownError","StorageVectorsApiError","publicUrl","type","downloadFn","cacheControl","public","contentType","allowed_mime_types","sortOrder","signedUrl","namespace","expiresIn","search","data","get","bucketId","VectorIndexApi","getHeaders","headers"]],"~:compiled-at",1771981597325,"~:source-map-json","{\n\"version\":3,\n\"file\":\"module$node_modules$$supabase$storage_js$dist$index_cjs.js\",\n\"lineCount\":691,\n\"mappings\":\"AAAAA,cAAA,CAAA,uDAAA,GAA4E,QAAQ,CAACC,OAAD,EAASC,MAAT,EAAgBC,OAAhB,CAAyB;AAwB7GC,UAASA,eAAc,CAACC,KAAD,CAAQ;AAC9B,WAAO,MAAOA,MAAd,KAAwB,QAAxB,IAAoCA,KAApC,KAA8C,IAA9C,IAAsD,kBAAtD,IAA4EA,KAA5E;AAD8B;AA6J/BC,UAASA,QAAO,CAACC,CAAD,CAAI;AACnB,6BAAA;AACA,WAAOD,OAAA,GAAU,UAAA,IAAc,MAAOE,OAArB,IAA+B,QAA/B,IAA2C,MAAOA,OAAOC,CAAAA,QAAzD,GAAoE,QAAQ,CAACC,GAAD,CAAM;AAClG,aAAO,MAAOA,IAAd;AADkG,KAAlF,GAEb,QAAQ,CAACA,GAAD,CAAM;AACjB,aAAOA,GAAA,IAAO,UAAP,IAAqB,MAAOF,OAA5B,IAAsCE,GAAIC,CAAAA,WAA1C,KAA0DH,MAA1D,IAAoEE,GAApE,KAA4EF,MAAOI,CAAAA,SAAnF,GAA+F,QAA/F,GAA0G,MAAOF,IAAxH;AADiB,KAFX,EAIJJ,OAAA,CAAQC,CAAR,CAJH;AAFmB;AA0CpBM,UAASA,QAAO,CAACC,CAAD,EAAIC,CAAJ,CAAO;AACtB,QAAIC,IAAIC,MAAOC,CAAAA,IAAP,CAAYJ,CAAZ,CAAR;AACA,QAAIG,MAAOE,CAAAA,qBAAX,CAAkC;AACjC,UAAIZ,IAAIU,MAAOE,CAAAA,qBAAP,CAA6BL,CAA7B,CAAR;AACAC,OAAA,KAAMR,CAAN,GAAUA,CAAEa,CAAAA,MAAF,CAAS,QAAQ,CAACC,GAAD,CAAM;AAChC,eAAOJ,MAAOK,CAAAA,wBAAP,CAAgCR,CAAhC,EAAmCO,GAAnC,CAAwCE,CAAAA,UAA/C;AADgC,OAAvB,CAAV;AAEKP,OAAEQ,CAAAA,IAAKC,CAAAA,KAAP,CAAaT,CAAb,EAAgBT,CAAhB,CAAA;AAJ4B;AAMlC,WAAOS,CAAP;AARsB;AAUvBU,UAASA,eAAc,CAACZ,UAAD,CAAI;AAC1B,SAAK,IAAIC,IAAI,CAAb,EAAgBA,CAAhB,GAAoBY,SAAUC,CAAAA,MAA9B,EAAsCb,CAAA,EAAtC,CAA2C;AAC1C,UAAIC,aAAI,IAAA,IAAQW,SAAA,CAAUZ,CAAV,CAAR,GAAuBY,SAAA,CAAUZ,CAAV,CAAvB,GAAsC,EAA9C;AACAA,OAAA,GAAI,CAAJ,GAAQF,OAAA,CAAQI,MAAA,CAAOD,UAAP,CAAR,EAAmB,CAAA,CAAnB,CAAuBa,CAAAA,OAAvB,CAA+B,QAAQ,CAACR,GAAD,CAAM;AACjCA,YAAAA,CAAAA,EAAK,IAAAL,UAAA,CAAEK,GAAF,CAALA;AA7CK,SAAA;AAC1B,cAAI,QAAJ,IAAgBf,OAAA,CAAQU,GAAR,CAAhB,IAA+BA,GAA/B,CAAA;AACA,gBAAIF,IAAIE,GAAA,CAAER,MAAOsB,CAAAA,WAAT,CAAR;AACA,gBAAI,IAAK,EAAT,KAAehB,CAAf,CAAkB;AACbiB,iBAAAA,GAAIjB,CAAEkB,CAAAA,IAAF,CAAOhB,GAAP,EAUcD,QAVd,CAAJgB;AACJ,kBAAI,QAAJ,IAAgBzB,OAAA,CAAQyB,GAAR,CAAhB;AAA4B,sBAAA,CAAA;AAA5B;AACA,oBAAM,IAAIE,SAAJ,CAAc,8CAAd,CAAN;AAHiB;AAKlB,eAAA,GAAyBC,MAAlB,CAAmClB,GAAnC,CAAP;AAPA;AAD0B;AAqBnB,SAACD,CAAD,GANA,QAAA,IAAYT,OAAA,CAAQyB,GAAR,CAAZ,GAAyBA,GAAzB,GAA6BA,GAA7B,GAAiC,EAMjC,KAwBWjB,UAxBX,GAA8BG,MAAOkB,CAAAA,cAAP,CAwBnBrB,UAxBmB,EAAyBC,CAAzB,EAA4B,CAChEqB,MAAOpB,CADyD,EAEhEO,WAAY,CAAA,CAFoD,EAGhEc,aAAc,CAAA,CAHkD,EAIhEC,SAAU,CAAA,CAJsD,CAA5B,CAA9B,GAwBWxB,UAnBb,CAAEC,CAAF,CALE,GAKKC,CALL;AAuB+C,OAA7C,CAAR,GAEKC,MAAOsB,CAAAA,yBAAP,GAAmCtB,MAAOuB,CAAAA,gBAAP,CAAwB1B,UAAxB,EAA2BG,MAAOsB,CAAAA,yBAAP,CAAiCvB,UAAjC,CAA3B,CAAnC,GAAqGH,OAAA,CAAQI,MAAA,CAAOD,UAAP,CAAR,CAAmBa,CAAAA,OAAnB,CAA2B,QAAQ,CAACR,GAAD,CAAM;AAClJJ,cAAOkB,CAAAA,cAAP,CAAsBrB,UAAtB,EAAyBO,GAAzB,EAA8BJ,MAAOK,CAAAA,wBAAP,CAAgCN,UAAhC,EAAmCK,GAAnC,CAA9B,CAAA;AADkJ,OAAzC,CAF1G;AAF0C;AAQ3C,WAAOP,UAAP;AAT0B;AAoF3B2B,gBAAeA,eAAc,CAACC,OAAD,EAAUC,MAAV,EAAkBC,GAAlB,EAAuBC,OAAvB,EAAgCC,UAAhC,EAA4CC,IAA5C,EAAkDC,SAAlD,CAA6D;AACzF,WAAO,IAAIC,OAAJ,CAAY,CAACC,OAAD,EAAUC,MAAV,CAAA,IAAqB;AACvCT,aAAA,CAAQE,GAAR,EAAaQ,iBAAA,CAAkBT,MAAlB,EAA0BE,OAA1B,EAAmCC,UAAnC,EAA+CC,IAA/C,CAAb,CAAmEM,CAAAA,IAAnE,CAAyEC,MAAD,IAAY;AACnF,YAAI,CAACA,MAAOC,CAAAA,EAAZ;AAAgB,gBAAMD,MAAN;AAAhB;AACA,YAAIT,OAAA,KAAY,IAAZ,IAAoBA,OAApB,KAAgC,IAAK,EAArC,GAAyC,CAAzC,GAAkDA,OAAQW,CAAAA,aAA9D;AAA6E,iBAAOF,MAAP;AAA7E;AACA,YAAIN,SAAJ,KAAkB,SAAlB,CAA6B;AAC5B,gBAAMS,cAAcH,MAAOI,CAAAA,OAAQC,CAAAA,GAAf,CAAmB,cAAnB,CAApB;AAEA,cADIL,MAAOI,CAAAA,OAAQC,CAAAA,GAAf,CAAmB,gBAAnB,CACJ,KAD6C,GAC7C,IADoDL,MAAOM,CAAAA,MAC3D,KADsE,GACtE,IAAI,CAACH,WAAL,IAAoB,CAACA,WAAYI,CAAAA,QAAZ,CAAqB,kBAArB,CAArB;AAA+D,mBAAO,EAAP;AAA/D;AAH4B;AAK7B,eAAOP,MAAOQ,CAAAA,IAAP,EAAP;AARmF,OAApF,CASGT,CAAAA,IATH,CASSU,IAAD,IAAUb,OAAA,CAAQa,IAAR,CATlB,CASiCC,CAAAA,KATjC,CASwC3D,KAAD,IAAW4D,WAAA,CAAY5D,KAAZ,EAAmB8C,MAAnB,EAA2BN,OAA3B,EAAoCG,SAApC,CATlD,CAAA;AADuC,KAAjC,CAAP;AADyF;AAmB1FkB,UAASA,eAAc,CAAClB,SAAA,GAAY,SAAb,CAAwB;AAC9C,WAAO,CACNW,IAAKA,KAAM,CAACjB,OAAD,EAAUE,GAAV,EAAeC,OAAf,EAAwBC,UAAxB,CAANa,IACGlB,cAAA,CAAeC,OAAf,EAAwB,KAAxB,EAA+BE,GAA/B,EAAoCC,OAApC,EAA6CC,UAA7C,EAAyD,IAAK,EAA9D,EAAiEE,SAAjE,CAFF,EAINmB,KAAMA,KAAM,CAACzB,OAAD,EAAUE,GAAV,EAAeG,IAAf,EAAqBF,OAArB,EAA8BC,UAA9B,CAANqB,IACE1B,cAAA,CAAeC,OAAf,EAAwB,MAAxB,EAAgCE,GAAhC,EAAqCC,OAArC,EAA8CC,UAA9C,EAA0DC,IAA1D,EAAgEC,SAAhE,CALF,EAONoB,IAAKA,KAAM,CAAC1B,OAAD,EAAUE,GAAV,EAAeG,IAAf,EAAqBF,OAArB,EAA8BC,UAA9B,CAANsB,IACG3B,cAAA,CAAeC,OAAf,EAAwB,KAAxB,EAA+BE,GAA/B,EAAoCC,OAApC,EAA6CC,UAA7C,EAAyDC,IAAzD,EAA+DC,SAA/D,CARF,EAUNqB,KAAMA,KAAM,CAAC3B,OAAD,EAAUE,GAAV,EAAeC,OAAf,EAAwBC,UAAxB,CAANuB,IACE5B,cAAA,CAAeC,OAAf,EAAwB,MAAxB,EAAgCE,GAAhC,EAAqClB,cAAA,CAAeA,cAAA,CAAe,EAAf;AAAmBmB,WAAnB,CAAf,EAA4C,EAA5C,EAAgD,CAAEW,cAAe,CAAA,CAAjB,CAAhD,CAArC,EAA+GV,UAA/G,EAA2H,IAAK,EAAhI,EAAmIE,SAAnI,CAXF,EAaNsB,OAAQA,KAAM,CAAC5B,OAAD,EAAUE,GAAV,EAAeG,IAAf,EAAqBF,OAArB,EAA8BC,UAA9B,CAANwB,IACA7B,cAAA,CAAeC,OAAf,EAAwB,QAAxB,EAAkCE,GAAlC,EAAuCC,OAAvC,EAAgDC,UAAhD,EAA4DC,IAA5D,EAAkEC,SAAlE,CAdF,CAAP;AAD8C;AA/U/C,MAAIuB,SAAStE,OAAA,CAAQ,kCAAR,CAAkBsE,CAAAA,MAA/B;AACA,MAAIC,aAAavE,OAAA,CAAQ,+CAAR,CAAjB;AAOA,MAAIwE,eAAe,aAAcC,MAAd;AAClB/D,eAAW,CAACgE,OAAD,EAAU3B,SAAA,GAAY,SAAtB,EAAiCY,MAAjC,EAAyCgB,UAAzC,CAAqD;AAC/D,WAAA,CAAMD,OAAN,CAAA;AACA,UAAKE,CAAAA,gBAAL,GAAwB,CAAA,CAAxB;AACA,UAAK7B,CAAAA,SAAL,GAAiBA,SAAjB;AACA,UAAK8B,CAAAA,IAAL,GAAY9B,SAAA,KAAc,SAAd,GAA0B,qBAA1B,GAAkD,cAA9D;AACA,UAAKY,CAAAA,MAAL,GAAcA,MAAd;AACA,UAAKgB,CAAAA,UAAL,GAAkBA,UAAlB;AAN+D;AAD9C,GAAnB,EAsBIG,kBAAkB,aAAcN,aAAd;AACrB9D,eAAW,CAACgE,OAAD,EAAUf,MAAV,EAAkBgB,UAAlB,EAA8B5B,SAAA,GAAY,SAA1C,CAAqD;AAC/D,WAAA,CAAM2B,OAAN,EAAe3B,SAAf,EAA0BY,MAA1B,EAAkCgB,UAAlC,CAAA;AACA,UAAKE,CAAAA,IAAL,GAAY9B,SAAA,KAAc,SAAd,GAA0B,wBAA1B,GAAqD,iBAAjE;AACA,UAAKY,CAAAA,MAAL,GAAcA,MAAd;AACA,UAAKgB,CAAAA,UAAL,GAAkBA,UAAlB;AAJ+D;AAMhEI,UAAM,EAAG;AACR,aAAO,CACNF,KAAM,IAAKA,CAAAA,IADL,EAENH,QAAS,IAAKA,CAAAA,OAFR,EAGNf,OAAQ,IAAKA,CAAAA,MAHP,EAINgB,WAAY,IAAKA,CAAAA,UAJX,CAAP;AADQ;AAPY,GAtBtB,EA0CIK,sBAAsB,aAAcR,aAAd;AACzB9D,eAAW,CAACgE,OAAD,EAAUO,aAAV,EAAyBlC,SAAA,GAAY,SAArC,CAAgD;AAC1D,WAAA,CAAM2B,OAAN,EAAe3B,SAAf,CAAA;AACA,UAAK8B,CAAAA,IAAL,GAAY9B,SAAA,KAAc,SAAd,GAA0B,4BAA1B,GAAyD,qBAArE;AACA,UAAKkC,CAAAA,aAAL,GAAqBA,aAArB;AAH0D;AADlC,GA1C1B;AAqDIC,SAAAA,GAAsB,aAAcV,aAAd;AACzB9D,eAAW,CAACgE,OAAD,CAAU;AACpB,WAAA,CAAMA,OAAN,EAAe,SAAf,CAAA;AADoB;AADI,GAAtBQ;AAiBAC,QAAAA,GAAyB,aAAcL,gBAAd;AAC5BpE,eAAW,CAACgE,OAAD,EAAUf,MAAV,EAAkBgB,UAAlB,CAA8B;AACxC,WAAA,CAAMD,OAAN,EAAef,MAAf,EAAuBgB,UAAvB,EAAmC,SAAnC,CAAA;AADwC;AADb,GAAzBQ;AASJ,MAAIC,6BAA6B,aAAcJ,oBAAd;AAChCtE,eAAW,CAACgE,OAAD,EAAUO,aAAV,CAAyB;AACnC,WAAA,CAAMP,OAAN,EAAeO,aAAf,EAA8B,SAA9B,CAAA;AADmC;AADJ,GAAjC;AASA,MAAII,0BAA0C,QAAQ,CAACC,yBAAD,CAA4B;AAEjFA,6BAAA,CAAA,aAAA,GAA6C,eAA7C;AAEAA,6BAAA,CAAA,yBAAA,GAAyD,2BAAzD;AAEAA,6BAAA,CAAA,yBAAA,GAAyD,2BAAzD;AAEAA,6BAAA,CAAA,sBAAA,GAAsD,wBAAtD;AAEAA,6BAAA,CAAA,0BAAA,GAA0D,4BAA1D;AAEAA,6BAAA,CAAA,0BAAA,GAA0D,4BAA1D;AACA,WAAOA,yBAAP;AAbiF,GAApC,CAc5C,EAd4C,CAA9C;AAyBA,QAAMC,eAAgBC,WAADD,IAChBC,WAAJ,GAAwB,CAAC,GAAGC,IAAJ,CAAA,IAAaD,WAAA,CAAY,GAAGC,IAAf,CAArC,GACO,CAAC,GAAGA,IAAJ,CAAA,IAAaC,KAAA,CAAM,GAAGD,IAAT,CAFrB,EAwBME,mBAAoBC,IAADD,IAAU;AAClC,QAAIE,KAAMC,CAAAA,OAAN,CAAcF,IAAd,CAAJ;AAAyB,aAAOA,IAAKG,CAAAA,GAAL,CAAUC,EAAD,IAAQL,gBAAA,CAAiBK,EAAjB,CAAjB,CAAP;AAAzB;AACK,QAAI,MAAOJ,KAAX,KAAoB,UAApB,IAAkCA,IAAlC,KAA2C5E,MAAA,CAAO4E,IAAP,CAA3C;AAAyD,aAAOA,IAAP;AAAzD;AACL,UAAMvC,SAAS,EAAf;AACArC,UAAOiF,CAAAA,OAAP,CAAeL,IAAf,CAAqBhE,CAAAA,OAArB,CAA6B,CAAC,CAACsE,GAAD,EAAM/D,KAAN,CAAD,CAAA,IAAkB;AACxCgE,SAAAA,GAASD,GAAIE,CAAAA,OAAJ,CAAY,eAAZ,EAA8BC,CAAD,IAAOA,CAAEC,CAAAA,WAAF,EAAgBF,CAAAA,OAAhB,CAAwB,OAAxB,EAAiC,EAAjC,CAApC,CAATD;AACN9C,YAAA,CAAO8C,GAAP,CAAA,GAAiBR,gBAAA,CAAiBxD,KAAjB,CAAjB;AAF8C,KAA/C,CAAA;AAIA,WAAOkB,MAAP;AARkC,GAxBnC,EAiDMkD,oBAAqBC,UAADD,IACrB,CAACC,UAGL,IAHmB,MAAOA,WAG1B,KAHyC,QAGzC,IAFIA,UAAW7E,CAAAA,MAEf,KAF0B,CAE1B,IAF+B6E,UAAW7E,CAAAA,MAE1C,GAFmD,GAEnD,IADI6E,UAAWC,CAAAA,IAAX,EACJ,KAD0BD,UAC1B,IAAIA,UAAW5C,CAAAA,QAAX,CAAoB,GAApB,CAAJ,IAAgC4C,UAAW5C,CAAAA,QAAX,CAAoB,IAApB,CAAhC,GAAkE,CAAA,CAAlE,GACO,2BAA4B8C,CAAAA,IAA5B,CAAiCF,UAAjC,CAtDR,EAkIMG,mBAAoBC,GAADD,IAAS;AACjC,QAAIE,UAAJ;AACA,WAAOD,GAAIE,CAAAA,GAAX,IAAkBF,GAAIlC,CAAAA,OAAtB,IAAiCkC,GAAIG,CAAAA,iBAArC,KAA2D,MAAOH,IAAIxG,CAAAA,KAAX,KAAqB,QAArB,GAAgCwG,GAAIxG,CAAAA,KAApC,GAA4C,CAACyG,UAAD,GAAcD,GAAIxG,CAAAA,KAAlB,MAA6B,IAA7B,IAAqCyG,UAArC,KAAoD,IAAK,EAAzD,GAA6D,IAAK,EAAlE,GAAsEA,UAAWnC,CAAAA,OAAxL,KAAoMsC,IAAKC,CAAAA,SAAL,CAAeL,GAAf,CAApM;AAFiC,GAlIlC,EA6IM5C,cAAcA,KAAM,CAAC5D,KAAD,EAAQ8C,MAAR,EAAgBN,OAAhB,EAAyBG,SAAzB,CAANiB,IAA6C;AAChE,QAAI5D,KAAJ,IAAa,MAAOA,MAApB,KAA8B,QAA9B,IAA0C,QAA1C,IAAsDA,KAAtD,IAA+D,IAA/D,IAAuEA,KAAvE,IAAgF,MAAOA,MAAMuD,CAAAA,MAA7F,KAAwG,QAAxG,KAAsHf,OAAtH,KAAkI,IAAlI,IAA0IA,OAA1I,KAAsJ,IAAK,EAA3J,IAAgLW,CAARX,OAAQW,CAAAA,aAAhL,EAAgM;AAE/L,YAAMI,SADgBvD,KACOuD,CAAAA,MAAvBA,IAAiC,GAAvC;AACI,YAFkBvD,MAEGyD,CAAAA,IAAzB,KAAkC,UAAlC,GAFsBzD,KAEsCyD,CAAAA,IAAd,EAAqBT,CAAAA,IAArB,CAA2BwD,GAAD,IAAS;AAChF,cAAMjC,cAAciC,GAAA,KAAQ,IAAR,IAAgBA,GAAhB,KAAwB,IAAK,EAA7B,GAAiC,IAAK,EAAtC,GAA0CA,GAAIjC,CAAAA,UAA5DA,MAA4EiC,GAAA,KAAQ,IAAR,IAAgBA,GAAhB,KAAwB,IAAK,EAA7B,GAAiC,IAAK,EAAtC,GAA0CA,GAAIM,CAAAA,IAA1HvC,KAAmIhB,MAAnIgB,GAA4I,EAAlJ;AACAzB,cAAA,CAAO,IAAI4B,eAAJ,CAAoB6B,gBAAA,CAAiBC,GAAjB,CAApB,EAA2CjD,MAA3C,EAAmDgB,UAAnD,EAA+D5B,SAA/D,CAAP,CAAA;AAFgF,OAAnC,CAG3CgB,CAAAA,KAH2C,CAGrC,EAAA,IAAM;AAGbb,cAAA,CAAO,IAAI4B,eAAJ,CARa1E,KAQqB+G,CAAAA,UAAlC,IAAiD,QAAOxD,MAAP,QAAjD,EAAwEA,MAAxE,EADYA,MACZ,GADqB,EACrB,EAA4FZ,SAA5F,CAAP,CAAA;AAHa,OAH+B,CAA9C,GAcCG,MAAA,CAAO,IAAI4B,eAAJ,CAhBc1E,KAgBoB+G,CAAAA,UAAlC,IAAiD,QAAOxD,MAAP,QAAjD,EAAwEA,MAAxE,EADYA,MACZ,GADqB,EACrB,EAA4FZ,SAA5F,CAAP,CAdD;AAH+L,KAAhM;AAmBOG,YAAA,CAAO,IAAI8B,mBAAJ,CAAwB2B,gBAAA,CAAiBvG,KAAjB,CAAxB,EAAiDA,KAAjD,EAAwD2C,SAAxD,CAAP,CAAA;AAnBP;AADgE,GA7IjE,EA2KMI,oBAAoB,CAACT,MAAD,EAASE,OAAT,EAAkBC,UAAlB,EAA8BC,IAA9B,CAAAK,IAAuC;AAChE,UAAMiE,SAAS,CACd1E,MADc,EAEde,SAAUb,OAAA,KAAY,IAAZ,IAAoBA,OAApB,KAAgC,IAAK,EAArC,GAAyC,IAAK,EAA9C,GAAkDA,OAAQa,CAAAA,OAApEA,KAAgF,EAFlE,CAAf;AAIA,QAAIf,MAAJ,KAAe,KAAf,IAAwBA,MAAxB,KAAmC,MAAnC,IAA6C,CAACI,IAA9C;AAAoD,aAAOrB,cAAA,CAAeA,cAAA,CAAe,EAAf,EAAmB2F,MAAnB,CAAf,EAA2CvE,UAA3C,CAAP;AAApD;AAnKI,UAoKcC,KApKlB,KAAqB,QAArB,IAoKkBA,IApKlB,KAA2C,IAA3C,GAAiD,MAAjD,GAAwD,CAAA,CAAxD,IACMnC,MACN,GADkBK,MAAOqG,CAAAA,cAAP,CAmKAvE,IAnKA,CAClB,EAAA,MAAA,IAAQnC,MAAR,KAAsB,IAAtB,IAA8BA,MAA9B,KAA4CK,MAAOL,CAAAA,SAAnD,IAAgEK,MAAOqG,CAAAA,cAAP,CAAsB1G,MAAtB,CAAhE,KAAqG,IAArG,KAA8G,EAAEJ,MAAO+G,CAAAA,WAAT,IAkK5FxE,IAlK4F,CAA9G,IAAgJ,EAAEvC,MAAOC,CAAAA,QAAT,IAkK9HsC,IAlK8H,CAFhJ,CAAA;AAoKI,UAAJ,IACCsE,MAAO3D,CAAAA,OACP,GADiBhC,cAAA,CAAe,CAAE,eAAgB,kBAAlB,CAAf,EAAuDmB,OAAA,KAAY,IAAZ,IAAoBA,OAApB,KAAgC,IAAK,EAArC,GAAyC,IAAK,EAA9C,GAAkDA,OAAQa,CAAAA,OAAjH,CACjB,EAAA2D,MAAOtE,CAAAA,IAAP,GAAckE,IAAKC,CAAAA,SAAL,CAAenE,IAAf,CAFf,IAGOsE,MAAOtE,CAAAA,IAHd,GAGqBA,IAHrB;AAIA,QAAIF,OAAA,KAAY,IAAZ,IAAoBA,OAApB,KAAgC,IAAK,EAArC,GAAyC,CAAzC,GAAkDA,OAAQ2E,CAAAA,MAA9D;AAAsEH,YAAOG,CAAAA,MAAP,GAAgB3E,OAAQ2E,CAAAA,MAAxB;AAAtE;AACA,WAAO9F,cAAA,CAAeA,cAAA,CAAe,EAAf,EAAmB2F,MAAnB,CAAf,EAA2CvE,UAA3C,CAAP;AAXgE,GA3KjE;AAyOA,MAAM2E,aAAavD,cAAA,CAAe,SAAf,CAAnB;AACA,QAAM,CAAEP,GAAF,EAAOQ,IAAP,EAAaC,GAAb,EAAkBC,IAAlB,EAAwBC,MAAxB,CAAA,GAAmCmD,UAAzC,EACMC,aAAaxD,cAAA,CAAe,SAAf,CADnB;AAYA,MAAIyD,gBAAgB,KAAA;AAQnBhH,eAAW,CAACiC,GAAD,EAAMc,OAAA,GAAU,EAAhB,EAAoBkE,OAApB,EAA6B5E,SAAA,GAAY,SAAzC,CAAoD;AAC9D,UAAK6E,CAAAA,kBAAL,GAA0B,CAAA,CAA1B;AACA,UAAKjF,CAAAA,GAAL,GAAWA,GAAX;AACA,UAAKc,CAAAA,OAAL,GAAeA,OAAf;AACA,UAAKiC,CAAAA,KAAL,GAAaH,YAAA,CAAaoC,OAAb,CAAb;AACA,UAAK5E,CAAAA,SAAL,GAAiBA,SAAjB;AAL8D;AAa/D8E,gBAAY,EAAG;AACd,UAAKD,CAAAA,kBAAL,GAA0B,CAAA,CAA1B;AACA,aAAO,IAAP;AAFc;AAYfE,aAAS,CAACjD,IAAD,EAAO1C,KAAP,CAAc;AACtB,UAAKsB,CAAAA,OAAL,GAAehC,cAAA,CAAeA,cAAA,CAAe,EAAf,EAAmB,IAAKgC,CAAAA,OAAxB,CAAf,EAAiD,EAAjD,EAAqD,CAAE,CAACoB,IAAD,EAAQ1C,KAAV,CAArD,CAAf;AACA,aAAO,IAAP;AAFsB;AA6BjB4F,yBAAe,CAACC,SAAD,CAAY;AAEhC,SAAI;AACH,eAAO,CACNlE,KAAM,MAAMkE,SAAA,EADN,EAEN5H,MAAO,IAFD,CAAP;AADG,OAKF,QAAOA,KAAP,CAAc;AACf,YAPW6H,IAODL,CAAAA,kBAAV;AAA8B,gBAAMxH,KAAN;AAA9B;AACA,YAAID,cAAA,CAAeC,KAAf,CAAJ;AAA2B,iBAAO,CACjC0D,KAAM,IAD2B,EAEjC1D,KAFiC,CAAP;AAA3B;AAIA,cAAMA,KAAN;AANe;AAPgB;AA9Dd,GAApB,EAkFI8H,wBAAwB,KAAA;AAC3BxH,eAAW,CAACyH,UAAD,EAAaP,kBAAb,CAAiC;AAC3C,UAAKO,CAAAA,UAAL,GAAkBA,UAAlB;AACA,UAAKP,CAAAA,kBAAL,GAA0BA,kBAA1B;AAF2C;AAI5CxE,QAAI,CAACgF,WAAD,EAAcC,UAAd,CAA0B;AAC7B,aAAO,IAAKC,CAAAA,OAAL,EAAelF,CAAAA,IAAf,CAAoBgF,WAApB,EAAiCC,UAAjC,CAAP;AAD6B;AAGxBC,iBAAO,EAAG;AAEf,SAAI;AACH,eAAO,CACNxE,KAAiChB,CAA1B,MAHGmF,IAGSE,CAAAA,UAAN,EAAoBrF,EAAAA,IAD3B,EAEN1C,MAAO,IAFD,CAAP;AADG,OAKF,QAAOA,KAAP,CAAc;AACf,YAPW6H,IAODL,CAAAA,kBAAV;AAA8B,gBAAMxH,KAAN;AAA9B;AACA,YAAID,cAAA,CAAeC,KAAf,CAAJ;AAA2B,iBAAO,CACjC0D,KAAM,IAD2B,EAEjC1D,KAFiC,CAAP;AAA3B;AAIA,cAAMA,KAAN;AANe;AAPD;AARW,GAlF5B;AA8GA,MAAImI,mBAAJ;AACAA,qBAAA,GAAsBhI,MAAO+G,CAAAA,WAA7B;AACA,MAAIkB,sBAAsB,KAAA;AACzB9H,eAAW,CAACyH,UAAD,EAAaP,kBAAb,CAAiC;AAC3C,UAAKO,CAAAA,UAAL,GAAkBA,UAAlB;AACA,UAAKP,CAAAA,kBAAL,GAA0BA,kBAA1B;AACA,UAAA,CAAKW,mBAAL,CAAA,GAA4B,qBAA5B;AACA,UAAKE,CAAAA,OAAL,GAAe,IAAf;AAJ2C;AAM5CC,YAAQ,EAAG;AACV,aAAO,IAAIR,qBAAJ,CAA0B,IAAKC,CAAAA,UAA/B,EAA2C,IAAKP,CAAAA,kBAAhD,CAAP;AADU;AAGXxE,QAAI,CAACgF,WAAD,EAAcC,UAAd,CAA0B;AAC7B,aAAO,IAAKM,CAAAA,UAAL,EAAkBvF,CAAAA,IAAlB,CAAuBgF,WAAvB,EAAoCC,UAApC,CAAP;AAD6B;AAG9BtE,SAAK,CAACsE,UAAD,CAAa;AACjB,aAAO,IAAKM,CAAAA,UAAL,EAAkB5E,CAAAA,KAAlB,CAAwBsE,UAAxB,CAAP;AADiB;AAGlBO,WAAO,CAACC,SAAD,CAAY;AAClB,aAAO,IAAKF,CAAAA,UAAL,EAAkBC,CAAAA,OAAlB,CAA0BC,SAA1B,CAAP;AADkB;AAGnBF,cAAU,EAAG;AACP,UAAKF,CAAAA,OAAV,KAAmB,IAAKA,CAAAA,OAAxB,GAAkC,IAAKH,CAAAA,OAAL,EAAlC;AACA,aAAO,IAAKG,CAAAA,OAAZ;AAFY;AAIPH,iBAAO,EAAG;AAEf,SAAI;AACH,eAAO,CACNxE,KAAM,MAAiCgF,CAA1B,MAHHb,IAGeE,CAAAA,UAAN,EAAoBW,EAAAA,IAA3B,EADN,EAEN1I,MAAO,IAFD,CAAP;AADG,OAKF,QAAOA,KAAP,CAAc;AACf,YAPW6H,IAODL,CAAAA,kBAAV;AAA8B,gBAAMxH,KAAN;AAA9B;AACA,YAAID,cAAA,CAAeC,KAAf,CAAJ;AAA2B,iBAAO,CACjC0D,KAAM,IAD2B,EAEjC1D,KAFiC,CAAP;AAA3B;AAIA,cAAMA,KAAN;AANe;AAPD;AAvBS,GAA1B;AA2CA,QAAM2I,yBAAyB,CAC9BC,MAAO,GADuB,EAE9BC,OAAQ,CAFsB,EAG9BC,OAAQ,CACPC,OAAQ,MADD,EAEPC,MAAO,KAFA,CAHsB,CAA/B,EAQMC,uBAAuB,CAC5BC,aAAc,MADc,EAE5B9F,YAAa,6BAFe,EAG5B+F,OAAQ,CAAA,CAHoB,CAR7B;AAaA,MAAIC,iBAAiB,aAAc9B,cAAd;AACpBhH,eAAW,CAACiC,GAAD,EAAMc,OAAA,GAAU,EAAhB,EAAoBgG,QAApB,EAA8B9B,OAA9B,CAAuC;AACjD,WAAA,CAAMhF,GAAN,EAAWc,OAAX,EAAoBkE,OAApB,EAA6B,SAA7B,CAAA;AACA,UAAK8B,CAAAA,QAAL,GAAgBA,QAAhB;AAFiD;AAW5CC,wBAAc,CAAChH,MAAD,EAASiH,IAAT,EAAeC,QAAf,EAAyBC,WAAzB,CAAsC;AACzD,UAAI5B,QAAQ,IAAZ;AACA,aAAOA,KAAMF,CAAAA,eAAN,CAAsB,KAAM,EAAN,IAAY;AAExC,cAAMnF,UAAUnB,cAAA,CAAeA,cAAA,CAAe,EAAf,EAAmB4H,oBAAnB,CAAf,EAAyDQ,WAAzD,CAAhB;AACA,YAAIpG,UAAUhC,cAAA,CAAeA,cAAA,CAAe,EAAf,EAAmBwG,KAAMxE,CAAAA,OAAzB,CAAf,EAAkDf,MAAlD,KAA6D,MAA7D,IAAuE,CAAE,WAAYT,MAAA,CAAOW,OAAQ2G,CAAAA,MAAf,CAAd,CAAvE,CAAd;AACA,YAAMO,WAAWlH,OAAQkH,CAAAA,QAAzB;AACA,YAAI,MAAOC,KAAX,KAAoB,WAApB,IAAmCH,QAAnC,YAAuDG,IAAvD,CAA6D;AAC5D,cAAAjH,OAAO,IAAIkH,QAAJ,EAAP;AACAlH,cAAKmH,CAAAA,MAAL,CAAY,cAAZ,EAA4BrH,OAAQ0G,CAAAA,YAApC,CAAA;AACIQ,kBAAJ,IAAchH,IAAKmH,CAAAA,MAAL,CAAY,UAAZ,EAAwBhC,KAAMiC,CAAAA,cAAN,CAAqBJ,QAArB,CAAxB,CAAd;AACAhH,cAAKmH,CAAAA,MAAL,CAAY,EAAZ,EAAgBL,QAAhB,CAAA;AAJ4D,SAA7D;AAKW,gBAAOI,SAAX,KAAwB,WAAxB,IAAuCJ,QAAvC,YAA2DI,QAA3D,IACNlH,IAEA,GAFO8G,QAEP,EADK9G,IAAKqH,CAAAA,GAAL,CAAS,cAAT,CACL,IAD+BrH,IAAKmH,CAAAA,MAAL,CAAY,cAAZ,EAA4BrH,OAAQ0G,CAAAA,YAApC,CAC/B,EAAIQ,QAAJ,IAAgB,CAAChH,IAAKqH,CAAAA,GAAL,CAAS,UAAT,CAAjB,IAAuCrH,IAAKmH,CAAAA,MAAL,CAAY,UAAZ,EAAwBhC,KAAMiC,CAAAA,cAAN,CAAqBJ,QAArB,CAAxB,CAHjC,KAKNhH,IAIA,GAJO8G,QAIP,EAHAnG,OAAA,CAAQ,eAAR,CAGA,GAH4B,WAAUb,OAAQ0G,CAAAA,YAAlB,EAG5B,EAFA7F,OAAA,CAAQ,cAAR,CAEA,GAF0Bb,OAAQY,CAAAA,WAElC,EADIsG,QACJ,KADcrG,OAAA,CAAQ,YAAR,CACd,GADsCwE,KAAMmC,CAAAA,QAAN,CAAenC,KAAMiC,CAAAA,cAAN,CAAqBJ,QAArB,CAAf,CACtC,IAAK,MAAOO,eAAZ;AAA+B,qBAA/B,IAA8CvH,IAA9C,YAA8DuH,cAA9D,IAAgFvH,IAAhF,IAAwF,MAAOA,KAA/F,KAAwG,QAAxG,IAAoH,MAApH,IAA8HA,IAA9H,IAAsI,MAAOA,KAAKwH,CAAAA,IAAlJ,KAA2J,UAA3J,KAA0K,CAAC1H,OAAQ2E,CAAAA,MAAnL,KAA2L3E,OAAQ2E,CAAAA,MAAnM,GAA4M,MAA5M,CATM,CAAA;AALP;AAgBA,YAAIsC,WAAA,KAAgB,IAAhB,IAAwBA,WAAxB,KAAwC,IAAK,EAA7C,GAAiD,CAAjD,GAA0DA,WAAYpG,CAAAA,OAA1E;AAAmFA,iBAAA,GAAUhC,cAAA,CAAeA,cAAA,CAAe,EAAf,EAAmBgC,OAAnB,CAAf,EAA4CoG,WAAYpG,CAAAA,OAAxD,CAAV;AAAnF;AACM8G,gBAAAA,GAAYtC,KAAMuC,CAAAA,mBAAN,CAA0Bb,IAA1B,CAAZY;AACN,cAAME,QAAQxC,KAAMyC,CAAAA,aAAN,CAAoBH,QAApB,CAAd;AACMzG,YAAAA,GAAO,MAAM,CAACpB,MAAA,IAAU,KAAV,GAAkByB,GAAlB,GAAwBD,IAAzB,EAA+B+D,KAAMvC,CAAAA,KAArC,EAA6C,GAAEuC,KAAMtF,CAAAA,GAAR,WAAsB8H,KAAtB,EAA7C,EAA4E3H,IAA5E,EAAkFrB,cAAA,CAAe,CAAEgC,OAAF,CAAf,EAA4B,CAACb,OAAA,KAAY,IAAZ,IAAoBA,OAApB,KAAgC,IAAK,EAArC,GAAyC,CAAzC,GAAkDA,OAAQ2E,CAAAA,MAA3D,IAAqE,CAAEA,OAAQ3E,OAAQ2E,CAAAA,MAAlB,CAArE,GAAkG,EAA9H,CAAlF,CAAbzD;AACN,eAAO,CACN6F,KAAMY,QADA,EAENI,GAAI7G,IAAK8G,CAAAA,EAFH,EAGNC,SAAU/G,IAAKgH,CAAAA,GAHT,CAAP;AAzBwC,OAAlC,CAAP;AAFyD;AA8EpDC,gBAAM,CAACpB,IAAD,EAAOC,QAAP,EAAiBC,WAAjB,CAA8B;AACzC,aAAO,IAAKH,CAAAA,cAAL,CAAoB,MAApB,EAA4BC,IAA5B,EAAkCC,QAAlC,EAA4CC,WAA5C,CAAP;AADyC;AAkCpCmB,2BAAiB,CAACrB,IAAD,EAAOsB,KAAP,EAAcrB,QAAd,EAAwBC,WAAxB,CAAqC;AAC3D,UAAIqB,SAAS,IAAb;AACA,YAAMX,YAAYW,MAAOV,CAAAA,mBAAP,CAA2Bb,IAA3B,CAAlB;AACMc,UAAAA,GAAQS,MAAOR,CAAAA,aAAP,CAAqBH,SAArB,CAARE;AACN,YAAM9H,MAAM,IAAIwI,GAAJ,CAAQD,MAAOvI,CAAAA,GAAf,GAAsB,uBAAsB8H,IAAtB,EAAtB,CAAZ;AACA9H,SAAIyI,CAAAA,YAAaC,CAAAA,GAAjB,CAAqB,OAArB,EAA8BJ,KAA9B,CAAA;AACA,aAAOC,MAAOnD,CAAAA,eAAP,CAAuB,KAAM,EAAN,IAAY;AACzC,YAAIjF,IAAJ;AACA,cAAMF,UAAUnB,cAAA,CAAe,CAAE8H,OAAQF,oBAAqBE,CAAAA,MAA/B,CAAf,EAAwDM,WAAxD,CAAhB,EACMpG,UAAUhC,cAAA,CAAeA,cAAA,CAAe,EAAf,EAAmByJ,MAAOzH,CAAAA,OAA1B,CAAf,EAAmD,CAAE,WAAYxB,MAAA,CAAOW,OAAQ2G,CAAAA,MAAf,CAAd,CAAnD,CADhB;AAEI,cAAOQ,KAAX,KAAoB,WAApB,IAAmCH,QAAnC,YAAuDG,IAAvD,IACCjH,IAEA,GAFO,IAAIkH,QAAJ,EAEP,EADAlH,IAAKmH,CAAAA,MAAL,CAAY,cAAZ,EAA4BrH,OAAQ0G,CAAAA,YAApC,CACA,EAAAxG,IAAKmH,CAAAA,MAAL,CAAY,EAAZ,EAAgBL,QAAhB,CAHD,IAIW,MAAOI,SAAX,KAAwB,WAAxB,IAAuCJ,QAAvC,YAA2DI,QAA3D,IACNlH,IACA,GADO8G,QACP,EAAA9G,IAAKmH,CAAAA,MAAL,CAAY,cAAZ,EAA4BrH,OAAQ0G,CAAAA,YAApC,CAFM,KAINxG,IAEA,GAFO8G,QAEP,EADAnG,OAAA,CAAQ,eAAR,CACA,GAD4B,WAAUb,OAAQ0G,CAAAA,YAAlB,EAC5B,EAAA7F,OAAA,CAAQ,cAAR,CAAA,GAA0Bb,OAAQY,CAAAA,WAN5B,CAJP;AAYA,eAAO,CACNmG,KAAMY,SADA,EAENM,SAAuEC,CAA5D,MAAM3G,GAAA,CAAI+G,MAAOxF,CAAAA,KAAX,EAAkB/C,GAAI2I,CAAAA,QAAJ,EAAlB,EAAkCxI,IAAlC,EAAwC,CAAEW,OAAF,CAAxC,CAAsDqH,EAAAA,GAFjE,CAAP;AAhByC,OAAnC,CAAP;AAN2D;AA0DtDS,+BAAqB,CAAC5B,IAAD,EAAO/G,OAAP,CAAgB;AAC1C,UAAI4I,SAAS,IAAb;AACA,aAAOA,MAAOzD,CAAAA,eAAP,CAAuB,KAAM,EAAN,IAAY;AACzC,YAAI0C,QAAQe,MAAOd,CAAAA,aAAP,CAAqBf,IAArB,CAAZ,EACMlG,UAAUhC,cAAA,CAAe,EAAf,EAAmB+J,MAAO/H,CAAAA,OAA1B,CADhB;AAEA,YAAIb,OAAA,KAAY,IAAZ,IAAoBA,OAApB,KAAgC,IAAK,EAArC,GAAyC,CAAzC,GAAkDA,OAAQ2G,CAAAA,MAA9D;AAAsE9F,iBAAA,CAAQ,UAAR,CAAA,GAAsB,MAAtB;AAAtE;AACMK,aAAAA,GAAO,MAAMI,IAAA,CAAKsH,MAAO9F,CAAAA,KAAZ,EAAoB,GAAE8F,MAAO7I,CAAAA,GAAT,uBAAmC8H,KAAnC,EAApB,EAAgE,EAAhE,EAAoE,CAAEhH,OAAF,CAApE,CAAbK;AACAnB,aAAAA,GAAM,IAAIwI,GAAJ,CAAQK,MAAO7I,CAAAA,GAAf,GAAqBmB,KAAKnB,CAAAA,GAA1B,CAANA;AACAsI,eAAAA,GAAQtI,KAAIyI,CAAAA,YAAa1H,CAAAA,GAAjB,CAAqB,OAArB,CAARuH;AACN,YAAI,CAACA,OAAL;AAAY,gBAAM,IAAIzG,YAAJ,CAAiB,0BAAjB,CAAN;AAAZ;AACA,eAAO,CACNiH,UAAW9I,KAAI2I,CAAAA,QAAJ,EADL,EAEN3B,IAFM,EAGNsB,MAAAA,OAHM,CAAP;AARyC,OAAnC,CAAP;AAF0C;AA6DrCS,gBAAM,CAAC/B,IAAD,EAAOC,QAAP,EAAiBC,WAAjB,CAA8B;AACzC,aAAO,IAAKH,CAAAA,cAAL,CAAoB,KAApB,EAA2BC,IAA3B,EAAiCC,QAAjC,EAA2CC,WAA3C,CAAP;AADyC;AA8BpC8B,cAAI,CAACC,QAAD,EAAWC,MAAX,EAAmBjJ,OAAnB,CAA4B;AACrC,UAAIkJ,SAAS,IAAb;AACA,aAAOA,MAAO/D,CAAAA,eAAP,CAAuB,KAAM,EAAN,IACtB,MAAM7D,IAAA,CAAK4H,MAAOpG,CAAAA,KAAZ,EAAoB,GAAEoG,MAAOnJ,CAAAA,GAAT,cAApB,EAAgD,CAC5D8G,SAAUqC,MAAOrC,CAAAA,QAD2C,EAE5DsC,UAAWH,QAFiD,EAG5DI,eAAgBH,MAH4C,EAI5DI,kBAAmBrJ,OAAA,KAAY,IAAZ,IAAoBA,OAApB,KAAgC,IAAK,EAArC,GAAyC,IAAK,EAA9C,GAAkDA,OAAQqJ,CAAAA,iBAJjB,CAAhD,EAKV,CAAExI,QAASqI,MAAOrI,CAAAA,OAAlB,CALU,CADP,CAAP;AAFqC;AAsChCyI,cAAI,CAACN,QAAD,EAAWC,MAAX,EAAmBjJ,OAAnB,CAA4B;AACrC,UAAIuJ,SAAS,IAAb;AACA,aAAOA,MAAOpE,CAAAA,eAAP,CAAuB,KAAM,EAAN,IACtB,EAAE4B,KAKwBmB,CALjB,MAAM5G,IAAA,CAAKiI,MAAOzG,CAAAA,KAAZ,EAAoB,GAAEyG,MAAOxJ,CAAAA,GAAT,cAApB,EAAgD,CACrE8G,SAAU0C,MAAO1C,CAAAA,QADoD,EAErEsC,UAAWH,QAF0D,EAGrEI,eAAgBH,MAHqD,EAIrEI,kBAAmBrJ,OAAA,KAAY,IAAZ,IAAoBA,OAApB,KAAgC,IAAK,EAArC,GAAyC,IAAK,EAA9C,GAAkDA,OAAQqJ,CAAAA,iBAJR,CAAhD,EAKnB,CAAExI,QAAS0I,MAAO1I,CAAAA,OAAlB,CALmB,CAKWqH,EAAAA,GAL1B,EADD,CAAP;AAFqC;AA8DhCsB,yBAAe,CAACzC,IAAD,EAAO0C,SAAP,EAAkBzJ,OAAlB,CAA2B;AAC/C,UAAI0J,SAAS,IAAb;AACA,aAAOA,MAAOvE,CAAAA,eAAP,CAAuB,KAAM,EAAN,IAAY;AACzC,YAAI0C,QAAQ6B,MAAO5B,CAAAA,aAAP,CAAqBf,IAArB,CAAZ;AACI7F,aAAAA,GAAO,MAAMI,IAAA,CAAKoI,MAAO5G,CAAAA,KAAZ,EAAoB,GAAE4G,MAAO3J,CAAAA,GAAT,gBAA4B8H,KAA5B,EAApB,EAAyDhJ,cAAA,CAAe,CAAE4K,SAAF,CAAf,EAA8B,CAACzJ,OAAA,KAAY,IAAZ,IAAoBA,OAApB,KAAgC,IAAK,EAArC,GAAyC,CAAzC,GAAkDA,OAAQ2J,CAAAA,SAA3D,IAAwE,CAAEA,UAAW3J,OAAQ2J,CAAAA,SAArB,CAAxE,GAA2G,EAAzI,CAAzD,EAAuM,CAAE9I,QAAS6I,MAAO7I,CAAAA,OAAlB,CAAvM,CAAbK;AAEJ,eAAO,CAAE2H,UAAWe,SAAA,CAAW,GAAEF,MAAO3J,CAAAA,GAAT,GAAemB,KAAK2I,CAAAA,SAApB,GADJC,CAAC9J,OAAA,KAAY,IAAZ,IAAoBA,OAApB,KAAgC,IAAK,EAArC,GAAyC,CAAzC,GAAkDA,OAAQ+J,CAAAA,QAA3DD,IAAwE,aAAY9J,OAAQ+J,CAAAA,QAAR,KAAqB,CAAA,CAArB,GAA4B,EAA5B,GAAiC/J,OAAQ+J,CAAAA,QAArD,EAAxED,GAA0I,EACtI,EAAX,CAAb,CAAP;AAJyC,OAAnC,CAAP;AAF+C;AA+C1CE,0BAAgB,CAACC,KAAD,EAAQR,SAAR,EAAmBzJ,OAAnB,CAA4B;AACjD,UAAIkK,SAAS,IAAb;AACA,aAAOA,MAAO/E,CAAAA,eAAP,CAAuB,KAAM,EAAN,IAAY;AACzC,cAAMjE,OAAO,MAAMI,IAAA,CAAK4I,MAAOpH,CAAAA,KAAZ,EAAoB,GAAEoH,MAAOnK,CAAAA,GAAT,gBAA4BmK,MAAOrD,CAAAA,QAAnC,EAApB,EAAmE,CACrF4C,SADqF,EAErFQ,KAFqF,CAAnE,EAGhB,CAAEpJ,QAASqJ,MAAOrJ,CAAAA,OAAlB,CAHgB,CAAnB,EAIMiJ,qBAAqB,CAAC9J,OAAA,KAAY,IAAZ,IAAoBA,OAApB,KAAgC,IAAK,EAArC,GAAyC,CAAzC,GAAkDA,OAAQ+J,CAAAA,QAA3D,IAAwE,aAAY/J,OAAQ+J,CAAAA,QAAR,KAAqB,CAAA,CAArB,GAA4B,EAA5B,GAAiC/J,OAAQ+J,CAAAA,QAArD,EAAxE,GAA0I,EAJrK;AAKA,eAAO7I,IAAKiC,CAAAA,GAAL,CAAUgH,KAAD,IAAWtL,cAAA,CAAeA,cAAA,CAAe,EAAf,EAAmBsL,KAAnB,CAAf,EAA0C,EAA1C,EAA8C,CAAEtB,UAAWsB,KAAMN,CAAAA,SAAN,GAAkBD,SAAA,CAAW,GAAEM,MAAOnK,CAAAA,GAAT,GAAeoK,KAAMN,CAAAA,SAArB,GAAiCC,kBAAjC,EAAX,CAAlB,GAAsF,IAAnG,CAA9C,CAApB,CAAP;AANyC,OAAnC,CAAP;AAFiD;AAqElDC,YAAQ,CAAChD,IAAD,EAAO/G,OAAP,EAAgBC,UAAhB,CAA4B;AACnC,YAAMmK,aAAa,OAAQpK,OAAA,KAAY,IAAZ,IAAoBA,OAApB,KAAgC,IAAK,EAArC,GAAyC,IAAK,EAA9C,GAAkDA,OAAQ2J,CAAAA,SAAlE,CAAA,KAAiF,WAAjF,GAA+F,4BAA/F,GAA8H,QAAjJ,EAEMU,cAAc,CADdC,OACc,GADQ,IAAKC,CAAAA,0BAAL,EAAiCvK,OAAA,KAAY,IAAZ,IAAoBA,OAApB,KAAgC,IAAK,EAArC,GAAyC,IAAK,EAA9C,GAAkDA,OAAQ2J,CAAAA,SAA3F,KAAyG,EAAzG,CACR,IAAuB,IAAGW,OAAH,EAAvB,GAAkD,EAFtE,EAGMzC,QAAQ,IAAKC,CAAAA,aAAL,CAAmBf,IAAnB,CAHd;AAQA,aAAO,IAAInB,mBAAJ,CAJY,EAAAL,IAAMzE,GAAA,CAAI,IAAKgC,CAAAA,KAAT,EAAiB,GAAE,IAAK/C,CAAAA,GAAP,IAAcqK,UAAd,IAA4BvC,KAA5B,GAAoCwC,WAApC,EAAjB,EAAoE,CAC5FxJ,QAAS,IAAKA,CAAAA,OAD8E,EAE5FF,cAAe,CAAA,CAF6E,CAApE,EAGtBV,UAHsB,CAIlB,EAAoC,IAAK+E,CAAAA,kBAAzC,CAAP;AATmC;AA0B9BwF,cAAI,CAACzD,IAAD,CAAO;AAChB,UAAI0D,UAAU,IAAd;AACA,YAAM5C,QAAQ4C,OAAQ3C,CAAAA,aAAR,CAAsBf,IAAtB,CAAd;AACA,aAAO0D,OAAQtF,CAAAA,eAAR,CAAwB,KAAM,EAAN,IACvBpC,gBAAA,CAAiB,MAAMjC,GAAA,CAAI2J,OAAQ3H,CAAAA,KAAZ,EAAoB,GAAE2H,OAAQ1K,CAAAA,GAAV,gBAA6B8H,KAA7B,EAApB,EAA0D,CAAEhH,QAAS4J,OAAQ5J,CAAAA,OAAnB,CAA1D,CAAvB,CADD,CAAP;AAHgB;AAsBX6J,gBAAM,CAAC3D,IAAD,CAAO;AAEZc,UAAAA,GADQ8C,IACQ7C,CAAAA,aAAR,CAAsBf,IAAtB,CAARc;AACN,SAAI;AAEH,eADA,MAAMrG,IAAA,CAHOmJ,IAGM7H,CAAAA,KAAb,EAAqB,GAHd6H,IAGwB5K,CAAAA,GAAV,WAAwB8H,IAAxB,EAArB,EAAsD,CAAEhH,QAHjD8J,IAGkE9J,CAAAA,OAAnB,CAAtD,CACC,EAAA,CACNK,KAAM,CAAA,CADA,EAEN1D,MAAO,IAFD,CAAP;AAFG,OAMF,QAAOA,KAAP,CAAc;AACf,YATamN,IASD3F,CAAAA,kBAAZ;AAAgC,gBAAMxH,KAAN;AAAhC;AACA,YAAID,cAAA,CAAeC,KAAf,CAAJ,IAA6BA,KAA7B,YAA8C4E,mBAA9C,KACOC,IACF,GADkB7E,KAAM6E,CAAAA,aACxB,EAAA,CAAC,GAAD,EAAM,GAAN,CAAWrB,CAAAA,QAAX,CAAoBqB,IAAA,KAAkB,IAAlB,IAA0BA,IAA1B,KAA4C,IAAK,EAAjD,GAAqD,IAAK,EAA1D,GAA8DA,IAActB,CAAAA,MAAhG,CAFL;AAE8G,iBAAO,CACnHG,KAAM,CAAA,CAD6G,EAEnH1D,KAFmH,CAAP;AAF9G;AAOA,cAAMA,KAAN;AATe;AATE;AAuEnBoN,gBAAY,CAAC7D,IAAD,EAAO/G,OAAP,CAAgB;AACrB6H,UAAAA,GAAQ,IAAKC,CAAAA,aAAL,CAAmBf,IAAnB,CAARc;AACN,YAAMgD,eAAe,EAArB;AACA,UAAMf,qBAAqB,CAAC9J,OAAA,KAAY,IAAZ,IAAoBA,OAApB,KAAgC,IAAK,EAArC,GAAyC,CAAzC,GAAkDA,OAAQ+J,CAAAA,QAA3D,IAAwE,YAAW/J,OAAQ+J,CAAAA,QAAR,KAAqB,CAAA,CAArB,GAA4B,EAA5B,GAAiC/J,OAAQ+J,CAAAA,QAApD,EAAxE,GAAyI,EAApK;AACID,wBAAJ,KAA2B,EAA3B,IAA+Be,YAAalM,CAAAA,IAAb,CAAkBmL,kBAAlB,CAA/B;AACMM,wBAAAA,GAAa,OAAQpK,OAAA,KAAY,IAAZ,IAAoBA,OAApB,KAAgC,IAAK,EAArC,GAAyC,IAAK,EAA9C,GAAkDA,OAAQ2J,CAAAA,SAAlE,CAAA,KAAiF,WAAjF,GAA+F,cAA/F,GAAgH,QAA7HS;AACAE,aAAAA,GAAsB,IAAKC,CAAAA,0BAAL,EAAiCvK,OAAA,KAAY,IAAZ,IAAoBA,OAApB,KAAgC,IAAK,EAArC,GAAyC,IAAK,EAA9C,GAAkDA,OAAQ2J,CAAAA,SAA3F,KAAyG,EAAzG,CAAtBW;AACFA,aAAJ,KAA4B,EAA5B,IAAgCO,YAAalM,CAAAA,IAAb,CAAkB2L,OAAlB,CAAhC;AACID,aAAAA,GAAcQ,YAAaC,CAAAA,IAAb,CAAkB,MAAlB,CAAdT;AACAA,aAAJ,KAAoB,EAApB,KAAwBA,OAAxB,GAAuC,IAAGA,OAAH,EAAvC;AACA,aAAO,CAAEnJ,KAAM,CAAE6J,UAAWnB,SAAA,CAAW,GAAE,IAAK7J,CAAAA,GAAP,IAAcqK,kBAAd,WAAmCvC,IAAnC,GAA2CwC,OAA3C,EAAX,CAAb,CAAR,CAAP;AAV2B;AAmCtB5I,gBAAM,CAACwI,KAAD,CAAQ;AACnB,UAAIe,UAAU,IAAd;AACA,aAAOA,OAAQ7F,CAAAA,eAAR,CAAwB,KAAM,EAAN,IACvB,MAAM1D,MAAA,CAAOuJ,OAAQlI,CAAAA,KAAf,EAAuB,GAAEkI,OAAQjL,CAAAA,GAAV,WAAwBiL,OAAQnE,CAAAA,QAAhC,EAAvB,EAAmE,CAAEoE,SAAUhB,KAAZ,CAAnE,EAAwF,CAAEpJ,QAASmK,OAAQnK,CAAAA,OAAnB,CAAxF,CADP,CAAP;AAFmB;AA0EdqK,cAAI,CAACnE,IAAD,EAAO/G,OAAP,EAAgBC,UAAhB,CAA4B;AACrC,UAAIkL,UAAU,IAAd;AACA,aAAOA,OAAQhG,CAAAA,eAAR,CAAwB,KAAM,EAAN,IAAY;AAC1C,cAAMjF,OAAOrB,cAAA,CAAeA,cAAA,CAAeA,cAAA,CAAe,EAAf,EAAmBsH,sBAAnB,CAAf,EAA2DnG,OAA3D,CAAf,EAAoF,EAApF,EAAwF,CAAEoL,OAAQrE,IAARqE,IAAgB,EAAlB,CAAxF,CAAb;AACA,eAAO,MAAM9J,IAAA,CAAK6J,OAAQrI,CAAAA,KAAb,EAAqB,GAAEqI,OAAQpL,CAAAA,GAAV,gBAA6BoL,OAAQtE,CAAAA,QAArC,EAArB,EAAsE3G,IAAtE,EAA4E,CAAEW,QAASsK,OAAQtK,CAAAA,OAAnB,CAA5E,EAA0GZ,UAA1G,CAAb;AAF0C,OAApC,CAAP;AAFqC;AAchCoL,gBAAM,CAACrL,OAAD,EAAUC,UAAV,CAAsB;AACjC,UAAIqL,UAAU,IAAd;AACA,aAAOA,OAAQnG,CAAAA,eAAR,CAAwB,KAAM,EAAN,IAAY;AAC1C,cAAMjF,OAAOrB,cAAA,CAAe,EAAf,EAAmBmB,OAAnB,CAAb;AACA,eAAO,MAAMsB,IAAA,CAAKgK,OAAQxI,CAAAA,KAAb,EAAqB,GAAEwI,OAAQvL,CAAAA,GAAV,mBAAgCuL,OAAQzE,CAAAA,QAAxC,EAArB,EAAyE3G,IAAzE,EAA+E,CAAEW,QAASyK,OAAQzK,CAAAA,OAAnB,CAA/E,EAA6GZ,UAA7G,CAAb;AAF0C,OAApC,CAAP;AAFiC;AAOlCqH,kBAAc,CAACJ,QAAD,CAAW;AACxB,aAAO9C,IAAKC,CAAAA,SAAL,CAAe6C,QAAf,CAAP;AADwB;AAGzBM,YAAQ,CAACtG,IAAD,CAAO;AACd,aAAI,MAAOQ,OAAX,KAAsB,WAAtB,GAA0CA,MAAO6J,CAAAA,IAAP,CAAYrK,IAAZ,CAAkBwH,CAAAA,QAAlB,CAA2B,QAA3B,CAA1C,GACO8C,IAAA,CAAKtK,IAAL,CADP;AADc;AAIf4G,iBAAa,CAACf,IAAD,CAAO;AACnB,aAAQ,GAAE,IAAKF,CAAAA,QAAP,IAAmBE,IAAKvD,CAAAA,OAAL,CAAa,MAAb,EAAqB,EAArB,CAAnB,EAAR;AADmB;AAGpBoE,uBAAmB,CAACb,IAAD,CAAO;AACzB,aAAOA,IAAKvD,CAAAA,OAAL,CAAa,UAAb,EAAyB,EAAzB,CAA6BA,CAAAA,OAA7B,CAAqC,MAArC,EAA6C,GAA7C,CAAP;AADyB;AAG1B+G,8BAA0B,CAACZ,SAAD,CAAY;AACrC,YAAMnF,SAAS,EAAf;AACImF,eAAU8B,CAAAA,KAAd,IAAqBjH,MAAO7F,CAAAA,IAAP,CAAa,SAAQgL,SAAU8B,CAAAA,KAAlB,EAAb,CAArB;AACI9B,eAAU+B,CAAAA,MAAd,IAAsBlH,MAAO7F,CAAAA,IAAP,CAAa,UAASgL,SAAU+B,CAAAA,MAAnB,EAAb,CAAtB;AACI/B,eAAUgC,CAAAA,MAAd,IAAsBnH,MAAO7F,CAAAA,IAAP,CAAa,UAASgL,SAAUgC,CAAAA,MAAnB,EAAb,CAAtB;AACIhC,eAAUiC,CAAAA,MAAd,IAAsBpH,MAAO7F,CAAAA,IAAP,CAAa,UAASgL,SAAUiC,CAAAA,MAAnB,EAAb,CAAtB;AACIjC,eAAUkC,CAAAA,OAAd,IAAuBrH,MAAO7F,CAAAA,IAAP,CAAa,WAAUgL,SAAUkC,CAAAA,OAApB,EAAb,CAAvB;AACA,aAAOrH,MAAOsG,CAAAA,IAAP,CAAY,MAAZ,CAAP;AAPqC;AA/uBlB,GAArB;AAgwBA,QAAMgB,kBAAkB,CAAE,gBAAkB,mBAApB,CAAxB;AAIA,MAAIC,mBAAmB,aAAcjH,cAAd;AACtBhH,eAAW,CAACiC,GAAD,EAAMc,OAAA,GAAU,EAAhB,EAAoBkE,OAApB,EAA6BiH,IAA7B,CAAmC;AACvCC,SAAAA,GAAU,IAAI1D,GAAJ,CAAQxI,GAAR,CAAVkM;AACN,OAAID,IAAA,KAAS,IAAT,IAAiBA,IAAjB,KAA0B,IAAK,EAA/B,GAAmC,CAAnC,GAA4CA,IAAKE,CAAAA,cAArD,KACK,wBAAyBpI,CAAAA,IAAzB,CAA8BmI,GAAQE,CAAAA,QAAtC,CADL,IACwD,CAACF,GAAQE,CAAAA,QAASnL,CAAAA,QAAjB,CAA0B,mBAA1B,CADzD,KACyGiL,GAAQE,CAAAA,QADjH,GAC4HF,GAAQE,CAAAA,QAAS3I,CAAAA,OAAjB,CAAyB,WAAzB,EAAsC,mBAAtC,CAD5H;AAGM4I,UAAAA,GAAWH,GAAQI,CAAAA,IAAK7I,CAAAA,OAAb,CAAqB,KAArB,EAA4B,EAA5B,CAAX4I;AACAE,aAAAA,GAAezN,cAAA,CAAeA,cAAA,CAAe,EAAf,EAAmBiN,eAAnB,CAAf,EAAoDjL,OAApD,CAAfyL;AACN,WAAA,CAAMF,IAAN,EAAgBE,OAAhB,EAA8BvH,OAA9B,EAAuC,SAAvC,CAAA;AAP6C;AAyCxCwH,qBAAW,CAACvM,OAAD,CAAU;AAC1B,UAAIqF,QAAQ,IAAZ;AACA,aAAOA,KAAMF,CAAAA,eAAN,CAAsB,KAAM,EAAN,IAAY;AACxC,cAAMkF,cAAchF,KAAMmH,CAAAA,8BAAN,CAAqCxM,OAArC,CAApB;AACA,eAAO,MAAMc,GAAA,CAAIuE,KAAMvC,CAAAA,KAAV,EAAkB,GAAEuC,KAAMtF,CAAAA,GAAR,UAAqBsK,WAArB,EAAlB,EAAsD,CAAExJ,QAASwE,KAAMxE,CAAAA,OAAjB,CAAtD,CAAb;AAFwC,OAAlC,CAAP;AAF0B;AAwCrB4L,mBAAS,CAAC1E,EAAD,CAAK;AACnB,UAAI2E,SAAS,IAAb;AACA,aAAOA,MAAOvH,CAAAA,eAAP,CAAuB,KAAM,EAAN,IACtB,MAAMrE,GAAA,CAAI4L,MAAO5J,CAAAA,KAAX,EAAmB,GAAE4J,MAAO3M,CAAAA,GAAT,WAAuBgI,EAAvB,EAAnB,EAAgD,CAAElH,QAAS6L,MAAO7L,CAAAA,OAAlB,CAAhD,CADP,CAAP;AAFmB;AA2Cd8L,sBAAY,CAAC5E,EAAD,EAAK/H,OAAA,GAAU,CAAE4M,OAAQ,CAAA,CAAV,CAAf,CAAkC;AACnD,UAAItE,SAAS,IAAb;AACA,aAAOA,MAAOnD,CAAAA,eAAP,CAAuB,KAAM,EAAN,IACtB,MAAM7D,IAAA,CAAKgH,MAAOxF,CAAAA,KAAZ,EAAoB,GAAEwF,MAAOvI,CAAAA,GAAT,SAApB,EAA2C,CACvDgI,EADuD,EAEvD9F,KAAM8F,EAFiD,EAGvD8E,KAAM7M,OAAQ6M,CAAAA,IAHyC,EAIvDD,OAAQ5M,OAAQ4M,CAAAA,MAJuC,EAKvDE,gBAAiB9M,OAAQ+M,CAAAA,aAL8B,EAMvDC,mBAAoBhN,OAAQiN,CAAAA,gBAN2B,CAA3C,EAOV,CAAEpM,QAASyH,MAAOzH,CAAAA,OAAlB,CAPU,CADP,CAAP;AAFmD;AAgD9CqM,sBAAY,CAACnF,EAAD,EAAK/H,OAAL,CAAc;AAC/B,UAAI4I,SAAS,IAAb;AACA,aAAOA,MAAOzD,CAAAA,eAAP,CAAuB,KAAM,EAAN,IACtB,MAAM5D,GAAA,CAAIqH,MAAO9F,CAAAA,KAAX,EAAmB,GAAE8F,MAAO7I,CAAAA,GAAT,WAAuBgI,EAAvB,EAAnB,EAAgD,CAC5DA,EAD4D,EAE5D9F,KAAM8F,EAFsD,EAG5D6E,OAAQ5M,OAAQ4M,CAAAA,MAH4C,EAI5DE,gBAAiB9M,OAAQ+M,CAAAA,aAJmC,EAK5DC,mBAAoBhN,OAAQiN,CAAAA,gBALgC,CAAhD,EAMV,CAAEpM,QAAS+H,MAAO/H,CAAAA,OAAlB,CANU,CADP,CAAP;AAF+B;AAoC1BsM,qBAAW,CAACpF,EAAD,CAAK;AACrB,UAAIqF,SAAS,IAAb;AACA,aAAOA,MAAOjI,CAAAA,eAAP,CAAuB,KAAM,EAAN,IACtB,MAAM7D,IAAA,CAAK8L,MAAOtK,CAAAA,KAAZ,EAAoB,GAAEsK,MAAOrN,CAAAA,GAAT,WAAuBgI,EAAvB,QAApB,EAAuD,EAAvD,EAA2D,CAAElH,QAASuM,MAAOvM,CAAAA,OAAlB,CAA3D,CADP,CAAP;AAFqB;AA+BhBwM,sBAAY,CAACtF,EAAD,CAAK;AACtB,UAAImB,SAAS,IAAb;AACA,aAAOA,MAAO/D,CAAAA,eAAP,CAAuB,KAAM,EAAN,IACtB,MAAM1D,MAAA,CAAOyH,MAAOpG,CAAAA,KAAd,EAAsB,GAAEoG,MAAOnJ,CAAAA,GAAT,WAAuBgI,EAAvB,EAAtB,EAAmD,EAAnD,EAAuD,CAAElH,QAASqI,MAAOrI,CAAAA,OAAlB,CAAvD,CADP,CAAP;AAFsB;AAMvB2L,kCAA8B,CAACxM,OAAD,CAAU;AACvC,YAAMwE,SAAS,EAAf;AACIxE,aAAJ,KACK,OAIJ,IAJeA,OAIf,KAJwBwE,MAAO4B,CAAAA,KAI/B,GAJuC/G,MAAA,CAAOW,OAAQoG,CAAAA,KAAf,CAIvC,GAHI,QAGJ,IAHgBpG,OAGhB,KAHyBwE,MAAO6B,CAAAA,MAGhC,GAHyChH,MAAA,CAAOW,OAAQqG,CAAAA,MAAf,CAGzC,GAFIrG,OAAQsN,CAAAA,MAEZ,KAFoB9I,MAAO8I,CAAAA,MAE3B,GAFoCtN,OAAQsN,CAAAA,MAE5C,GADItN,OAAQuN,CAAAA,UACZ,KADwB/I,MAAO+I,CAAAA,UAC/B,GAD4CvN,OAAQuN,CAAAA,UACpD,GAAIvN,OAAQwN,CAAAA,SAAZ,KAAuBhJ,MAAOgJ,CAAAA,SAA9B,GAA0CxN,OAAQwN,CAAAA,SAAlD,CALD;AAOA,aAAOpP,MAAOC,CAAAA,IAAP,CAAYmG,MAAZ,CAAoBzF,CAAAA,MAApB,GAA6B,CAA7B,GAAiC,GAAjC,GAAmE2J,CAA5B,IAAI+E,eAAJ,CAAoBjJ,MAApB,CAA4BkE,EAAAA,QAA5B,EAAvC,GAAgF,EAAvF;AATuC;AAtPlB,GAAvB,EAyQIgF,yBAAyB,aAAc5I,cAAd;AAkB5BhH,eAAW,CAACiC,GAAD,EAAMc,OAAA,GAAU,EAAhB,EAAoBkE,OAApB,CAA6B;AACjCqH,SAAAA,GAAWrM,GAAIyD,CAAAA,OAAJ,CAAY,KAAZ,EAAmB,EAAnB,CAAX4I;AACAE,aAAAA,GAAezN,cAAA,CAAeA,cAAA,CAAe,EAAf,EAAmBiN,eAAnB,CAAf,EAAoDjL,OAApD,CAAfyL;AACN,WAAA,CAAMF,GAAN,EAAgBE,OAAhB,EAA8BvH,OAA9B,EAAuC,SAAvC,CAAA;AAHuC;AAuClC4H,sBAAY,CAAC1K,IAAD,CAAO;AACxB,UAAIoD,QAAQ,IAAZ;AACA,aAAOA,KAAMF,CAAAA,eAAN,CAAsB,KAAM,EAAN,IACrB,MAAM7D,IAAA,CAAK+D,KAAMvC,CAAAA,KAAX,EAAmB,GAAEuC,KAAMtF,CAAAA,GAAR,SAAnB,EAAyC,CAAEkC,IAAF,CAAzC,EAAmD,CAAEpB,QAASwE,KAAMxE,CAAAA,OAAjB,CAAnD,CADP,CAAP;AAFwB;AAoDnB0L,qBAAW,CAACvM,OAAD,CAAU;AAC1B,UAAI0M,SAAS,IAAb;AACA,aAAOA,MAAOvH,CAAAA,eAAP,CAAuB,KAAM,EAAN,IAAY;AACzC,YAAMwI,cAAc,IAAIF,eAAJ,EAApB;AACA,SAAKzN,OAAA,KAAY,IAAZ,IAAoBA,OAApB,KAAgC,IAAK,EAArC,GAAyC,IAAK,EAA9C,GAAkDA,OAAQoG,CAAAA,KAA/D,MAA0E,IAAK,EAA/E,IAAkFuH,WAAYlF,CAAAA,GAAZ,CAAgB,OAAhB,EAAyBzI,OAAQoG,CAAAA,KAAMsC,CAAAA,QAAd,EAAzB,CAAlF;AACA,SAAK1I,OAAA,KAAY,IAAZ,IAAoBA,OAApB,KAAgC,IAAK,EAArC,GAAyC,IAAK,EAA9C,GAAkDA,OAAQqG,CAAAA,MAA/D,MAA2E,IAAK,EAAhF,IAAmFsH,WAAYlF,CAAAA,GAAZ,CAAgB,QAAhB,EAA0BzI,OAAQqG,CAAAA,MAAOqC,CAAAA,QAAf,EAA1B,CAAnF;AACA,SAAI1I,OAAA,KAAY,IAAZ,IAAoBA,OAApB,KAAgC,IAAK,EAArC,GAAyC,CAAzC,GAAkDA,OAAQuN,CAAAA,UAA9D,KAA0EI,WAAYlF,CAAAA,GAAZ,CAAgB,YAAhB,EAA8BzI,OAAQuN,CAAAA,UAAtC,CAA1E;AACA,SAAIvN,OAAA,KAAY,IAAZ,IAAoBA,OAApB,KAAgC,IAAK,EAArC,GAAyC,CAAzC,GAAkDA,OAAQwN,CAAAA,SAA9D,KAAyEG,WAAYlF,CAAAA,GAAZ,CAAgB,WAAhB,EAA6BzI,OAAQwN,CAAAA,SAArC,CAAzE;AACA,SAAIxN,OAAA,KAAY,IAAZ,IAAoBA,OAApB,KAAgC,IAAK,EAArC,GAAyC,CAAzC,GAAkDA,OAAQsN,CAAAA,MAA9D,KAAsEK,WAAYlF,CAAAA,GAAZ,CAAgB,QAAhB,EAA0BzI,OAAQsN,CAAAA,MAAlC,CAAtE;AACMjD,mBAAAA,GAAcsD,WAAYjF,CAAAA,QAAZ,EAAd2B;AAEN,eAAO,MAAMvJ,GAAA,CAAI4L,MAAO5J,CAAAA,KAAX,EADDuH,WAAAtK,GAAe,GAAE2M,MAAO3M,CAAAA,GAAT,WAAuBsK,WAAvB,EAAftK,GAAuD,GAAE2M,MAAO3M,CAAAA,GAAT,SACtD,EAAuB,CAAEc,QAAS6L,MAAO7L,CAAAA,OAAlB,CAAvB,CAAb;AATyC,OAAnC,CAAP;AAF0B;AA6CrBwM,sBAAY,CAACzJ,UAAD,CAAa;AAC9B,UAAI0E,SAAS,IAAb;AACA,aAAOA,MAAOnD,CAAAA,eAAP,CAAuB,KAAM,EAAN,IACtB,MAAM1D,MAAA,CAAO6G,MAAOxF,CAAAA,KAAd,EAAsB,GAAEwF,MAAOvI,CAAAA,GAAT,WAAuB6D,UAAvB,EAAtB,EAA2D,EAA3D,EAA+D,CAAE/C,QAASyH,MAAOzH,CAAAA,OAAlB,CAA/D,CADP,CAAP;AAF8B;AAiI/B0K,QAAI,CAAC3H,UAAD,CAAa;AAChB,UAAIgF,SAAS,IAAb;AACA,UAAI,CAACjF,iBAAA,CAAkBC,UAAlB,CAAL;AAAoC,cAAM,IAAIhC,YAAJ,CAAiB,oJAAjB,CAAN;AAApC;AACMgM,gBAAAA,GAAU,IAAIjM,UAAWkM,CAAAA,kBAAf,CAAkC,CACjD5B,QAAS,IAAKlM,CAAAA,GADmC,EAEjD+N,YAAalK,UAFoC,EAGjDmK,KAAM,CACLlB,KAAM,QADD,EAELmB,WAAYA,KAAM,EAANA,IAAYpF,MAAO/H,CAAAA,OAF1B,CAH2C,EAOjDiC,MAAO,IAAKA,CAAAA,KAPqC,CAAlC,CAAV8K;AASN,YAAM5I,qBAAqB,IAAKA,CAAAA,kBAAhC;AACA,aAAO,IAAIiJ,KAAJ,CAAUL,UAAV,EAAmB,CAAE9M,GAAG,CAACoN,MAAD,EAASC,IAAT,CAAe;AAC7C,cAAM5O,QAAQ2O,MAAA,CAAOC,IAAP,CAAd;AACA,eAAI,MAAO5O,MAAX,KAAqB,UAArB,GAAwCA,KAAxC,GACO,KAAM,CAAC,GAAGsD,IAAJ,CAAN,IAAmB;AACzB,aAAI;AACH,mBAAO,CACN3B,KAAM,MAAM3B,KAAMX,CAAAA,KAAN,CAAYsP,MAAZ,EAAoBrL,IAApB,CADN,EAENrF,MAAO,IAFD,CAAP;AADG,WAKF,QAAOA,KAAP,CAAc;AACf,gBAAIwH,kBAAJ;AAAwB,oBAAMxH,KAAN;AAAxB;AACA,mBAAO,CACN0D,KAAM,IADA,EAEN1D,KAFM,CAAP;AAFe;AANS,SAD1B;AAF6C,OAApB,CAAnB,CAAP;AAbgB;AA3RW,GAzQ7B;AA6kBI4Q,YAAAA,GAAiB,aAActJ,cAAd;AAEpBhH,eAAW,CAACiC,GAAD,EAAMc,OAAA,GAAU,EAAhB,EAAoBkE,OAApB,CAA6B;AACjCqH,SAAAA,GAAWrM,GAAIyD,CAAAA,OAAJ,CAAY,KAAZ,EAAmB,EAAnB,CAAX4I;AACAE,aAAAA,GAAezN,cAAA,CAAeA,cAAA,CAAe,EAAf,EAAmBiN,eAAnB,CAAf,EAAoD,EAApD,EAAwD,CAAE,eAAgB,kBAAlB,CAAxD,EAAgGjL,OAAhG,CAAfyL;AACN,WAAA,CAAMF,GAAN,EAAgBE,OAAhB,EAA8BvH,OAA9B,EAAuC,SAAvC,CAAA;AAHuC;AAMlCsJ,qBAAW,CAACrO,OAAD,CAAU;AAC1B,UAAIqF,QAAQ,IAAZ;AACA,aAAOA,KAAMF,CAAAA,eAAN,CAAsB,KAAM,EAAN,IACrB,MAAMN,UAAWvD,CAAAA,IAAX,CAAgB+D,KAAMvC,CAAAA,KAAtB,EAA8B,GAAEuC,KAAMtF,CAAAA,GAAR,cAA9B,EAAyDC,OAAzD,EAAkE,CAAEa,QAASwE,KAAMxE,CAAAA,OAAjB,CAAlE,CADe,IACkF,EADxG,CAAP;AAF0B;AAOrByN,kBAAQ,CAACC,gBAAD,EAAmBC,SAAnB,CAA8B;AAC3C,UAAI9B,SAAS,IAAb;AACA,aAAOA,MAAOvH,CAAAA,eAAP,CAAuB,KAAM,EAAN,IACtB,MAAMN,UAAWvD,CAAAA,IAAX,CAAgBoL,MAAO5J,CAAAA,KAAvB,EAA+B,GAAE4J,MAAO3M,CAAAA,GAAT,WAA/B,EAAwD,CACpEwO,gBADoE,EAEpEC,SAFoE,CAAxD,EAGV,CAAE3N,QAAS6L,MAAO7L,CAAAA,OAAlB,CAHU,CADP,CAAP;AAF2C;AAUtC4N,qBAAW,CAACzO,OAAD,CAAU;AAC1B,UAAIsI,SAAS,IAAb;AACA,aAAOA,MAAOnD,CAAAA,eAAP,CAAuB,KAAM,EAAN,IACtB,MAAMN,UAAWvD,CAAAA,IAAX,CAAgBgH,MAAOxF,CAAAA,KAAvB,EAA+B,GAAEwF,MAAOvI,CAAAA,GAAT,cAA/B,EAA2DC,OAA3D,EAAoE,CAAEa,QAASyH,MAAOzH,CAAAA,OAAlB,CAApE,CADP,CAAP;AAF0B;AAOrB6N,qBAAW,CAACH,gBAAD,EAAmBC,SAAnB,CAA8B;AAC9C,UAAI5F,SAAS,IAAb;AACA,aAAOA,MAAOzD,CAAAA,eAAP,CAAuB,KAAM,EAAN,IACtB,MAAMN,UAAWvD,CAAAA,IAAX,CAAgBsH,MAAO9F,CAAAA,KAAvB,EAA+B,GAAE8F,MAAO7I,CAAAA,GAAT,cAA/B,EAA2D,CACvEwO,gBADuE,EAEvEC,SAFuE,CAA3D,EAGV,CAAE3N,QAAS+H,MAAO/H,CAAAA,OAAlB,CAHU,CADgB,IAIM,EAJ7B,CAAP;AAF8C;AAhC3B,GAAjBuN;AAkDJ,MAAIO,gBAAgB,aAAc7J,cAAd;AAEnBhH,eAAW,CAACiC,GAAD,EAAMc,OAAA,GAAU,EAAhB,EAAoBkE,OAApB,CAA6B;AACjCqH,SAAAA,GAAWrM,GAAIyD,CAAAA,OAAJ,CAAY,KAAZ,EAAmB,EAAnB,CAAX4I;AACAE,aAAAA,GAAezN,cAAA,CAAeA,cAAA,CAAe,EAAf,EAAmBiN,eAAnB,CAAf,EAAoD,EAApD,EAAwD,CAAE,eAAgB,kBAAlB,CAAxD,EAAgGjL,OAAhG,CAAfyL;AACN,WAAA,CAAMF,GAAN,EAAgBE,OAAhB,EAA8BvH,OAA9B,EAAuC,SAAvC,CAAA;AAHuC;AAMlC6J,oBAAU,CAAC5O,OAAD,CAAU;AACzB,UAAIqF,QAAQ,IAAZ;AACA,UAAIrF,OAAQ6O,CAAAA,OAAQ9P,CAAAA,MAApB,GAA6B,CAA7B,IAAkCiB,OAAQ6O,CAAAA,OAAQ9P,CAAAA,MAAlD,GAA2D,GAA3D;AAAgE,cAAU8C,KAAJ,CAAU,mDAAV,CAAN;AAAhE;AACA,aAAOwD,KAAMF,CAAAA,eAAN,CAAsB,KAAM,EAAN,IACrB,MAAMN,UAAWvD,CAAAA,IAAX,CAAgB+D,KAAMvC,CAAAA,KAAtB,EAA8B,GAAEuC,KAAMtF,CAAAA,GAAR,aAA9B,EAAwDC,OAAxD,EAAiE,CAAEa,QAASwE,KAAMxE,CAAAA,OAAjB,CAAjE,CADe,IACiF,EADvG,CAAP;AAHyB;AAQpBiO,oBAAU,CAAC9O,OAAD,CAAU;AACzB,UAAI0M,SAAS,IAAb;AACA,aAAOA,MAAOvH,CAAAA,eAAP,CAAuB,KAAM,EAAN,IACtB,MAAMN,UAAWvD,CAAAA,IAAX,CAAgBoL,MAAO5J,CAAAA,KAAvB,EAA+B,GAAE4J,MAAO3M,CAAAA,GAAT,aAA/B,EAA0DC,OAA1D,EAAmE,CAAEa,QAAS6L,MAAO7L,CAAAA,OAAlB,CAAnE,CADP,CAAP;AAFyB;AAOpBkO,qBAAW,CAAC/O,OAAD,CAAU;AAC1B,UAAIsI,SAAS,IAAb;AACA,UAAItI,OAAQgP,CAAAA,YAAZ,KAA6B,IAAK,EAAlC,CAAqC;AACpC,YAAIhP,OAAQgP,CAAAA,YAAZ,GAA2B,CAA3B,IAAgChP,OAAQgP,CAAAA,YAAxC,GAAuD,EAAvD;AAA2D,gBAAUnN,KAAJ,CAAU,uCAAV,CAAN;AAA3D;AACA,YAAI7B,OAAQiP,CAAAA,YAAZ,KAA6B,IAAK,EAAlC,KACKjP,OAAQiP,CAAAA,YADb,GAC4B,CAD5B,IACiCjP,OAAQiP,CAAAA,YADzC,IACyDjP,OAAQgP,CAAAA,YADjE;AAC+E,gBAAUnN,KAAJ,CAAW,sCAAqC7B,OAAQgP,CAAAA,YAA7C,GAA4D,CAA5D,EAAX,CAAN;AAD/E;AAFoC;AAMrC,aAAO1G,MAAOnD,CAAAA,eAAP,CAAuB,KAAM,EAAN,IACtB,MAAMN,UAAWvD,CAAAA,IAAX,CAAgBgH,MAAOxF,CAAAA,KAAvB,EAA+B,GAAEwF,MAAOvI,CAAAA,GAAT,cAA/B,EAA2DC,OAA3D,EAAoE,CAAEa,QAASyH,MAAOzH,CAAAA,OAAlB,CAApE,CADP,CAAP;AAR0B;AAarBqO,sBAAY,CAAClP,OAAD,CAAU;AAC3B,UAAI4I,SAAS,IAAb;AACA,aAAOA,MAAOzD,CAAAA,eAAP,CAAuB,KAAM,EAAN,IACtB,MAAMN,UAAWvD,CAAAA,IAAX,CAAgBsH,MAAO9F,CAAAA,KAAvB,EAA+B,GAAE8F,MAAO7I,CAAAA,GAAT,eAA/B,EAA4DC,OAA5D,EAAqE,CAAEa,QAAS+H,MAAO/H,CAAAA,OAAlB,CAArE,CADP,CAAP;AAF2B;AAOtBsO,uBAAa,CAACnP,OAAD,CAAU;AAC5B,UAAIoN,SAAS,IAAb;AACA,UAAIpN,OAAQ3B,CAAAA,IAAKU,CAAAA,MAAjB,GAA0B,CAA1B,IAA+BiB,OAAQ3B,CAAAA,IAAKU,CAAAA,MAA5C,GAAqD,GAArD;AAA0D,cAAU8C,KAAJ,CAAU,iDAAV,CAAN;AAA1D;AACA,aAAOuL,MAAOjI,CAAAA,eAAP,CAAuB,KAAM,EAAN,IACtB,MAAMN,UAAWvD,CAAAA,IAAX,CAAgB8L,MAAOtK,CAAAA,KAAvB,EAA+B,GAAEsK,MAAOrN,CAAAA,GAAT,gBAA/B,EAA6DC,OAA7D,EAAsE,CAAEa,QAASuM,MAAOvM,CAAAA,OAAlB,CAAtE,CADgB,IACsF,EAD7G,CAAP;AAH4B;AA3CV,GAApB;AA2DIuO,eAAAA,GAAkB,aAActK,cAAd;AAErBhH,eAAW,CAACiC,GAAD,EAAMc,OAAA,GAAU,EAAhB,EAAoBkE,OAApB,CAA6B;AACjCqH,SAAAA,GAAWrM,GAAIyD,CAAAA,OAAJ,CAAY,KAAZ,EAAmB,EAAnB,CAAX4I;AACAE,aAAAA,GAAezN,cAAA,CAAeA,cAAA,CAAe,EAAf,EAAmBiN,eAAnB,CAAf,EAAoD,EAApD,EAAwD,CAAE,eAAgB,kBAAlB,CAAxD,EAAgGjL,OAAhG,CAAfyL;AACN,WAAA,CAAMF,GAAN,EAAgBE,OAAhB,EAA8BvH,OAA9B,EAAuC,SAAvC,CAAA;AAHuC;AAMlC4H,sBAAY,CAAC4B,gBAAD,CAAmB;AACpC,UAAIlJ,QAAQ,IAAZ;AACA,aAAOA,KAAMF,CAAAA,eAAN,CAAsB,KAAM,EAAN,IACrB,MAAMN,UAAWvD,CAAAA,IAAX,CAAgB+D,KAAMvC,CAAAA,KAAtB,EAA8B,GAAEuC,KAAMtF,CAAAA,GAAR,qBAA9B,EAAgE,CAAEwO,gBAAF,CAAhE,EAAsF,CAAE1N,QAASwE,KAAMxE,CAAAA,OAAjB,CAAtF,CADe,IACsG,EAD5H,CAAP;AAFoC;AAO/B4L,mBAAS,CAAC8B,gBAAD,CAAmB;AACjC,UAAI7B,SAAS,IAAb;AACA,aAAOA,MAAOvH,CAAAA,eAAP,CAAuB,KAAM,EAAN,IACtB,MAAMN,UAAWvD,CAAAA,IAAX,CAAgBoL,MAAO5J,CAAAA,KAAvB,EAA+B,GAAE4J,MAAO3M,CAAAA,GAAT,kBAA/B,EAA+D,CAAEwO,gBAAF,CAA/D,EAAqF,CAAE1N,QAAS6L,MAAO7L,CAAAA,OAAlB,CAArF,CADP,CAAP;AAFiC;AAO5B0L,qBAAW,CAACvM,OAAA,GAAU,EAAX,CAAe;AAC/B,UAAIsI,SAAS,IAAb;AACA,aAAOA,MAAOnD,CAAAA,eAAP,CAAuB,KAAM,EAAN,IACtB,MAAMN,UAAWvD,CAAAA,IAAX,CAAgBgH,MAAOxF,CAAAA,KAAvB,EAA+B,GAAEwF,MAAOvI,CAAAA,GAAT,oBAA/B,EAAiEC,OAAjE,EAA0E,CAAEa,QAASyH,MAAOzH,CAAAA,OAAlB,CAA1E,CADP,CAAP;AAF+B;AAO1BwM,sBAAY,CAACkB,gBAAD,CAAmB;AACpC,UAAI3F,SAAS,IAAb;AACA,aAAOA,MAAOzD,CAAAA,eAAP,CAAuB,KAAM,EAAN,IACtB,MAAMN,UAAWvD,CAAAA,IAAX,CAAgBsH,MAAO9F,CAAAA,KAAvB,EAA+B,GAAE8F,MAAO7I,CAAAA,GAAT,qBAA/B,EAAkE,CAAEwO,gBAAF,CAAlE,EAAwF,CAAE1N,QAAS+H,MAAO/H,CAAAA,OAAlB,CAAxF,CADgB,IACwG,EAD/H,CAAP;AAFoC;AA7BhB,GAAlBuO;AAiFJ,MAAIC,uBAAuB,aAAcD,cAAd;AAkB1BtR,eAAW,CAACiC,GAAD,EAAMC,OAAA,GAAU,EAAhB,CAAoB;AAC9B,WAAA,CAAMD,GAAN,EAAWC,OAAQa,CAAAA,OAAnB,IAA8B,EAA9B,EAAkCb,OAAQ8C,CAAAA,KAA1C,CAAA;AAD8B;AAqB/ByI,QAAI,CAACgD,gBAAD,CAAmB;AACtB,aAAO,IAAIe,iBAAJ,CAAsB,IAAKvP,CAAAA,GAA3B,EAAgC,IAAKc,CAAAA,OAArC,EAA8C0N,gBAA9C,EAAgE,IAAKzL,CAAAA,KAArE,CAAP;AADsB;AAwBjB6J,sBAAY,CAAC4B,gBAAD,CAAmB;AAEpC,aADiCgB,CAAA,EAAAA,IAAM5C,KAAMA,CAAAA,YAAZ4C,CAC1B,EAA6BpQ,CAAAA,IAA7B,CAD4DkG,IAC5D,EAAyCkJ,gBAAzC,CAAP;AAFoC;AA0B/B9B,mBAAS,CAAC8B,gBAAD,CAAmB;AAEjC,aAD8BiB,CAAA,EAAAA,IAAM/C,KAAMA,CAAAA,SAAZ+C,CACvB,EAA0BrQ,CAAAA,IAA1B,CADuDuN,IACvD,EAAuC6B,gBAAvC,CAAP;AAFiC;AA4B5BhC,qBAAW,CAACvM,OAAA,GAAU,EAAX,CAAe;AAE/B,aADgCyP,CAAA,EAAAA,IAAMlD,KAAMA,CAAAA,WAAZkD,CACzB,EAA4BtQ,CAAAA,IAA5B,CAD2DmJ,IAC3D,EAAyCtI,OAAzC,CAAP;AAF+B;AAyB1BqN,sBAAY,CAACkB,gBAAD,CAAmB;AAEpC,aADiCmB,CAAA,EAAAA,IAAMrC,KAAMA,CAAAA,YAAZqC,CAC1B,EAA6BvQ,CAAAA,IAA7B,CAD6DyJ,IAC7D,EAA0C2F,gBAA1C,CAAP;AAFoC;AA9IX,GAA3B,EA4JIe,oBAAoB,aAAclB,WAAd;AAcvBtQ,eAAW,CAACiC,GAAD,EAAMc,OAAN,EAAe0N,gBAAf,EAAiCxJ,OAAjC,CAA0C;AACpD,WAAA,CAAMhF,GAAN,EAAWc,OAAX,EAAoBkE,OAApB,CAAA;AACA,UAAKwJ,CAAAA,gBAAL,GAAwBA,gBAAxB;AAFoD;AA+B/CF,qBAAW,CAACrO,OAAD,CAAU;AAE1B,aADgC2P,CAAA,EAAAA,IAAMtB,KAAMA,CAAAA,WAAZsB,CACzB,EAA4BxQ,CAAAA,IAA5B,CAD2DiO,IAC3D,EAAyCvO,cAAA,CAAeA,cAAA,CAAe,EAAf,EAAmBmB,OAAnB,CAAf,EAA4C,EAA5C,EAAgD,CAAEuO,iBADhCnB,IACyDmB,CAAAA,gBAA3B,CAAhD,CAAzC,CAAP;AAF0B;AAuBrBE,qBAAW,CAACzO,OAAA,GAAU,EAAX,CAAe;AAE/B,aADgC4P,CAAA,EAAAA,IAAMnB,KAAMA,CAAAA,WAAZmB,CACzB,EAA4BzQ,CAAAA,IAA5B,CAD2D+J,IAC3D,EAAyCrK,cAAA,CAAeA,cAAA,CAAe,EAAf,EAAmBmB,OAAnB,CAAf,EAA4C,EAA5C,EAAgD,CAAEuO,iBADhCrF,IACyDqF,CAAAA,gBAA3B,CAAhD,CAAzC,CAAP;AAF+B;AAwB1BD,kBAAQ,CAACE,SAAD,CAAY;AAEzB,aAD6BqB,CAAA,EAAAA,IAAMvB,KAAMA,CAAAA,QAAZuB,CACtB,EAAyB1Q,CAAAA,IAAzB,CADqDoK,IACrD,EADqDA,IACRgF,CAAAA,gBAA7C,EAA+DC,SAA/D,CAAP;AAFyB;AAuBpBE,qBAAW,CAACF,SAAD,CAAY;AAE5B,aADgCsB,CAAA,EAAAA,IAAMpB,KAAMA,CAAAA,WAAZoB,CACzB,EAA4B3Q,CAAAA,IAA5B,CAD2DuK,IAC3D,EAD2DA,IACX6E,CAAAA,gBAAhD,EAAkEC,SAAlE,CAAP;AAF4B;AAmC7BuB,SAAK,CAACvB,SAAD,CAAY;AAChB,aAAO,IAAIwB,gBAAJ,CAAqB,IAAKjQ,CAAAA,GAA1B,EAA+B,IAAKc,CAAAA,OAApC,EAA6C,IAAK0N,CAAAA,gBAAlD,EAAoEC,SAApE,EAA+E,IAAK1L,CAAAA,KAApF,CAAP;AADgB;AAtJM,GA5JxB,EA+TIkN,mBAAmB,aAAcrB,cAAd;AAetB7Q,eAAW,CAACiC,GAAD,EAAMc,OAAN,EAAe0N,gBAAf,EAAiCC,SAAjC,EAA4CzJ,OAA5C,CAAqD;AAC/D,WAAA,CAAMhF,GAAN,EAAWc,OAAX,EAAoBkE,OAApB,CAAA;AACA,UAAKwJ,CAAAA,gBAAL,GAAwBA,gBAAxB;AACA,UAAKC,CAAAA,SAAL,GAAiBA,SAAjB;AAH+D;AAgC1DI,oBAAU,CAAC5O,OAAD,CAAU;AAEzB,aAD+BiQ,CAAA,EAAAA,IAAMrB,KAAMA,CAAAA,UAAZqB,CACxB,EAA2B9Q,CAAAA,IAA3B,CADyD+K,IACzD,EAAwCrL,cAAA,CAAeA,cAAA,CAAe,EAAf,EAAmBmB,OAAnB,CAAf,EAA4C,EAA5C,EAAgD,CAC9FuO,iBAF+DrE,IAEtCqE,CAAAA,gBADqE,EAE9FC,UAH+DtE,IAG7CsE,CAAAA,SAF4E,CAAhD,CAAxC,CAAP;AAFyB;AA6BpBM,oBAAU,CAAC9O,OAAD,CAAU;AAEzB,aAD+BkQ,CAAA,EAAAA,IAAMpB,KAAMA,CAAAA,UAAZoB,CACxB,EAA2B/Q,CAAAA,IAA3B,CAD0DsL,IAC1D,EAAyC5L,cAAA,CAAeA,cAAA,CAAe,EAAf,EAAmBmB,OAAnB,CAAf,EAA4C,EAA5C,EAAgD,CAC/FuO,iBAFgE9D,IAEtC8D,CAAAA,gBADqE,EAE/FC,UAHgE/D,IAG7C+D,CAAAA,SAF4E,CAAhD,CAAzC,CAAP;AAFyB;AA6BpBO,qBAAW,CAAC/O,OAAA,GAAU,EAAX,CAAe;AAE/B,aADgCmQ,CAAA,EAAAA,IAAMpB,KAAMA,CAAAA,WAAZoB,CACzB,EAA4BhR,CAAAA,IAA5B,CAD4DwL,IAC5D,EAA0C9L,cAAA,CAAeA,cAAA,CAAe,EAAf,EAAmBmB,OAAnB,CAAf,EAA4C,EAA5C,EAAgD,CAChGuO,iBAFkE5D,IAExC4D,CAAAA,gBADsE,EAEhGC,UAHkE7D,IAG/C6D,CAAAA,SAF6E,CAAhD,CAA1C,CAAP;AAF+B;AAgC1BU,sBAAY,CAAClP,OAAD,CAAU;AAE3B,aADiCoQ,CAAA,EAAAA,IAAMlB,KAAMA,CAAAA,YAAZkB,CAC1B,EAA6BjR,CAAAA,IAA7B,CAD8D6L,IAC9D,EAA2CnM,cAAA,CAAeA,cAAA,CAAe,EAAf,EAAmBmB,OAAnB,CAAf,EAA4C,EAA5C,EAAgD,CACjGuO,iBAFoEvD,IAE1CuD,CAAAA,gBADuE,EAEjGC,UAHoExD,IAGjDwD,CAAAA,SAF8E,CAAhD,CAA3C,CAAP;AAF2B;AA4BtBW,uBAAa,CAACnP,OAAD,CAAU;AAE5B,aADkCqQ,CAAA,EAAAA,IAAMlB,KAAMA,CAAAA,aAAZkB,CAC3B,EAA8BlR,CAAAA,IAA9B,CADgEgM,IAChE,EAA4CtM,cAAA,CAAeA,cAAA,CAAe,EAAf,EAAmBmB,OAAnB,CAAf,EAA4C,EAA5C,EAAgD,CAClGuO,iBAFsEpD,IAE5CoD,CAAAA,gBADwE,EAElGC,UAHsErD,IAGnDqD,CAAAA,SAF+E,CAAhD,CAA5C,CAAP;AAF4B;AArKP,GA/TvB;AA+eI8B,kBAAAA,GAAgB,aAAcvE,iBAAd;AAenBjO,eAAW,CAACiC,GAAD,EAAMc,OAAA,GAAU,EAAhB,EAAoBkE,OAApB,EAA6BiH,IAA7B,CAAmC;AAC7C,WAAA,CAAMjM,GAAN,EAAWc,OAAX,EAAoBkE,OAApB,EAA6BiH,IAA7B,CAAA;AAD6C;AAc9CT,QAAI,CAACxD,EAAD,CAAK;AACR,aAAO,IAAInB,cAAJ,CAAmB,IAAK7G,CAAAA,GAAxB,EAA6B,IAAKc,CAAAA,OAAlC,EAA2CkH,EAA3C,EAA+C,IAAKjF,CAAAA,KAApD,CAAP;AADQ;AAcL,eAAU,EAAA;AACb,aAAO,IAAIuM,oBAAJ,CAAyB,IAAKtP,CAAAA,GAA9B,GAAoC,SAApC,EAA+C,CACrDc,QAAS,IAAKA,CAAAA,OADuC,EAErDiC,MAAO,IAAKA,CAAAA,KAFyC,CAA/C,CAAP;AADa;AAiBV,iBAAY,EAAA;AACf,aAAO,IAAI4K,sBAAJ,CAA2B,IAAK3N,CAAAA,GAAhC,GAAsC,UAAtC,EAAkD,IAAKc,CAAAA,OAAvD,EAAgE,IAAKiC,CAAAA,KAArE,CAAP;AADe;AA5DG,GAAhBwN;AAkEJhT,SAAQoQ,CAAAA,sBAAR,GAAiCA,sBAAjC;AACApQ,SAAQ4E,CAAAA,eAAR,GAA0BA,eAA1B;AACA5E,SAAQgT,CAAAA,aAAR,GAAwBA,gBAAxB;AACAhT,SAAQsE,CAAAA,YAAR,GAAuBA,YAAvB;AACAtE,SAAQ8E,CAAAA,mBAAR,GAA8BA,mBAA9B;AACA9E,SAAQiF,CAAAA,sBAAR,GAAiCA,MAAjC;AACAjF,SAAQ+R,CAAAA,oBAAR,GAA+BA,oBAA/B;AACA/R,SAAQgF,CAAAA,mBAAR,GAA8BA,OAA9B;AACAhF,SAAQmF,CAAAA,uBAAR,GAAkCA,uBAAlC;AACAnF,SAAQkF,CAAAA,0BAAR,GAAqCA,0BAArC;AACAlF,SAAQ8R,CAAAA,eAAR,GAA0BA,aAA1B;AACA9R,SAAQgS,CAAAA,iBAAR,GAA4BA,iBAA5B;AACAhS,SAAQqR,CAAAA,aAAR,GAAwBA,aAAxB;AACArR,SAAQ8Q,CAAAA,cAAR,GAAyBA,UAAzB;AACA9Q,SAAQ0S,CAAAA,gBAAR,GAA2BA,gBAA3B;AACA1S,SAAQC,CAAAA,cAAR,GAAyBA,cAAzB;AACAD,SAAQiT,CAAAA,qBAAR,GAhiFAA,QAA8B,CAAC/S,KAAD,CAAQ;AACrC,WAAOD,cAAA,CAAeC,KAAf,CAAP,IAAgCA,KAAA,CAAA,SAAhC,KAAuD,SAAvD;AADqC,GAgiFtC;AAxmF6G,CAA7G;;\",\n\"sources\":[\"node_modules/@supabase/storage-js/dist/index.cjs\"],\n\"sourcesContent\":[\"shadow$provide[\\\"module$node_modules$$supabase$storage_js$dist$index_cjs\\\"] = function(require,module,exports) {\\nvar Buffer = require('buffer').Buffer;\\nlet iceberg_js = require(\\\"iceberg-js\\\");\\n\\n//#region src/lib/common/errors.ts\\n/**\\n* Base error class for all Storage errors\\n* Supports both 'storage' and 'vectors' namespaces\\n*/\\nvar StorageError = class extends Error {\\n\\tconstructor(message, namespace = \\\"storage\\\", status, statusCode) {\\n\\t\\tsuper(message);\\n\\t\\tthis.__isStorageError = true;\\n\\t\\tthis.namespace = namespace;\\n\\t\\tthis.name = namespace === \\\"vectors\\\" ? \\\"StorageVectorsError\\\" : \\\"StorageError\\\";\\n\\t\\tthis.status = status;\\n\\t\\tthis.statusCode = statusCode;\\n\\t}\\n};\\n/**\\n* Type guard to check if an error is a StorageError\\n* @param error - The error to check\\n* @returns True if the error is a StorageError\\n*/\\nfunction isStorageError(error) {\\n\\treturn typeof error === \\\"object\\\" && error !== null && \\\"__isStorageError\\\" in error;\\n}\\n/**\\n* API error returned from Storage service\\n* Includes HTTP status code and service-specific error code\\n*/\\nvar StorageApiError = class extends StorageError {\\n\\tconstructor(message, status, statusCode, namespace = \\\"storage\\\") {\\n\\t\\tsuper(message, namespace, status, statusCode);\\n\\t\\tthis.name = namespace === \\\"vectors\\\" ? \\\"StorageVectorsApiError\\\" : \\\"StorageApiError\\\";\\n\\t\\tthis.status = status;\\n\\t\\tthis.statusCode = statusCode;\\n\\t}\\n\\ttoJSON() {\\n\\t\\treturn {\\n\\t\\t\\tname: this.name,\\n\\t\\t\\tmessage: this.message,\\n\\t\\t\\tstatus: this.status,\\n\\t\\t\\tstatusCode: this.statusCode\\n\\t\\t};\\n\\t}\\n};\\n/**\\n* Unknown error that doesn't match expected error patterns\\n* Wraps the original error for debugging\\n*/\\nvar StorageUnknownError = class extends StorageError {\\n\\tconstructor(message, originalError, namespace = \\\"storage\\\") {\\n\\t\\tsuper(message, namespace);\\n\\t\\tthis.name = namespace === \\\"vectors\\\" ? \\\"StorageVectorsUnknownError\\\" : \\\"StorageUnknownError\\\";\\n\\t\\tthis.originalError = originalError;\\n\\t}\\n};\\n/**\\n* @deprecated Use StorageError with namespace='vectors' instead\\n* Alias for backward compatibility with existing vector storage code\\n*/\\nvar StorageVectorsError = class extends StorageError {\\n\\tconstructor(message) {\\n\\t\\tsuper(message, \\\"vectors\\\");\\n\\t}\\n};\\n/**\\n* Type guard to check if an error is a StorageVectorsError\\n* @param error - The error to check\\n* @returns True if the error is a StorageVectorsError\\n*/\\nfunction isStorageVectorsError(error) {\\n\\treturn isStorageError(error) && error[\\\"namespace\\\"] === \\\"vectors\\\";\\n}\\n/**\\n* @deprecated Use StorageApiError with namespace='vectors' instead\\n* Alias for backward compatibility with existing vector storage code\\n*/\\nvar StorageVectorsApiError = class extends StorageApiError {\\n\\tconstructor(message, status, statusCode) {\\n\\t\\tsuper(message, status, statusCode, \\\"vectors\\\");\\n\\t}\\n};\\n/**\\n* @deprecated Use StorageUnknownError with namespace='vectors' instead\\n* Alias for backward compatibility with existing vector storage code\\n*/\\nvar StorageVectorsUnknownError = class extends StorageUnknownError {\\n\\tconstructor(message, originalError) {\\n\\t\\tsuper(message, originalError, \\\"vectors\\\");\\n\\t}\\n};\\n/**\\n* Error codes specific to S3 Vectors API\\n* Maps AWS service errors to application-friendly error codes\\n*/\\nlet StorageVectorsErrorCode = /* @__PURE__ */ function(StorageVectorsErrorCode$1) {\\n\\t/** Internal server fault (HTTP 500) */\\n\\tStorageVectorsErrorCode$1[\\\"InternalError\\\"] = \\\"InternalError\\\";\\n\\t/** Resource already exists / conflict (HTTP 409) */\\n\\tStorageVectorsErrorCode$1[\\\"S3VectorConflictException\\\"] = \\\"S3VectorConflictException\\\";\\n\\t/** Resource not found (HTTP 404) */\\n\\tStorageVectorsErrorCode$1[\\\"S3VectorNotFoundException\\\"] = \\\"S3VectorNotFoundException\\\";\\n\\t/** Delete bucket while not empty (HTTP 400) */\\n\\tStorageVectorsErrorCode$1[\\\"S3VectorBucketNotEmpty\\\"] = \\\"S3VectorBucketNotEmpty\\\";\\n\\t/** Exceeds bucket quota/limit (HTTP 400) */\\n\\tStorageVectorsErrorCode$1[\\\"S3VectorMaxBucketsExceeded\\\"] = \\\"S3VectorMaxBucketsExceeded\\\";\\n\\t/** Exceeds index quota/limit (HTTP 400) */\\n\\tStorageVectorsErrorCode$1[\\\"S3VectorMaxIndexesExceeded\\\"] = \\\"S3VectorMaxIndexesExceeded\\\";\\n\\treturn StorageVectorsErrorCode$1;\\n}({});\\n\\n//#endregion\\n//#region src/lib/common/helpers.ts\\n/**\\n* Resolves the fetch implementation to use\\n* Uses custom fetch if provided, otherwise uses native fetch\\n*\\n* @param customFetch - Optional custom fetch implementation\\n* @returns Resolved fetch function\\n*/\\nconst resolveFetch = (customFetch) => {\\n\\tif (customFetch) return (...args) => customFetch(...args);\\n\\treturn (...args) => fetch(...args);\\n};\\n/**\\n* Determine if input is a plain object\\n* An object is plain if it's created by either {}, new Object(), or Object.create(null)\\n*\\n* @param value - Value to check\\n* @returns True if value is a plain object\\n* @source https://github.com/sindresorhus/is-plain-obj\\n*/\\nconst isPlainObject = (value) => {\\n\\tif (typeof value !== \\\"object\\\" || value === null) return false;\\n\\tconst prototype = Object.getPrototypeOf(value);\\n\\treturn (prototype === null || prototype === Object.prototype || Object.getPrototypeOf(prototype) === null) && !(Symbol.toStringTag in value) && !(Symbol.iterator in value);\\n};\\n/**\\n* Recursively converts object keys from snake_case to camelCase\\n* Used for normalizing API responses\\n*\\n* @param item - Object to convert\\n* @returns Converted object with camelCase keys\\n*/\\nconst recursiveToCamel = (item) => {\\n\\tif (Array.isArray(item)) return item.map((el) => recursiveToCamel(el));\\n\\telse if (typeof item === \\\"function\\\" || item !== Object(item)) return item;\\n\\tconst result = {};\\n\\tObject.entries(item).forEach(([key, value]) => {\\n\\t\\tconst newKey = key.replace(/([-_][a-z])/gi, (c) => c.toUpperCase().replace(/[-_]/g, \\\"\\\"));\\n\\t\\tresult[newKey] = recursiveToCamel(value);\\n\\t});\\n\\treturn result;\\n};\\n/**\\n* Validates if a given bucket name is valid according to Supabase Storage API rules\\n* Mirrors backend validation from: storage/src/storage/limits.ts:isValidBucketName()\\n*\\n* Rules:\\n* - Length: 1-100 characters\\n* - Allowed characters: alphanumeric (a-z, A-Z, 0-9), underscore (_), and safe special characters\\n* - Safe special characters: ! - . * ' ( ) space & $ @ = ; : + , ?\\n* - Forbidden: path separators (/, \\\\), path traversal (..), leading/trailing whitespace\\n*\\n* AWS S3 Reference: https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-keys.html\\n*\\n* @param bucketName - The bucket name to validate\\n* @returns true if valid, false otherwise\\n*/\\nconst isValidBucketName = (bucketName) => {\\n\\tif (!bucketName || typeof bucketName !== \\\"string\\\") return false;\\n\\tif (bucketName.length === 0 || bucketName.length > 100) return false;\\n\\tif (bucketName.trim() !== bucketName) return false;\\n\\tif (bucketName.includes(\\\"/\\\") || bucketName.includes(\\\"\\\\\\\\\\\")) return false;\\n\\treturn /^[\\\\w!.\\\\*'() &$@=;:+,?-]+$/.test(bucketName);\\n};\\n\\n//#endregion\\n//#region \\\\0@oxc-project+runtime@0.101.0/helpers/typeof.js\\nfunction _typeof(o) {\\n\\t\\\"@babel/helpers - typeof\\\";\\n\\treturn _typeof = \\\"function\\\" == typeof Symbol && \\\"symbol\\\" == typeof Symbol.iterator ? function(o$1) {\\n\\t\\treturn typeof o$1;\\n\\t} : function(o$1) {\\n\\t\\treturn o$1 && \\\"function\\\" == typeof Symbol && o$1.constructor === Symbol && o$1 !== Symbol.prototype ? \\\"symbol\\\" : typeof o$1;\\n\\t}, _typeof(o);\\n}\\n\\n//#endregion\\n//#region \\\\0@oxc-project+runtime@0.101.0/helpers/toPrimitive.js\\nfunction toPrimitive(t, r) {\\n\\tif (\\\"object\\\" != _typeof(t) || !t) return t;\\n\\tvar e = t[Symbol.toPrimitive];\\n\\tif (void 0 !== e) {\\n\\t\\tvar i = e.call(t, r || \\\"default\\\");\\n\\t\\tif (\\\"object\\\" != _typeof(i)) return i;\\n\\t\\tthrow new TypeError(\\\"@@toPrimitive must return a primitive value.\\\");\\n\\t}\\n\\treturn (\\\"string\\\" === r ? String : Number)(t);\\n}\\n\\n//#endregion\\n//#region \\\\0@oxc-project+runtime@0.101.0/helpers/toPropertyKey.js\\nfunction toPropertyKey(t) {\\n\\tvar i = toPrimitive(t, \\\"string\\\");\\n\\treturn \\\"symbol\\\" == _typeof(i) ? i : i + \\\"\\\";\\n}\\n\\n//#endregion\\n//#region \\\\0@oxc-project+runtime@0.101.0/helpers/defineProperty.js\\nfunction _defineProperty(e, r, t) {\\n\\treturn (r = toPropertyKey(r)) in e ? Object.defineProperty(e, r, {\\n\\t\\tvalue: t,\\n\\t\\tenumerable: !0,\\n\\t\\tconfigurable: !0,\\n\\t\\twritable: !0\\n\\t}) : e[r] = t, e;\\n}\\n\\n//#endregion\\n//#region \\\\0@oxc-project+runtime@0.101.0/helpers/objectSpread2.js\\nfunction ownKeys(e, r) {\\n\\tvar t = Object.keys(e);\\n\\tif (Object.getOwnPropertySymbols) {\\n\\t\\tvar o = Object.getOwnPropertySymbols(e);\\n\\t\\tr && (o = o.filter(function(r$1) {\\n\\t\\t\\treturn Object.getOwnPropertyDescriptor(e, r$1).enumerable;\\n\\t\\t})), t.push.apply(t, o);\\n\\t}\\n\\treturn t;\\n}\\nfunction _objectSpread2(e) {\\n\\tfor (var r = 1; r < arguments.length; r++) {\\n\\t\\tvar t = null != arguments[r] ? arguments[r] : {};\\n\\t\\tr % 2 ? ownKeys(Object(t), !0).forEach(function(r$1) {\\n\\t\\t\\t_defineProperty(e, r$1, t[r$1]);\\n\\t\\t}) : Object.getOwnPropertyDescriptors ? Object.defineProperties(e, Object.getOwnPropertyDescriptors(t)) : ownKeys(Object(t)).forEach(function(r$1) {\\n\\t\\t\\tObject.defineProperty(e, r$1, Object.getOwnPropertyDescriptor(t, r$1));\\n\\t\\t});\\n\\t}\\n\\treturn e;\\n}\\n\\n//#endregion\\n//#region src/lib/common/fetch.ts\\n/**\\n* Extracts error message from various error response formats\\n* @param err - Error object from API\\n* @returns Human-readable error message\\n*/\\nconst _getErrorMessage = (err) => {\\n\\tvar _err$error;\\n\\treturn err.msg || err.message || err.error_description || (typeof err.error === \\\"string\\\" ? err.error : (_err$error = err.error) === null || _err$error === void 0 ? void 0 : _err$error.message) || JSON.stringify(err);\\n};\\n/**\\n* Handles fetch errors and converts them to Storage error types\\n* @param error - The error caught from fetch\\n* @param reject - Promise rejection function\\n* @param options - Fetch options that may affect error handling\\n* @param namespace - Error namespace ('storage' or 'vectors')\\n*/\\nconst handleError = async (error, reject, options, namespace) => {\\n\\tif (error && typeof error === \\\"object\\\" && \\\"status\\\" in error && \\\"ok\\\" in error && typeof error.status === \\\"number\\\" && !(options === null || options === void 0 ? void 0 : options.noResolveJson)) {\\n\\t\\tconst responseError = error;\\n\\t\\tconst status = responseError.status || 500;\\n\\t\\tif (typeof responseError.json === \\\"function\\\") responseError.json().then((err) => {\\n\\t\\t\\tconst statusCode = (err === null || err === void 0 ? void 0 : err.statusCode) || (err === null || err === void 0 ? void 0 : err.code) || status + \\\"\\\";\\n\\t\\t\\treject(new StorageApiError(_getErrorMessage(err), status, statusCode, namespace));\\n\\t\\t}).catch(() => {\\n\\t\\t\\tif (namespace === \\\"vectors\\\") {\\n\\t\\t\\t\\tconst statusCode = status + \\\"\\\";\\n\\t\\t\\t\\treject(new StorageApiError(responseError.statusText || `HTTP ${status} error`, status, statusCode, namespace));\\n\\t\\t\\t} else {\\n\\t\\t\\t\\tconst statusCode = status + \\\"\\\";\\n\\t\\t\\t\\treject(new StorageApiError(responseError.statusText || `HTTP ${status} error`, status, statusCode, namespace));\\n\\t\\t\\t}\\n\\t\\t});\\n\\t\\telse {\\n\\t\\t\\tconst statusCode = status + \\\"\\\";\\n\\t\\t\\treject(new StorageApiError(responseError.statusText || `HTTP ${status} error`, status, statusCode, namespace));\\n\\t\\t}\\n\\t} else reject(new StorageUnknownError(_getErrorMessage(error), error, namespace));\\n};\\n/**\\n* Builds request parameters for fetch calls\\n* @param method - HTTP method\\n* @param options - Custom fetch options\\n* @param parameters - Additional fetch parameters like AbortSignal\\n* @param body - Request body (will be JSON stringified if plain object)\\n* @returns Complete fetch request parameters\\n*/\\nconst _getRequestParams = (method, options, parameters, body) => {\\n\\tconst params = {\\n\\t\\tmethod,\\n\\t\\theaders: (options === null || options === void 0 ? void 0 : options.headers) || {}\\n\\t};\\n\\tif (method === \\\"GET\\\" || method === \\\"HEAD\\\" || !body) return _objectSpread2(_objectSpread2({}, params), parameters);\\n\\tif (isPlainObject(body)) {\\n\\t\\tparams.headers = _objectSpread2({ \\\"Content-Type\\\": \\\"application/json\\\" }, options === null || options === void 0 ? void 0 : options.headers);\\n\\t\\tparams.body = JSON.stringify(body);\\n\\t} else params.body = body;\\n\\tif (options === null || options === void 0 ? void 0 : options.duplex) params.duplex = options.duplex;\\n\\treturn _objectSpread2(_objectSpread2({}, params), parameters);\\n};\\n/**\\n* Internal request handler that wraps fetch with error handling\\n* @param fetcher - Fetch function to use\\n* @param method - HTTP method\\n* @param url - Request URL\\n* @param options - Custom fetch options\\n* @param parameters - Additional fetch parameters\\n* @param body - Request body\\n* @param namespace - Error namespace ('storage' or 'vectors')\\n* @returns Promise with parsed response or error\\n*/\\nasync function _handleRequest(fetcher, method, url, options, parameters, body, namespace) {\\n\\treturn new Promise((resolve, reject) => {\\n\\t\\tfetcher(url, _getRequestParams(method, options, parameters, body)).then((result) => {\\n\\t\\t\\tif (!result.ok) throw result;\\n\\t\\t\\tif (options === null || options === void 0 ? void 0 : options.noResolveJson) return result;\\n\\t\\t\\tif (namespace === \\\"vectors\\\") {\\n\\t\\t\\t\\tconst contentType = result.headers.get(\\\"content-type\\\");\\n\\t\\t\\t\\tif (result.headers.get(\\\"content-length\\\") === \\\"0\\\" || result.status === 204) return {};\\n\\t\\t\\t\\tif (!contentType || !contentType.includes(\\\"application/json\\\")) return {};\\n\\t\\t\\t}\\n\\t\\t\\treturn result.json();\\n\\t\\t}).then((data) => resolve(data)).catch((error) => handleError(error, reject, options, namespace));\\n\\t});\\n}\\n/**\\n* Creates a fetch API with the specified namespace\\n* @param namespace - Error namespace ('storage' or 'vectors')\\n* @returns Object with HTTP method functions\\n*/\\nfunction createFetchApi(namespace = \\\"storage\\\") {\\n\\treturn {\\n\\t\\tget: async (fetcher, url, options, parameters) => {\\n\\t\\t\\treturn _handleRequest(fetcher, \\\"GET\\\", url, options, parameters, void 0, namespace);\\n\\t\\t},\\n\\t\\tpost: async (fetcher, url, body, options, parameters) => {\\n\\t\\t\\treturn _handleRequest(fetcher, \\\"POST\\\", url, options, parameters, body, namespace);\\n\\t\\t},\\n\\t\\tput: async (fetcher, url, body, options, parameters) => {\\n\\t\\t\\treturn _handleRequest(fetcher, \\\"PUT\\\", url, options, parameters, body, namespace);\\n\\t\\t},\\n\\t\\thead: async (fetcher, url, options, parameters) => {\\n\\t\\t\\treturn _handleRequest(fetcher, \\\"HEAD\\\", url, _objectSpread2(_objectSpread2({}, options), {}, { noResolveJson: true }), parameters, void 0, namespace);\\n\\t\\t},\\n\\t\\tremove: async (fetcher, url, body, options, parameters) => {\\n\\t\\t\\treturn _handleRequest(fetcher, \\\"DELETE\\\", url, options, parameters, body, namespace);\\n\\t\\t}\\n\\t};\\n}\\nconst defaultApi = createFetchApi(\\\"storage\\\");\\nconst { get, post, put, head, remove } = defaultApi;\\nconst vectorsApi = createFetchApi(\\\"vectors\\\");\\n\\n//#endregion\\n//#region src/lib/common/BaseApiClient.ts\\n/**\\n* @ignore\\n* Base API client class for all Storage API classes\\n* Provides common infrastructure for error handling and configuration\\n*\\n* @typeParam TError - The error type (StorageError or subclass)\\n*/\\nvar BaseApiClient = class {\\n\\t/**\\n\\t* Creates a new BaseApiClient instance\\n\\t* @param url - Base URL for API requests\\n\\t* @param headers - Default headers for API requests\\n\\t* @param fetch - Optional custom fetch implementation\\n\\t* @param namespace - Error namespace ('storage' or 'vectors')\\n\\t*/\\n\\tconstructor(url, headers = {}, fetch$1, namespace = \\\"storage\\\") {\\n\\t\\tthis.shouldThrowOnError = false;\\n\\t\\tthis.url = url;\\n\\t\\tthis.headers = headers;\\n\\t\\tthis.fetch = resolveFetch(fetch$1);\\n\\t\\tthis.namespace = namespace;\\n\\t}\\n\\t/**\\n\\t* Enable throwing errors instead of returning them.\\n\\t* When enabled, errors are thrown instead of returned in { data, error } format.\\n\\t*\\n\\t* @returns this - For method chaining\\n\\t*/\\n\\tthrowOnError() {\\n\\t\\tthis.shouldThrowOnError = true;\\n\\t\\treturn this;\\n\\t}\\n\\t/**\\n\\t* Set an HTTP header for the request.\\n\\t* Creates a shallow copy of headers to avoid mutating shared state.\\n\\t*\\n\\t* @param name - Header name\\n\\t* @param value - Header value\\n\\t* @returns this - For method chaining\\n\\t*/\\n\\tsetHeader(name, value) {\\n\\t\\tthis.headers = _objectSpread2(_objectSpread2({}, this.headers), {}, { [name]: value });\\n\\t\\treturn this;\\n\\t}\\n\\t/**\\n\\t* Handles API operation with standardized error handling\\n\\t* Eliminates repetitive try-catch blocks across all API methods\\n\\t*\\n\\t* This wrapper:\\n\\t* 1. Executes the operation\\n\\t* 2. Returns { data, error: null } on success\\n\\t* 3. Returns { data: null, error } on failure (if shouldThrowOnError is false)\\n\\t* 4. Throws error on failure (if shouldThrowOnError is true)\\n\\t*\\n\\t* @typeParam T - The expected data type from the operation\\n\\t* @param operation - Async function that performs the API call\\n\\t* @returns Promise with { data, error } tuple\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* async listBuckets() {\\n\\t*   return this.handleOperation(async () => {\\n\\t*     return await get(this.fetch, `${this.url}/bucket`, {\\n\\t*       headers: this.headers,\\n\\t*     })\\n\\t*   })\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync handleOperation(operation) {\\n\\t\\tvar _this = this;\\n\\t\\ttry {\\n\\t\\t\\treturn {\\n\\t\\t\\t\\tdata: await operation(),\\n\\t\\t\\t\\terror: null\\n\\t\\t\\t};\\n\\t\\t} catch (error) {\\n\\t\\t\\tif (_this.shouldThrowOnError) throw error;\\n\\t\\t\\tif (isStorageError(error)) return {\\n\\t\\t\\t\\tdata: null,\\n\\t\\t\\t\\terror\\n\\t\\t\\t};\\n\\t\\t\\tthrow error;\\n\\t\\t}\\n\\t}\\n};\\n\\n//#endregion\\n//#region src/packages/StreamDownloadBuilder.ts\\nvar StreamDownloadBuilder = class {\\n\\tconstructor(downloadFn, shouldThrowOnError) {\\n\\t\\tthis.downloadFn = downloadFn;\\n\\t\\tthis.shouldThrowOnError = shouldThrowOnError;\\n\\t}\\n\\tthen(onfulfilled, onrejected) {\\n\\t\\treturn this.execute().then(onfulfilled, onrejected);\\n\\t}\\n\\tasync execute() {\\n\\t\\tvar _this = this;\\n\\t\\ttry {\\n\\t\\t\\treturn {\\n\\t\\t\\t\\tdata: (await _this.downloadFn()).body,\\n\\t\\t\\t\\terror: null\\n\\t\\t\\t};\\n\\t\\t} catch (error) {\\n\\t\\t\\tif (_this.shouldThrowOnError) throw error;\\n\\t\\t\\tif (isStorageError(error)) return {\\n\\t\\t\\t\\tdata: null,\\n\\t\\t\\t\\terror\\n\\t\\t\\t};\\n\\t\\t\\tthrow error;\\n\\t\\t}\\n\\t}\\n};\\n\\n//#endregion\\n//#region src/packages/BlobDownloadBuilder.ts\\nlet _Symbol$toStringTag;\\n_Symbol$toStringTag = Symbol.toStringTag;\\nvar BlobDownloadBuilder = class {\\n\\tconstructor(downloadFn, shouldThrowOnError) {\\n\\t\\tthis.downloadFn = downloadFn;\\n\\t\\tthis.shouldThrowOnError = shouldThrowOnError;\\n\\t\\tthis[_Symbol$toStringTag] = \\\"BlobDownloadBuilder\\\";\\n\\t\\tthis.promise = null;\\n\\t}\\n\\tasStream() {\\n\\t\\treturn new StreamDownloadBuilder(this.downloadFn, this.shouldThrowOnError);\\n\\t}\\n\\tthen(onfulfilled, onrejected) {\\n\\t\\treturn this.getPromise().then(onfulfilled, onrejected);\\n\\t}\\n\\tcatch(onrejected) {\\n\\t\\treturn this.getPromise().catch(onrejected);\\n\\t}\\n\\tfinally(onfinally) {\\n\\t\\treturn this.getPromise().finally(onfinally);\\n\\t}\\n\\tgetPromise() {\\n\\t\\tif (!this.promise) this.promise = this.execute();\\n\\t\\treturn this.promise;\\n\\t}\\n\\tasync execute() {\\n\\t\\tvar _this = this;\\n\\t\\ttry {\\n\\t\\t\\treturn {\\n\\t\\t\\t\\tdata: await (await _this.downloadFn()).blob(),\\n\\t\\t\\t\\terror: null\\n\\t\\t\\t};\\n\\t\\t} catch (error) {\\n\\t\\t\\tif (_this.shouldThrowOnError) throw error;\\n\\t\\t\\tif (isStorageError(error)) return {\\n\\t\\t\\t\\tdata: null,\\n\\t\\t\\t\\terror\\n\\t\\t\\t};\\n\\t\\t\\tthrow error;\\n\\t\\t}\\n\\t}\\n};\\n\\n//#endregion\\n//#region src/packages/StorageFileApi.ts\\nconst DEFAULT_SEARCH_OPTIONS = {\\n\\tlimit: 100,\\n\\toffset: 0,\\n\\tsortBy: {\\n\\t\\tcolumn: \\\"name\\\",\\n\\t\\torder: \\\"asc\\\"\\n\\t}\\n};\\nconst DEFAULT_FILE_OPTIONS = {\\n\\tcacheControl: \\\"3600\\\",\\n\\tcontentType: \\\"text/plain;charset=UTF-8\\\",\\n\\tupsert: false\\n};\\nvar StorageFileApi = class extends BaseApiClient {\\n\\tconstructor(url, headers = {}, bucketId, fetch$1) {\\n\\t\\tsuper(url, headers, fetch$1, \\\"storage\\\");\\n\\t\\tthis.bucketId = bucketId;\\n\\t}\\n\\t/**\\n\\t* Uploads a file to an existing bucket or replaces an existing file at the specified path with a new one.\\n\\t*\\n\\t* @param method HTTP method.\\n\\t* @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\\n\\t* @param fileBody The body of the file to be stored in the bucket.\\n\\t*/\\n\\tasync uploadOrUpdate(method, path, fileBody, fileOptions) {\\n\\t\\tvar _this = this;\\n\\t\\treturn _this.handleOperation(async () => {\\n\\t\\t\\tlet body;\\n\\t\\t\\tconst options = _objectSpread2(_objectSpread2({}, DEFAULT_FILE_OPTIONS), fileOptions);\\n\\t\\t\\tlet headers = _objectSpread2(_objectSpread2({}, _this.headers), method === \\\"POST\\\" && { \\\"x-upsert\\\": String(options.upsert) });\\n\\t\\t\\tconst metadata = options.metadata;\\n\\t\\t\\tif (typeof Blob !== \\\"undefined\\\" && fileBody instanceof Blob) {\\n\\t\\t\\t\\tbody = new FormData();\\n\\t\\t\\t\\tbody.append(\\\"cacheControl\\\", options.cacheControl);\\n\\t\\t\\t\\tif (metadata) body.append(\\\"metadata\\\", _this.encodeMetadata(metadata));\\n\\t\\t\\t\\tbody.append(\\\"\\\", fileBody);\\n\\t\\t\\t} else if (typeof FormData !== \\\"undefined\\\" && fileBody instanceof FormData) {\\n\\t\\t\\t\\tbody = fileBody;\\n\\t\\t\\t\\tif (!body.has(\\\"cacheControl\\\")) body.append(\\\"cacheControl\\\", options.cacheControl);\\n\\t\\t\\t\\tif (metadata && !body.has(\\\"metadata\\\")) body.append(\\\"metadata\\\", _this.encodeMetadata(metadata));\\n\\t\\t\\t} else {\\n\\t\\t\\t\\tbody = fileBody;\\n\\t\\t\\t\\theaders[\\\"cache-control\\\"] = `max-age=${options.cacheControl}`;\\n\\t\\t\\t\\theaders[\\\"content-type\\\"] = options.contentType;\\n\\t\\t\\t\\tif (metadata) headers[\\\"x-metadata\\\"] = _this.toBase64(_this.encodeMetadata(metadata));\\n\\t\\t\\t\\tif ((typeof ReadableStream !== \\\"undefined\\\" && body instanceof ReadableStream || body && typeof body === \\\"object\\\" && \\\"pipe\\\" in body && typeof body.pipe === \\\"function\\\") && !options.duplex) options.duplex = \\\"half\\\";\\n\\t\\t\\t}\\n\\t\\t\\tif (fileOptions === null || fileOptions === void 0 ? void 0 : fileOptions.headers) headers = _objectSpread2(_objectSpread2({}, headers), fileOptions.headers);\\n\\t\\t\\tconst cleanPath = _this._removeEmptyFolders(path);\\n\\t\\t\\tconst _path = _this._getFinalPath(cleanPath);\\n\\t\\t\\tconst data = await (method == \\\"PUT\\\" ? put : post)(_this.fetch, `${_this.url}/object/${_path}`, body, _objectSpread2({ headers }, (options === null || options === void 0 ? void 0 : options.duplex) ? { duplex: options.duplex } : {}));\\n\\t\\t\\treturn {\\n\\t\\t\\t\\tpath: cleanPath,\\n\\t\\t\\t\\tid: data.Id,\\n\\t\\t\\t\\tfullPath: data.Key\\n\\t\\t\\t};\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Uploads a file to an existing bucket.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\\n\\t* @param fileBody The body of the file to be stored in the bucket.\\n\\t* @param fileOptions Optional file upload options including cacheControl, contentType, upsert, and metadata.\\n\\t* @returns Promise with response containing file path, id, and fullPath or error\\n\\t*\\n\\t* @example Upload file\\n\\t* ```js\\n\\t* const avatarFile = event.target.files[0]\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .upload('public/avatar1.png', avatarFile, {\\n\\t*     cacheControl: '3600',\\n\\t*     upsert: false\\n\\t*   })\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"path\\\": \\\"public/avatar1.png\\\",\\n\\t*     \\\"fullPath\\\": \\\"avatars/public/avatar1.png\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*\\n\\t* @example Upload file using `ArrayBuffer` from base64 file data\\n\\t* ```js\\n\\t* import { decode } from 'base64-arraybuffer'\\n\\t*\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .upload('public/avatar1.png', decode('base64FileData'), {\\n\\t*     contentType: 'image/png'\\n\\t*   })\\n\\t* ```\\n\\t*/\\n\\tasync upload(path, fileBody, fileOptions) {\\n\\t\\treturn this.uploadOrUpdate(\\\"POST\\\", path, fileBody, fileOptions);\\n\\t}\\n\\t/**\\n\\t* Upload a file with a token generated from `createSignedUploadUrl`.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\\n\\t* @param token The token generated from `createSignedUploadUrl`\\n\\t* @param fileBody The body of the file to be stored in the bucket.\\n\\t* @param fileOptions HTTP headers (cacheControl, contentType, etc.).\\n\\t* **Note:** The `upsert` option has no effect here. To enable upsert behavior,\\n\\t* pass `{ upsert: true }` when calling `createSignedUploadUrl()` instead.\\n\\t* @returns Promise with response containing file path and fullPath or error\\n\\t*\\n\\t* @example Upload to a signed URL\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .uploadToSignedUrl('folder/cat.jpg', 'token-from-createSignedUploadUrl', file)\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"path\\\": \\\"folder/cat.jpg\\\",\\n\\t*     \\\"fullPath\\\": \\\"avatars/folder/cat.jpg\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync uploadToSignedUrl(path, token, fileBody, fileOptions) {\\n\\t\\tvar _this3 = this;\\n\\t\\tconst cleanPath = _this3._removeEmptyFolders(path);\\n\\t\\tconst _path = _this3._getFinalPath(cleanPath);\\n\\t\\tconst url = new URL(_this3.url + `/object/upload/sign/${_path}`);\\n\\t\\turl.searchParams.set(\\\"token\\\", token);\\n\\t\\treturn _this3.handleOperation(async () => {\\n\\t\\t\\tlet body;\\n\\t\\t\\tconst options = _objectSpread2({ upsert: DEFAULT_FILE_OPTIONS.upsert }, fileOptions);\\n\\t\\t\\tconst headers = _objectSpread2(_objectSpread2({}, _this3.headers), { \\\"x-upsert\\\": String(options.upsert) });\\n\\t\\t\\tif (typeof Blob !== \\\"undefined\\\" && fileBody instanceof Blob) {\\n\\t\\t\\t\\tbody = new FormData();\\n\\t\\t\\t\\tbody.append(\\\"cacheControl\\\", options.cacheControl);\\n\\t\\t\\t\\tbody.append(\\\"\\\", fileBody);\\n\\t\\t\\t} else if (typeof FormData !== \\\"undefined\\\" && fileBody instanceof FormData) {\\n\\t\\t\\t\\tbody = fileBody;\\n\\t\\t\\t\\tbody.append(\\\"cacheControl\\\", options.cacheControl);\\n\\t\\t\\t} else {\\n\\t\\t\\t\\tbody = fileBody;\\n\\t\\t\\t\\theaders[\\\"cache-control\\\"] = `max-age=${options.cacheControl}`;\\n\\t\\t\\t\\theaders[\\\"content-type\\\"] = options.contentType;\\n\\t\\t\\t}\\n\\t\\t\\treturn {\\n\\t\\t\\t\\tpath: cleanPath,\\n\\t\\t\\t\\tfullPath: (await put(_this3.fetch, url.toString(), body, { headers })).Key\\n\\t\\t\\t};\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Creates a signed upload URL.\\n\\t* Signed upload URLs can be used to upload files to the bucket without further authentication.\\n\\t* They are valid for 2 hours.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param path The file path, including the current file name. For example `folder/image.png`.\\n\\t* @param options.upsert If set to true, allows the file to be overwritten if it already exists.\\n\\t* @returns Promise with response containing signed upload URL, token, and path or error\\n\\t*\\n\\t* @example Create Signed Upload URL\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .createSignedUploadUrl('folder/cat.jpg')\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"signedUrl\\\": \\\"https://example.supabase.co/storage/v1/object/upload/sign/avatars/folder/cat.jpg?token=<TOKEN>\\\",\\n\\t*     \\\"path\\\": \\\"folder/cat.jpg\\\",\\n\\t*     \\\"token\\\": \\\"<TOKEN>\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync createSignedUploadUrl(path, options) {\\n\\t\\tvar _this4 = this;\\n\\t\\treturn _this4.handleOperation(async () => {\\n\\t\\t\\tlet _path = _this4._getFinalPath(path);\\n\\t\\t\\tconst headers = _objectSpread2({}, _this4.headers);\\n\\t\\t\\tif (options === null || options === void 0 ? void 0 : options.upsert) headers[\\\"x-upsert\\\"] = \\\"true\\\";\\n\\t\\t\\tconst data = await post(_this4.fetch, `${_this4.url}/object/upload/sign/${_path}`, {}, { headers });\\n\\t\\t\\tconst url = new URL(_this4.url + data.url);\\n\\t\\t\\tconst token = url.searchParams.get(\\\"token\\\");\\n\\t\\t\\tif (!token) throw new StorageError(\\\"No token returned by API\\\");\\n\\t\\t\\treturn {\\n\\t\\t\\t\\tsignedUrl: url.toString(),\\n\\t\\t\\t\\tpath,\\n\\t\\t\\t\\ttoken\\n\\t\\t\\t};\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Replaces an existing file at the specified path with a new one.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to update.\\n\\t* @param fileBody The body of the file to be stored in the bucket.\\n\\t* @param fileOptions Optional file upload options including cacheControl, contentType, upsert, and metadata.\\n\\t* @returns Promise with response containing file path, id, and fullPath or error\\n\\t*\\n\\t* @example Update file\\n\\t* ```js\\n\\t* const avatarFile = event.target.files[0]\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .update('public/avatar1.png', avatarFile, {\\n\\t*     cacheControl: '3600',\\n\\t*     upsert: true\\n\\t*   })\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"path\\\": \\\"public/avatar1.png\\\",\\n\\t*     \\\"fullPath\\\": \\\"avatars/public/avatar1.png\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*\\n\\t* @example Update file using `ArrayBuffer` from base64 file data\\n\\t* ```js\\n\\t* import {decode} from 'base64-arraybuffer'\\n\\t*\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .update('public/avatar1.png', decode('base64FileData'), {\\n\\t*     contentType: 'image/png'\\n\\t*   })\\n\\t* ```\\n\\t*/\\n\\tasync update(path, fileBody, fileOptions) {\\n\\t\\treturn this.uploadOrUpdate(\\\"PUT\\\", path, fileBody, fileOptions);\\n\\t}\\n\\t/**\\n\\t* Moves an existing file to a new path in the same bucket.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param fromPath The original file path, including the current file name. For example `folder/image.png`.\\n\\t* @param toPath The new file path, including the new file name. For example `folder/image-new.png`.\\n\\t* @param options The destination options.\\n\\t* @returns Promise with response containing success message or error\\n\\t*\\n\\t* @example Move file\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .move('public/avatar1.png', 'private/avatar2.png')\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"message\\\": \\\"Successfully moved\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync move(fromPath, toPath, options) {\\n\\t\\tvar _this6 = this;\\n\\t\\treturn _this6.handleOperation(async () => {\\n\\t\\t\\treturn await post(_this6.fetch, `${_this6.url}/object/move`, {\\n\\t\\t\\t\\tbucketId: _this6.bucketId,\\n\\t\\t\\t\\tsourceKey: fromPath,\\n\\t\\t\\t\\tdestinationKey: toPath,\\n\\t\\t\\t\\tdestinationBucket: options === null || options === void 0 ? void 0 : options.destinationBucket\\n\\t\\t\\t}, { headers: _this6.headers });\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Copies an existing file to a new path in the same bucket.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param fromPath The original file path, including the current file name. For example `folder/image.png`.\\n\\t* @param toPath The new file path, including the new file name. For example `folder/image-copy.png`.\\n\\t* @param options The destination options.\\n\\t* @returns Promise with response containing copied file path or error\\n\\t*\\n\\t* @example Copy file\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .copy('public/avatar1.png', 'private/avatar2.png')\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"path\\\": \\\"avatars/private/avatar2.png\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync copy(fromPath, toPath, options) {\\n\\t\\tvar _this7 = this;\\n\\t\\treturn _this7.handleOperation(async () => {\\n\\t\\t\\treturn { path: (await post(_this7.fetch, `${_this7.url}/object/copy`, {\\n\\t\\t\\t\\tbucketId: _this7.bucketId,\\n\\t\\t\\t\\tsourceKey: fromPath,\\n\\t\\t\\t\\tdestinationKey: toPath,\\n\\t\\t\\t\\tdestinationBucket: options === null || options === void 0 ? void 0 : options.destinationBucket\\n\\t\\t\\t}, { headers: _this7.headers })).Key };\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Creates a signed URL. Use a signed URL to share a file for a fixed amount of time.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param path The file path, including the current file name. For example `folder/image.png`.\\n\\t* @param expiresIn The number of seconds until the signed URL expires. For example, `60` for a URL which is valid for one minute.\\n\\t* @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\\n\\t* @param options.transform Transform the asset before serving it to the client.\\n\\t* @returns Promise with response containing signed URL or error\\n\\t*\\n\\t* @example Create Signed URL\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .createSignedUrl('folder/avatar1.png', 60)\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"signedUrl\\\": \\\"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*\\n\\t* @example Create a signed URL for an asset with transformations\\n\\t* ```js\\n\\t* const { data } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .createSignedUrl('folder/avatar1.png', 60, {\\n\\t*     transform: {\\n\\t*       width: 100,\\n\\t*       height: 100,\\n\\t*     }\\n\\t*   })\\n\\t* ```\\n\\t*\\n\\t* @example Create a signed URL which triggers the download of the asset\\n\\t* ```js\\n\\t* const { data } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .createSignedUrl('folder/avatar1.png', 60, {\\n\\t*     download: true,\\n\\t*   })\\n\\t* ```\\n\\t*/\\n\\tasync createSignedUrl(path, expiresIn, options) {\\n\\t\\tvar _this8 = this;\\n\\t\\treturn _this8.handleOperation(async () => {\\n\\t\\t\\tlet _path = _this8._getFinalPath(path);\\n\\t\\t\\tlet data = await post(_this8.fetch, `${_this8.url}/object/sign/${_path}`, _objectSpread2({ expiresIn }, (options === null || options === void 0 ? void 0 : options.transform) ? { transform: options.transform } : {}), { headers: _this8.headers });\\n\\t\\t\\tconst downloadQueryParam = (options === null || options === void 0 ? void 0 : options.download) ? `&download=${options.download === true ? \\\"\\\" : options.download}` : \\\"\\\";\\n\\t\\t\\treturn { signedUrl: encodeURI(`${_this8.url}${data.signedURL}${downloadQueryParam}`) };\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Creates multiple signed URLs. Use a signed URL to share a file for a fixed amount of time.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param paths The file paths to be downloaded, including the current file names. For example `['folder/image.png', 'folder2/image2.png']`.\\n\\t* @param expiresIn The number of seconds until the signed URLs expire. For example, `60` for URLs which are valid for one minute.\\n\\t* @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\\n\\t* @returns Promise with response containing array of objects with signedUrl, path, and error or error\\n\\t*\\n\\t* @example Create Signed URLs\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .createSignedUrls(['folder/avatar1.png', 'folder/avatar2.png'], 60)\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": [\\n\\t*     {\\n\\t*       \\\"error\\\": null,\\n\\t*       \\\"path\\\": \\\"folder/avatar1.png\\\",\\n\\t*       \\\"signedURL\\\": \\\"/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\\\",\\n\\t*       \\\"signedUrl\\\": \\\"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\\\"\\n\\t*     },\\n\\t*     {\\n\\t*       \\\"error\\\": null,\\n\\t*       \\\"path\\\": \\\"folder/avatar2.png\\\",\\n\\t*       \\\"signedURL\\\": \\\"/object/sign/avatars/folder/avatar2.png?token=<TOKEN>\\\",\\n\\t*       \\\"signedUrl\\\": \\\"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar2.png?token=<TOKEN>\\\"\\n\\t*     }\\n\\t*   ],\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync createSignedUrls(paths, expiresIn, options) {\\n\\t\\tvar _this9 = this;\\n\\t\\treturn _this9.handleOperation(async () => {\\n\\t\\t\\tconst data = await post(_this9.fetch, `${_this9.url}/object/sign/${_this9.bucketId}`, {\\n\\t\\t\\t\\texpiresIn,\\n\\t\\t\\t\\tpaths\\n\\t\\t\\t}, { headers: _this9.headers });\\n\\t\\t\\tconst downloadQueryParam = (options === null || options === void 0 ? void 0 : options.download) ? `&download=${options.download === true ? \\\"\\\" : options.download}` : \\\"\\\";\\n\\t\\t\\treturn data.map((datum) => _objectSpread2(_objectSpread2({}, datum), {}, { signedUrl: datum.signedURL ? encodeURI(`${_this9.url}${datum.signedURL}${downloadQueryParam}`) : null }));\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Downloads a file from a private bucket. For public buckets, make a request to the URL returned from `getPublicUrl` instead.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param path The full path and file name of the file to be downloaded. For example `folder/image.png`.\\n\\t* @param options.transform Transform the asset before serving it to the client.\\n\\t* @param parameters Additional fetch parameters like signal for cancellation. Supports standard fetch options including cache control.\\n\\t* @returns BlobDownloadBuilder instance for downloading the file\\n\\t*\\n\\t* @example Download file\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .download('folder/avatar1.png')\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": <BLOB>,\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*\\n\\t* @example Download file with transformations\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .download('folder/avatar1.png', {\\n\\t*     transform: {\\n\\t*       width: 100,\\n\\t*       height: 100,\\n\\t*       quality: 80\\n\\t*     }\\n\\t*   })\\n\\t* ```\\n\\t*\\n\\t* @example Download with cache control (useful in Edge Functions)\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .download('folder/avatar1.png', {}, { cache: 'no-store' })\\n\\t* ```\\n\\t*\\n\\t* @example Download with abort signal\\n\\t* ```js\\n\\t* const controller = new AbortController()\\n\\t* setTimeout(() => controller.abort(), 5000)\\n\\t*\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .download('folder/avatar1.png', {}, { signal: controller.signal })\\n\\t* ```\\n\\t*/\\n\\tdownload(path, options, parameters) {\\n\\t\\tconst renderPath = typeof (options === null || options === void 0 ? void 0 : options.transform) !== \\\"undefined\\\" ? \\\"render/image/authenticated\\\" : \\\"object\\\";\\n\\t\\tconst transformationQuery = this.transformOptsToQueryString((options === null || options === void 0 ? void 0 : options.transform) || {});\\n\\t\\tconst queryString = transformationQuery ? `?${transformationQuery}` : \\\"\\\";\\n\\t\\tconst _path = this._getFinalPath(path);\\n\\t\\tconst downloadFn = () => get(this.fetch, `${this.url}/${renderPath}/${_path}${queryString}`, {\\n\\t\\t\\theaders: this.headers,\\n\\t\\t\\tnoResolveJson: true\\n\\t\\t}, parameters);\\n\\t\\treturn new BlobDownloadBuilder(downloadFn, this.shouldThrowOnError);\\n\\t}\\n\\t/**\\n\\t* Retrieves the details of an existing file.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param path The file path, including the file name. For example `folder/image.png`.\\n\\t* @returns Promise with response containing file metadata or error\\n\\t*\\n\\t* @example Get file info\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .info('folder/avatar1.png')\\n\\t* ```\\n\\t*/\\n\\tasync info(path) {\\n\\t\\tvar _this10 = this;\\n\\t\\tconst _path = _this10._getFinalPath(path);\\n\\t\\treturn _this10.handleOperation(async () => {\\n\\t\\t\\treturn recursiveToCamel(await get(_this10.fetch, `${_this10.url}/object/info/${_path}`, { headers: _this10.headers }));\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Checks the existence of a file.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param path The file path, including the file name. For example `folder/image.png`.\\n\\t* @returns Promise with response containing boolean indicating file existence or error\\n\\t*\\n\\t* @example Check file existence\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .exists('folder/avatar1.png')\\n\\t* ```\\n\\t*/\\n\\tasync exists(path) {\\n\\t\\tvar _this11 = this;\\n\\t\\tconst _path = _this11._getFinalPath(path);\\n\\t\\ttry {\\n\\t\\t\\tawait head(_this11.fetch, `${_this11.url}/object/${_path}`, { headers: _this11.headers });\\n\\t\\t\\treturn {\\n\\t\\t\\t\\tdata: true,\\n\\t\\t\\t\\terror: null\\n\\t\\t\\t};\\n\\t\\t} catch (error) {\\n\\t\\t\\tif (_this11.shouldThrowOnError) throw error;\\n\\t\\t\\tif (isStorageError(error) && error instanceof StorageUnknownError) {\\n\\t\\t\\t\\tconst originalError = error.originalError;\\n\\t\\t\\t\\tif ([400, 404].includes(originalError === null || originalError === void 0 ? void 0 : originalError.status)) return {\\n\\t\\t\\t\\t\\tdata: false,\\n\\t\\t\\t\\t\\terror\\n\\t\\t\\t\\t};\\n\\t\\t\\t}\\n\\t\\t\\tthrow error;\\n\\t\\t}\\n\\t}\\n\\t/**\\n\\t* A simple convenience function to get the URL for an asset in a public bucket. If you do not want to use this function, you can construct the public URL by concatenating the bucket URL with the path to the asset.\\n\\t* This function does not verify if the bucket is public. If a public URL is created for a bucket which is not public, you will not be able to download the asset.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param path The path and name of the file to generate the public URL for. For example `folder/image.png`.\\n\\t* @param options.download Triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\\n\\t* @param options.transform Transform the asset before serving it to the client.\\n\\t* @returns Object with public URL\\n\\t*\\n\\t* @example Returns the URL for an asset in a public bucket\\n\\t* ```js\\n\\t* const { data } = supabase\\n\\t*   .storage\\n\\t*   .from('public-bucket')\\n\\t*   .getPublicUrl('folder/avatar1.png')\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"publicUrl\\\": \\\"https://example.supabase.co/storage/v1/object/public/public-bucket/folder/avatar1.png\\\"\\n\\t*   }\\n\\t* }\\n\\t* ```\\n\\t*\\n\\t* @example Returns the URL for an asset in a public bucket with transformations\\n\\t* ```js\\n\\t* const { data } = supabase\\n\\t*   .storage\\n\\t*   .from('public-bucket')\\n\\t*   .getPublicUrl('folder/avatar1.png', {\\n\\t*     transform: {\\n\\t*       width: 100,\\n\\t*       height: 100,\\n\\t*     }\\n\\t*   })\\n\\t* ```\\n\\t*\\n\\t* @example Returns the URL which triggers the download of an asset in a public bucket\\n\\t* ```js\\n\\t* const { data } = supabase\\n\\t*   .storage\\n\\t*   .from('public-bucket')\\n\\t*   .getPublicUrl('folder/avatar1.png', {\\n\\t*     download: true,\\n\\t*   })\\n\\t* ```\\n\\t*/\\n\\tgetPublicUrl(path, options) {\\n\\t\\tconst _path = this._getFinalPath(path);\\n\\t\\tconst _queryString = [];\\n\\t\\tconst downloadQueryParam = (options === null || options === void 0 ? void 0 : options.download) ? `download=${options.download === true ? \\\"\\\" : options.download}` : \\\"\\\";\\n\\t\\tif (downloadQueryParam !== \\\"\\\") _queryString.push(downloadQueryParam);\\n\\t\\tconst renderPath = typeof (options === null || options === void 0 ? void 0 : options.transform) !== \\\"undefined\\\" ? \\\"render/image\\\" : \\\"object\\\";\\n\\t\\tconst transformationQuery = this.transformOptsToQueryString((options === null || options === void 0 ? void 0 : options.transform) || {});\\n\\t\\tif (transformationQuery !== \\\"\\\") _queryString.push(transformationQuery);\\n\\t\\tlet queryString = _queryString.join(\\\"&\\\");\\n\\t\\tif (queryString !== \\\"\\\") queryString = `?${queryString}`;\\n\\t\\treturn { data: { publicUrl: encodeURI(`${this.url}/${renderPath}/public/${_path}${queryString}`) } };\\n\\t}\\n\\t/**\\n\\t* Deletes files within the same bucket\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param paths An array of files to delete, including the path and file name. For example [`'folder/image.png'`].\\n\\t* @returns Promise with response containing array of deleted file objects or error\\n\\t*\\n\\t* @example Delete file\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .remove(['folder/avatar1.png'])\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": [],\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync remove(paths) {\\n\\t\\tvar _this12 = this;\\n\\t\\treturn _this12.handleOperation(async () => {\\n\\t\\t\\treturn await remove(_this12.fetch, `${_this12.url}/object/${_this12.bucketId}`, { prefixes: paths }, { headers: _this12.headers });\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Get file metadata\\n\\t* @param id the file id to retrieve metadata\\n\\t*/\\n\\t/**\\n\\t* Update file metadata\\n\\t* @param id the file id to update metadata\\n\\t* @param meta the new file metadata\\n\\t*/\\n\\t/**\\n\\t* Lists all the files and folders within a path of the bucket.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param path The folder path.\\n\\t* @param options Search options including limit (defaults to 100), offset, sortBy, and search\\n\\t* @param parameters Optional fetch parameters including signal for cancellation\\n\\t* @returns Promise with response containing array of files or error\\n\\t*\\n\\t* @example List files in a bucket\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .list('folder', {\\n\\t*     limit: 100,\\n\\t*     offset: 0,\\n\\t*     sortBy: { column: 'name', order: 'asc' },\\n\\t*   })\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": [\\n\\t*     {\\n\\t*       \\\"name\\\": \\\"avatar1.png\\\",\\n\\t*       \\\"id\\\": \\\"e668cf7f-821b-4a2f-9dce-7dfa5dd1cfd2\\\",\\n\\t*       \\\"updated_at\\\": \\\"2024-05-22T23:06:05.580Z\\\",\\n\\t*       \\\"created_at\\\": \\\"2024-05-22T23:04:34.443Z\\\",\\n\\t*       \\\"last_accessed_at\\\": \\\"2024-05-22T23:04:34.443Z\\\",\\n\\t*       \\\"metadata\\\": {\\n\\t*         \\\"eTag\\\": \\\"\\\\\\\"c5e8c553235d9af30ef4f6e280790b92\\\\\\\"\\\",\\n\\t*         \\\"size\\\": 32175,\\n\\t*         \\\"mimetype\\\": \\\"image/png\\\",\\n\\t*         \\\"cacheControl\\\": \\\"max-age=3600\\\",\\n\\t*         \\\"lastModified\\\": \\\"2024-05-22T23:06:05.574Z\\\",\\n\\t*         \\\"contentLength\\\": 32175,\\n\\t*         \\\"httpStatusCode\\\": 200\\n\\t*       }\\n\\t*     }\\n\\t*   ],\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*\\n\\t* @example Search files in a bucket\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .list('folder', {\\n\\t*     limit: 100,\\n\\t*     offset: 0,\\n\\t*     sortBy: { column: 'name', order: 'asc' },\\n\\t*     search: 'jon'\\n\\t*   })\\n\\t* ```\\n\\t*/\\n\\tasync list(path, options, parameters) {\\n\\t\\tvar _this13 = this;\\n\\t\\treturn _this13.handleOperation(async () => {\\n\\t\\t\\tconst body = _objectSpread2(_objectSpread2(_objectSpread2({}, DEFAULT_SEARCH_OPTIONS), options), {}, { prefix: path || \\\"\\\" });\\n\\t\\t\\treturn await post(_this13.fetch, `${_this13.url}/object/list/${_this13.bucketId}`, body, { headers: _this13.headers }, parameters);\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* @experimental this method signature might change in the future\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param options search options\\n\\t* @param parameters\\n\\t*/\\n\\tasync listV2(options, parameters) {\\n\\t\\tvar _this14 = this;\\n\\t\\treturn _this14.handleOperation(async () => {\\n\\t\\t\\tconst body = _objectSpread2({}, options);\\n\\t\\t\\treturn await post(_this14.fetch, `${_this14.url}/object/list-v2/${_this14.bucketId}`, body, { headers: _this14.headers }, parameters);\\n\\t\\t});\\n\\t}\\n\\tencodeMetadata(metadata) {\\n\\t\\treturn JSON.stringify(metadata);\\n\\t}\\n\\ttoBase64(data) {\\n\\t\\tif (typeof Buffer !== \\\"undefined\\\") return Buffer.from(data).toString(\\\"base64\\\");\\n\\t\\treturn btoa(data);\\n\\t}\\n\\t_getFinalPath(path) {\\n\\t\\treturn `${this.bucketId}/${path.replace(/^\\\\/+/, \\\"\\\")}`;\\n\\t}\\n\\t_removeEmptyFolders(path) {\\n\\t\\treturn path.replace(/^\\\\/|\\\\/$/g, \\\"\\\").replace(/\\\\/+/g, \\\"/\\\");\\n\\t}\\n\\ttransformOptsToQueryString(transform) {\\n\\t\\tconst params = [];\\n\\t\\tif (transform.width) params.push(`width=${transform.width}`);\\n\\t\\tif (transform.height) params.push(`height=${transform.height}`);\\n\\t\\tif (transform.resize) params.push(`resize=${transform.resize}`);\\n\\t\\tif (transform.format) params.push(`format=${transform.format}`);\\n\\t\\tif (transform.quality) params.push(`quality=${transform.quality}`);\\n\\t\\treturn params.join(\\\"&\\\");\\n\\t}\\n};\\n\\n//#endregion\\n//#region src/lib/version.ts\\nconst version = \\\"2.97.0\\\";\\n\\n//#endregion\\n//#region src/lib/constants.ts\\nconst DEFAULT_HEADERS = { \\\"X-Client-Info\\\": `storage-js/${version}` };\\n\\n//#endregion\\n//#region src/packages/StorageBucketApi.ts\\nvar StorageBucketApi = class extends BaseApiClient {\\n\\tconstructor(url, headers = {}, fetch$1, opts) {\\n\\t\\tconst baseUrl = new URL(url);\\n\\t\\tif (opts === null || opts === void 0 ? void 0 : opts.useNewHostname) {\\n\\t\\t\\tif (/supabase\\\\.(co|in|red)$/.test(baseUrl.hostname) && !baseUrl.hostname.includes(\\\"storage.supabase.\\\")) baseUrl.hostname = baseUrl.hostname.replace(\\\"supabase.\\\", \\\"storage.supabase.\\\");\\n\\t\\t}\\n\\t\\tconst finalUrl = baseUrl.href.replace(/\\\\/$/, \\\"\\\");\\n\\t\\tconst finalHeaders = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), headers);\\n\\t\\tsuper(finalUrl, finalHeaders, fetch$1, \\\"storage\\\");\\n\\t}\\n\\t/**\\n\\t* Retrieves the details of all Storage buckets within an existing project.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param options Query parameters for listing buckets\\n\\t* @param options.limit Maximum number of buckets to return\\n\\t* @param options.offset Number of buckets to skip\\n\\t* @param options.sortColumn Column to sort by ('id', 'name', 'created_at', 'updated_at')\\n\\t* @param options.sortOrder Sort order ('asc' or 'desc')\\n\\t* @param options.search Search term to filter bucket names\\n\\t* @returns Promise with response containing array of buckets or error\\n\\t*\\n\\t* @example List buckets\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .listBuckets()\\n\\t* ```\\n\\t*\\n\\t* @example List buckets with options\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .listBuckets({\\n\\t*     limit: 10,\\n\\t*     offset: 0,\\n\\t*     sortColumn: 'created_at',\\n\\t*     sortOrder: 'desc',\\n\\t*     search: 'prod'\\n\\t*   })\\n\\t* ```\\n\\t*/\\n\\tasync listBuckets(options) {\\n\\t\\tvar _this = this;\\n\\t\\treturn _this.handleOperation(async () => {\\n\\t\\t\\tconst queryString = _this.listBucketOptionsToQueryString(options);\\n\\t\\t\\treturn await get(_this.fetch, `${_this.url}/bucket${queryString}`, { headers: _this.headers });\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Retrieves the details of an existing Storage bucket.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param id The unique identifier of the bucket you would like to retrieve.\\n\\t* @returns Promise with response containing bucket details or error\\n\\t*\\n\\t* @example Get bucket\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .getBucket('avatars')\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"id\\\": \\\"avatars\\\",\\n\\t*     \\\"name\\\": \\\"avatars\\\",\\n\\t*     \\\"owner\\\": \\\"\\\",\\n\\t*     \\\"public\\\": false,\\n\\t*     \\\"file_size_limit\\\": 1024,\\n\\t*     \\\"allowed_mime_types\\\": [\\n\\t*       \\\"image/png\\\"\\n\\t*     ],\\n\\t*     \\\"created_at\\\": \\\"2024-05-22T22:26:05.100Z\\\",\\n\\t*     \\\"updated_at\\\": \\\"2024-05-22T22:26:05.100Z\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync getBucket(id) {\\n\\t\\tvar _this2 = this;\\n\\t\\treturn _this2.handleOperation(async () => {\\n\\t\\t\\treturn await get(_this2.fetch, `${_this2.url}/bucket/${id}`, { headers: _this2.headers });\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Creates a new Storage bucket\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param id A unique identifier for the bucket you are creating.\\n\\t* @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations. By default, buckets are private.\\n\\t* @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\\n\\t* The global file size limit takes precedence over this value.\\n\\t* The default value is null, which doesn't set a per bucket file size limit.\\n\\t* @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\\n\\t* The default value is null, which allows files with all mime types to be uploaded.\\n\\t* Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\\n\\t* @param options.type (private-beta) specifies the bucket type. see `BucketType` for more details.\\n\\t*   - default bucket type is `STANDARD`\\n\\t* @returns Promise with response containing newly created bucket name or error\\n\\t*\\n\\t* @example Create bucket\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .createBucket('avatars', {\\n\\t*     public: false,\\n\\t*     allowedMimeTypes: ['image/png'],\\n\\t*     fileSizeLimit: 1024\\n\\t*   })\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"name\\\": \\\"avatars\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync createBucket(id, options = { public: false }) {\\n\\t\\tvar _this3 = this;\\n\\t\\treturn _this3.handleOperation(async () => {\\n\\t\\t\\treturn await post(_this3.fetch, `${_this3.url}/bucket`, {\\n\\t\\t\\t\\tid,\\n\\t\\t\\t\\tname: id,\\n\\t\\t\\t\\ttype: options.type,\\n\\t\\t\\t\\tpublic: options.public,\\n\\t\\t\\t\\tfile_size_limit: options.fileSizeLimit,\\n\\t\\t\\t\\tallowed_mime_types: options.allowedMimeTypes\\n\\t\\t\\t}, { headers: _this3.headers });\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Updates a Storage bucket\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param id A unique identifier for the bucket you are updating.\\n\\t* @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations.\\n\\t* @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\\n\\t* The global file size limit takes precedence over this value.\\n\\t* The default value is null, which doesn't set a per bucket file size limit.\\n\\t* @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\\n\\t* The default value is null, which allows files with all mime types to be uploaded.\\n\\t* Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\\n\\t* @returns Promise with response containing success message or error\\n\\t*\\n\\t* @example Update bucket\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .updateBucket('avatars', {\\n\\t*     public: false,\\n\\t*     allowedMimeTypes: ['image/png'],\\n\\t*     fileSizeLimit: 1024\\n\\t*   })\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"message\\\": \\\"Successfully updated\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync updateBucket(id, options) {\\n\\t\\tvar _this4 = this;\\n\\t\\treturn _this4.handleOperation(async () => {\\n\\t\\t\\treturn await put(_this4.fetch, `${_this4.url}/bucket/${id}`, {\\n\\t\\t\\t\\tid,\\n\\t\\t\\t\\tname: id,\\n\\t\\t\\t\\tpublic: options.public,\\n\\t\\t\\t\\tfile_size_limit: options.fileSizeLimit,\\n\\t\\t\\t\\tallowed_mime_types: options.allowedMimeTypes\\n\\t\\t\\t}, { headers: _this4.headers });\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Removes all objects inside a single bucket.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param id The unique identifier of the bucket you would like to empty.\\n\\t* @returns Promise with success message or error\\n\\t*\\n\\t* @example Empty bucket\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .emptyBucket('avatars')\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"message\\\": \\\"Successfully emptied\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync emptyBucket(id) {\\n\\t\\tvar _this5 = this;\\n\\t\\treturn _this5.handleOperation(async () => {\\n\\t\\t\\treturn await post(_this5.fetch, `${_this5.url}/bucket/${id}/empty`, {}, { headers: _this5.headers });\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Deletes an existing bucket. A bucket can't be deleted with existing objects inside it.\\n\\t* You must first `empty()` the bucket.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param id The unique identifier of the bucket you would like to delete.\\n\\t* @returns Promise with success message or error\\n\\t*\\n\\t* @example Delete bucket\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .deleteBucket('avatars')\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"message\\\": \\\"Successfully deleted\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync deleteBucket(id) {\\n\\t\\tvar _this6 = this;\\n\\t\\treturn _this6.handleOperation(async () => {\\n\\t\\t\\treturn await remove(_this6.fetch, `${_this6.url}/bucket/${id}`, {}, { headers: _this6.headers });\\n\\t\\t});\\n\\t}\\n\\tlistBucketOptionsToQueryString(options) {\\n\\t\\tconst params = {};\\n\\t\\tif (options) {\\n\\t\\t\\tif (\\\"limit\\\" in options) params.limit = String(options.limit);\\n\\t\\t\\tif (\\\"offset\\\" in options) params.offset = String(options.offset);\\n\\t\\t\\tif (options.search) params.search = options.search;\\n\\t\\t\\tif (options.sortColumn) params.sortColumn = options.sortColumn;\\n\\t\\t\\tif (options.sortOrder) params.sortOrder = options.sortOrder;\\n\\t\\t}\\n\\t\\treturn Object.keys(params).length > 0 ? \\\"?\\\" + new URLSearchParams(params).toString() : \\\"\\\";\\n\\t}\\n};\\n\\n//#endregion\\n//#region src/packages/StorageAnalyticsClient.ts\\n/**\\n* Client class for managing Analytics Buckets using Iceberg tables\\n* Provides methods for creating, listing, and deleting analytics buckets\\n*/\\nvar StorageAnalyticsClient = class extends BaseApiClient {\\n\\t/**\\n\\t* @alpha\\n\\t*\\n\\t* Creates a new StorageAnalyticsClient instance\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Analytics Buckets\\n\\t* @param url - The base URL for the storage API\\n\\t* @param headers - HTTP headers to include in requests\\n\\t* @param fetch - Optional custom fetch implementation\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const client = new StorageAnalyticsClient(url, headers)\\n\\t* ```\\n\\t*/\\n\\tconstructor(url, headers = {}, fetch$1) {\\n\\t\\tconst finalUrl = url.replace(/\\\\/$/, \\\"\\\");\\n\\t\\tconst finalHeaders = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), headers);\\n\\t\\tsuper(finalUrl, finalHeaders, fetch$1, \\\"storage\\\");\\n\\t}\\n\\t/**\\n\\t* @alpha\\n\\t*\\n\\t* Creates a new analytics bucket using Iceberg tables\\n\\t* Analytics buckets are optimized for analytical queries and data processing\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Analytics Buckets\\n\\t* @param name A unique name for the bucket you are creating\\n\\t* @returns Promise with response containing newly created analytics bucket or error\\n\\t*\\n\\t* @example Create analytics bucket\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .analytics\\n\\t*   .createBucket('analytics-data')\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"name\\\": \\\"analytics-data\\\",\\n\\t*     \\\"type\\\": \\\"ANALYTICS\\\",\\n\\t*     \\\"format\\\": \\\"iceberg\\\",\\n\\t*     \\\"created_at\\\": \\\"2024-05-22T22:26:05.100Z\\\",\\n\\t*     \\\"updated_at\\\": \\\"2024-05-22T22:26:05.100Z\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync createBucket(name) {\\n\\t\\tvar _this = this;\\n\\t\\treturn _this.handleOperation(async () => {\\n\\t\\t\\treturn await post(_this.fetch, `${_this.url}/bucket`, { name }, { headers: _this.headers });\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* @alpha\\n\\t*\\n\\t* Retrieves the details of all Analytics Storage buckets within an existing project\\n\\t* Only returns buckets of type 'ANALYTICS'\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Analytics Buckets\\n\\t* @param options Query parameters for listing buckets\\n\\t* @param options.limit Maximum number of buckets to return\\n\\t* @param options.offset Number of buckets to skip\\n\\t* @param options.sortColumn Column to sort by ('name', 'created_at', 'updated_at')\\n\\t* @param options.sortOrder Sort order ('asc' or 'desc')\\n\\t* @param options.search Search term to filter bucket names\\n\\t* @returns Promise with response containing array of analytics buckets or error\\n\\t*\\n\\t* @example List analytics buckets\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .analytics\\n\\t*   .listBuckets({\\n\\t*     limit: 10,\\n\\t*     offset: 0,\\n\\t*     sortColumn: 'created_at',\\n\\t*     sortOrder: 'desc'\\n\\t*   })\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": [\\n\\t*     {\\n\\t*       \\\"name\\\": \\\"analytics-data\\\",\\n\\t*       \\\"type\\\": \\\"ANALYTICS\\\",\\n\\t*       \\\"format\\\": \\\"iceberg\\\",\\n\\t*       \\\"created_at\\\": \\\"2024-05-22T22:26:05.100Z\\\",\\n\\t*       \\\"updated_at\\\": \\\"2024-05-22T22:26:05.100Z\\\"\\n\\t*     }\\n\\t*   ],\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync listBuckets(options) {\\n\\t\\tvar _this2 = this;\\n\\t\\treturn _this2.handleOperation(async () => {\\n\\t\\t\\tconst queryParams = new URLSearchParams();\\n\\t\\t\\tif ((options === null || options === void 0 ? void 0 : options.limit) !== void 0) queryParams.set(\\\"limit\\\", options.limit.toString());\\n\\t\\t\\tif ((options === null || options === void 0 ? void 0 : options.offset) !== void 0) queryParams.set(\\\"offset\\\", options.offset.toString());\\n\\t\\t\\tif (options === null || options === void 0 ? void 0 : options.sortColumn) queryParams.set(\\\"sortColumn\\\", options.sortColumn);\\n\\t\\t\\tif (options === null || options === void 0 ? void 0 : options.sortOrder) queryParams.set(\\\"sortOrder\\\", options.sortOrder);\\n\\t\\t\\tif (options === null || options === void 0 ? void 0 : options.search) queryParams.set(\\\"search\\\", options.search);\\n\\t\\t\\tconst queryString = queryParams.toString();\\n\\t\\t\\tconst url = queryString ? `${_this2.url}/bucket?${queryString}` : `${_this2.url}/bucket`;\\n\\t\\t\\treturn await get(_this2.fetch, url, { headers: _this2.headers });\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* @alpha\\n\\t*\\n\\t* Deletes an existing analytics bucket\\n\\t* A bucket can't be deleted with existing objects inside it\\n\\t* You must first empty the bucket before deletion\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Analytics Buckets\\n\\t* @param bucketName The unique identifier of the bucket you would like to delete\\n\\t* @returns Promise with response containing success message or error\\n\\t*\\n\\t* @example Delete analytics bucket\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .analytics\\n\\t*   .deleteBucket('analytics-data')\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"message\\\": \\\"Successfully deleted\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync deleteBucket(bucketName) {\\n\\t\\tvar _this3 = this;\\n\\t\\treturn _this3.handleOperation(async () => {\\n\\t\\t\\treturn await remove(_this3.fetch, `${_this3.url}/bucket/${bucketName}`, {}, { headers: _this3.headers });\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* @alpha\\n\\t*\\n\\t* Get an Iceberg REST Catalog client configured for a specific analytics bucket\\n\\t* Use this to perform advanced table and namespace operations within the bucket\\n\\t* The returned client provides full access to the Apache Iceberg REST Catalog API\\n\\t* with the Supabase `{ data, error }` pattern for consistent error handling on all operations.\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Analytics Buckets\\n\\t* @param bucketName - The name of the analytics bucket (warehouse) to connect to\\n\\t* @returns The wrapped Iceberg catalog client\\n\\t* @throws {StorageError} If the bucket name is invalid\\n\\t*\\n\\t* @example Get catalog and create table\\n\\t* ```js\\n\\t* // First, create an analytics bucket\\n\\t* const { data: bucket, error: bucketError } = await supabase\\n\\t*   .storage\\n\\t*   .analytics\\n\\t*   .createBucket('analytics-data')\\n\\t*\\n\\t* // Get the Iceberg catalog for that bucket\\n\\t* const catalog = supabase.storage.analytics.from('analytics-data')\\n\\t*\\n\\t* // Create a namespace\\n\\t* const { error: nsError } = await catalog.createNamespace({ namespace: ['default'] })\\n\\t*\\n\\t* // Create a table with schema\\n\\t* const { data: tableMetadata, error: tableError } = await catalog.createTable(\\n\\t*   { namespace: ['default'] },\\n\\t*   {\\n\\t*     name: 'events',\\n\\t*     schema: {\\n\\t*       type: 'struct',\\n\\t*       fields: [\\n\\t*         { id: 1, name: 'id', type: 'long', required: true },\\n\\t*         { id: 2, name: 'timestamp', type: 'timestamp', required: true },\\n\\t*         { id: 3, name: 'user_id', type: 'string', required: false }\\n\\t*       ],\\n\\t*       'schema-id': 0,\\n\\t*       'identifier-field-ids': [1]\\n\\t*     },\\n\\t*     'partition-spec': {\\n\\t*       'spec-id': 0,\\n\\t*       fields: []\\n\\t*     },\\n\\t*     'write-order': {\\n\\t*       'order-id': 0,\\n\\t*       fields: []\\n\\t*     },\\n\\t*     properties: {\\n\\t*       'write.format.default': 'parquet'\\n\\t*     }\\n\\t*   }\\n\\t* )\\n\\t* ```\\n\\t*\\n\\t* @example List tables in namespace\\n\\t* ```js\\n\\t* const catalog = supabase.storage.analytics.from('analytics-data')\\n\\t*\\n\\t* // List all tables in the default namespace\\n\\t* const { data: tables, error: listError } = await catalog.listTables({ namespace: ['default'] })\\n\\t* if (listError) {\\n\\t*   if (listError.isNotFound()) {\\n\\t*     console.log('Namespace not found')\\n\\t*   }\\n\\t*   return\\n\\t* }\\n\\t* console.log(tables) // [{ namespace: ['default'], name: 'events' }]\\n\\t* ```\\n\\t*\\n\\t* @example Working with namespaces\\n\\t* ```js\\n\\t* const catalog = supabase.storage.analytics.from('analytics-data')\\n\\t*\\n\\t* // List all namespaces\\n\\t* const { data: namespaces } = await catalog.listNamespaces()\\n\\t*\\n\\t* // Create namespace with properties\\n\\t* await catalog.createNamespace(\\n\\t*   { namespace: ['production'] },\\n\\t*   { properties: { owner: 'data-team', env: 'prod' } }\\n\\t* )\\n\\t* ```\\n\\t*\\n\\t* @example Cleanup operations\\n\\t* ```js\\n\\t* const catalog = supabase.storage.analytics.from('analytics-data')\\n\\t*\\n\\t* // Drop table with purge option (removes all data)\\n\\t* const { error: dropError } = await catalog.dropTable(\\n\\t*   { namespace: ['default'], name: 'events' },\\n\\t*   { purge: true }\\n\\t* )\\n\\t*\\n\\t* if (dropError?.isNotFound()) {\\n\\t*   console.log('Table does not exist')\\n\\t* }\\n\\t*\\n\\t* // Drop namespace (must be empty)\\n\\t* await catalog.dropNamespace({ namespace: ['default'] })\\n\\t* ```\\n\\t*\\n\\t* @remarks\\n\\t* This method provides a bridge between Supabase's bucket management and the standard\\n\\t* Apache Iceberg REST Catalog API. The bucket name maps to the Iceberg warehouse parameter.\\n\\t* All authentication and configuration is handled automatically using your Supabase credentials.\\n\\t*\\n\\t* **Error Handling**: Invalid bucket names throw immediately. All catalog\\n\\t* operations return `{ data, error }` where errors are `IcebergError` instances from iceberg-js.\\n\\t* Use helper methods like `error.isNotFound()` or check `error.status` for specific error handling.\\n\\t* Use `.throwOnError()` on the analytics client if you prefer exceptions for catalog operations.\\n\\t*\\n\\t* **Cleanup Operations**: When using `dropTable`, the `purge: true` option permanently\\n\\t* deletes all table data. Without it, the table is marked as deleted but data remains.\\n\\t*\\n\\t* **Library Dependency**: The returned catalog wraps `IcebergRestCatalog` from iceberg-js.\\n\\t* For complete API documentation and advanced usage, refer to the\\n\\t* [iceberg-js documentation](https://supabase.github.io/iceberg-js/).\\n\\t*/\\n\\tfrom(bucketName) {\\n\\t\\tvar _this4 = this;\\n\\t\\tif (!isValidBucketName(bucketName)) throw new StorageError(\\\"Invalid bucket name: File, folder, and bucket names must follow AWS object key naming guidelines and should avoid the use of any other characters.\\\");\\n\\t\\tconst catalog = new iceberg_js.IcebergRestCatalog({\\n\\t\\t\\tbaseUrl: this.url,\\n\\t\\t\\tcatalogName: bucketName,\\n\\t\\t\\tauth: {\\n\\t\\t\\t\\ttype: \\\"custom\\\",\\n\\t\\t\\t\\tgetHeaders: async () => _this4.headers\\n\\t\\t\\t},\\n\\t\\t\\tfetch: this.fetch\\n\\t\\t});\\n\\t\\tconst shouldThrowOnError = this.shouldThrowOnError;\\n\\t\\treturn new Proxy(catalog, { get(target, prop) {\\n\\t\\t\\tconst value = target[prop];\\n\\t\\t\\tif (typeof value !== \\\"function\\\") return value;\\n\\t\\t\\treturn async (...args) => {\\n\\t\\t\\t\\ttry {\\n\\t\\t\\t\\t\\treturn {\\n\\t\\t\\t\\t\\t\\tdata: await value.apply(target, args),\\n\\t\\t\\t\\t\\t\\terror: null\\n\\t\\t\\t\\t\\t};\\n\\t\\t\\t\\t} catch (error) {\\n\\t\\t\\t\\t\\tif (shouldThrowOnError) throw error;\\n\\t\\t\\t\\t\\treturn {\\n\\t\\t\\t\\t\\t\\tdata: null,\\n\\t\\t\\t\\t\\t\\terror\\n\\t\\t\\t\\t\\t};\\n\\t\\t\\t\\t}\\n\\t\\t\\t};\\n\\t\\t} });\\n\\t}\\n};\\n\\n//#endregion\\n//#region src/packages/VectorIndexApi.ts\\n/**\\n* @hidden\\n* Base implementation for vector index operations.\\n* Use {@link VectorBucketScope} via `supabase.storage.vectors.from('bucket')` instead.\\n*/\\nvar VectorIndexApi = class extends BaseApiClient {\\n\\t/** Creates a new VectorIndexApi instance */\\n\\tconstructor(url, headers = {}, fetch$1) {\\n\\t\\tconst finalUrl = url.replace(/\\\\/$/, \\\"\\\");\\n\\t\\tconst finalHeaders = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), {}, { \\\"Content-Type\\\": \\\"application/json\\\" }, headers);\\n\\t\\tsuper(finalUrl, finalHeaders, fetch$1, \\\"vectors\\\");\\n\\t}\\n\\t/** Creates a new vector index within a bucket */\\n\\tasync createIndex(options) {\\n\\t\\tvar _this = this;\\n\\t\\treturn _this.handleOperation(async () => {\\n\\t\\t\\treturn await vectorsApi.post(_this.fetch, `${_this.url}/CreateIndex`, options, { headers: _this.headers }) || {};\\n\\t\\t});\\n\\t}\\n\\t/** Retrieves metadata for a specific vector index */\\n\\tasync getIndex(vectorBucketName, indexName) {\\n\\t\\tvar _this2 = this;\\n\\t\\treturn _this2.handleOperation(async () => {\\n\\t\\t\\treturn await vectorsApi.post(_this2.fetch, `${_this2.url}/GetIndex`, {\\n\\t\\t\\t\\tvectorBucketName,\\n\\t\\t\\t\\tindexName\\n\\t\\t\\t}, { headers: _this2.headers });\\n\\t\\t});\\n\\t}\\n\\t/** Lists vector indexes within a bucket with optional filtering and pagination */\\n\\tasync listIndexes(options) {\\n\\t\\tvar _this3 = this;\\n\\t\\treturn _this3.handleOperation(async () => {\\n\\t\\t\\treturn await vectorsApi.post(_this3.fetch, `${_this3.url}/ListIndexes`, options, { headers: _this3.headers });\\n\\t\\t});\\n\\t}\\n\\t/** Deletes a vector index and all its data */\\n\\tasync deleteIndex(vectorBucketName, indexName) {\\n\\t\\tvar _this4 = this;\\n\\t\\treturn _this4.handleOperation(async () => {\\n\\t\\t\\treturn await vectorsApi.post(_this4.fetch, `${_this4.url}/DeleteIndex`, {\\n\\t\\t\\t\\tvectorBucketName,\\n\\t\\t\\t\\tindexName\\n\\t\\t\\t}, { headers: _this4.headers }) || {};\\n\\t\\t});\\n\\t}\\n};\\n\\n//#endregion\\n//#region src/packages/VectorDataApi.ts\\n/**\\n* @hidden\\n* Base implementation for vector data operations.\\n* Use {@link VectorIndexScope} via `supabase.storage.vectors.from('bucket').index('idx')` instead.\\n*/\\nvar VectorDataApi = class extends BaseApiClient {\\n\\t/** Creates a new VectorDataApi instance */\\n\\tconstructor(url, headers = {}, fetch$1) {\\n\\t\\tconst finalUrl = url.replace(/\\\\/$/, \\\"\\\");\\n\\t\\tconst finalHeaders = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), {}, { \\\"Content-Type\\\": \\\"application/json\\\" }, headers);\\n\\t\\tsuper(finalUrl, finalHeaders, fetch$1, \\\"vectors\\\");\\n\\t}\\n\\t/** Inserts or updates vectors in batch (1-500 per request) */\\n\\tasync putVectors(options) {\\n\\t\\tvar _this = this;\\n\\t\\tif (options.vectors.length < 1 || options.vectors.length > 500) throw new Error(\\\"Vector batch size must be between 1 and 500 items\\\");\\n\\t\\treturn _this.handleOperation(async () => {\\n\\t\\t\\treturn await vectorsApi.post(_this.fetch, `${_this.url}/PutVectors`, options, { headers: _this.headers }) || {};\\n\\t\\t});\\n\\t}\\n\\t/** Retrieves vectors by their keys in batch */\\n\\tasync getVectors(options) {\\n\\t\\tvar _this2 = this;\\n\\t\\treturn _this2.handleOperation(async () => {\\n\\t\\t\\treturn await vectorsApi.post(_this2.fetch, `${_this2.url}/GetVectors`, options, { headers: _this2.headers });\\n\\t\\t});\\n\\t}\\n\\t/** Lists vectors in an index with pagination */\\n\\tasync listVectors(options) {\\n\\t\\tvar _this3 = this;\\n\\t\\tif (options.segmentCount !== void 0) {\\n\\t\\t\\tif (options.segmentCount < 1 || options.segmentCount > 16) throw new Error(\\\"segmentCount must be between 1 and 16\\\");\\n\\t\\t\\tif (options.segmentIndex !== void 0) {\\n\\t\\t\\t\\tif (options.segmentIndex < 0 || options.segmentIndex >= options.segmentCount) throw new Error(`segmentIndex must be between 0 and ${options.segmentCount - 1}`);\\n\\t\\t\\t}\\n\\t\\t}\\n\\t\\treturn _this3.handleOperation(async () => {\\n\\t\\t\\treturn await vectorsApi.post(_this3.fetch, `${_this3.url}/ListVectors`, options, { headers: _this3.headers });\\n\\t\\t});\\n\\t}\\n\\t/** Queries for similar vectors using approximate nearest neighbor search */\\n\\tasync queryVectors(options) {\\n\\t\\tvar _this4 = this;\\n\\t\\treturn _this4.handleOperation(async () => {\\n\\t\\t\\treturn await vectorsApi.post(_this4.fetch, `${_this4.url}/QueryVectors`, options, { headers: _this4.headers });\\n\\t\\t});\\n\\t}\\n\\t/** Deletes vectors by their keys in batch (1-500 per request) */\\n\\tasync deleteVectors(options) {\\n\\t\\tvar _this5 = this;\\n\\t\\tif (options.keys.length < 1 || options.keys.length > 500) throw new Error(\\\"Keys batch size must be between 1 and 500 items\\\");\\n\\t\\treturn _this5.handleOperation(async () => {\\n\\t\\t\\treturn await vectorsApi.post(_this5.fetch, `${_this5.url}/DeleteVectors`, options, { headers: _this5.headers }) || {};\\n\\t\\t});\\n\\t}\\n};\\n\\n//#endregion\\n//#region src/packages/VectorBucketApi.ts\\n/**\\n* @hidden\\n* Base implementation for vector bucket operations.\\n* Use {@link StorageVectorsClient} via `supabase.storage.vectors` instead.\\n*/\\nvar VectorBucketApi = class extends BaseApiClient {\\n\\t/** Creates a new VectorBucketApi instance */\\n\\tconstructor(url, headers = {}, fetch$1) {\\n\\t\\tconst finalUrl = url.replace(/\\\\/$/, \\\"\\\");\\n\\t\\tconst finalHeaders = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), {}, { \\\"Content-Type\\\": \\\"application/json\\\" }, headers);\\n\\t\\tsuper(finalUrl, finalHeaders, fetch$1, \\\"vectors\\\");\\n\\t}\\n\\t/** Creates a new vector bucket */\\n\\tasync createBucket(vectorBucketName) {\\n\\t\\tvar _this = this;\\n\\t\\treturn _this.handleOperation(async () => {\\n\\t\\t\\treturn await vectorsApi.post(_this.fetch, `${_this.url}/CreateVectorBucket`, { vectorBucketName }, { headers: _this.headers }) || {};\\n\\t\\t});\\n\\t}\\n\\t/** Retrieves metadata for a specific vector bucket */\\n\\tasync getBucket(vectorBucketName) {\\n\\t\\tvar _this2 = this;\\n\\t\\treturn _this2.handleOperation(async () => {\\n\\t\\t\\treturn await vectorsApi.post(_this2.fetch, `${_this2.url}/GetVectorBucket`, { vectorBucketName }, { headers: _this2.headers });\\n\\t\\t});\\n\\t}\\n\\t/** Lists vector buckets with optional filtering and pagination */\\n\\tasync listBuckets(options = {}) {\\n\\t\\tvar _this3 = this;\\n\\t\\treturn _this3.handleOperation(async () => {\\n\\t\\t\\treturn await vectorsApi.post(_this3.fetch, `${_this3.url}/ListVectorBuckets`, options, { headers: _this3.headers });\\n\\t\\t});\\n\\t}\\n\\t/** Deletes a vector bucket (must be empty first) */\\n\\tasync deleteBucket(vectorBucketName) {\\n\\t\\tvar _this4 = this;\\n\\t\\treturn _this4.handleOperation(async () => {\\n\\t\\t\\treturn await vectorsApi.post(_this4.fetch, `${_this4.url}/DeleteVectorBucket`, { vectorBucketName }, { headers: _this4.headers }) || {};\\n\\t\\t});\\n\\t}\\n};\\n\\n//#endregion\\n//#region src/packages/StorageVectorsClient.ts\\n/**\\n*\\n* @alpha\\n*\\n* Main client for interacting with S3 Vectors API\\n* Provides access to bucket, index, and vector data operations\\n*\\n* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n*\\n* **Usage Patterns:**\\n*\\n* ```typescript\\n* const { data, error } = await supabase\\n*  .storage\\n*  .vectors\\n*  .createBucket('embeddings-prod')\\n*\\n* // Access index operations via buckets\\n* const bucket = supabase.storage.vectors.from('embeddings-prod')\\n* await bucket.createIndex({\\n*   indexName: 'documents',\\n*   dataType: 'float32',\\n*   dimension: 1536,\\n*   distanceMetric: 'cosine'\\n* })\\n*\\n* // Access vector operations via index\\n* const index = bucket.index('documents')\\n* await index.putVectors({\\n*   vectors: [\\n*     { key: 'doc-1', data: { float32: [...] }, metadata: { title: 'Intro' } }\\n*   ]\\n* })\\n*\\n* // Query similar vectors\\n* const { data } = await index.queryVectors({\\n*   queryVector: { float32: [...] },\\n*   topK: 5,\\n*   returnDistance: true\\n* })\\n* ```\\n*/\\nvar StorageVectorsClient = class extends VectorBucketApi {\\n\\t/**\\n\\t* @alpha\\n\\t*\\n\\t* Creates a StorageVectorsClient that can manage buckets, indexes, and vectors.\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param url - Base URL of the Storage Vectors REST API.\\n\\t* @param options.headers - Optional headers (for example `Authorization`) applied to every request.\\n\\t* @param options.fetch - Optional custom `fetch` implementation for non-browser runtimes.\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const client = new StorageVectorsClient(url, options)\\n\\t* ```\\n\\t*/\\n\\tconstructor(url, options = {}) {\\n\\t\\tsuper(url, options.headers || {}, options.fetch);\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Access operations for a specific vector bucket\\n\\t* Returns a scoped client for index and vector operations within the bucket\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param vectorBucketName - Name of the vector bucket\\n\\t* @returns Bucket-scoped client with index and vector operations\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const bucket = supabase.storage.vectors.from('embeddings-prod')\\n\\t* ```\\n\\t*/\\n\\tfrom(vectorBucketName) {\\n\\t\\treturn new VectorBucketScope(this.url, this.headers, vectorBucketName, this.fetch);\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Creates a new vector bucket\\n\\t* Vector buckets are containers for vector indexes and their data\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param vectorBucketName - Unique name for the vector bucket\\n\\t* @returns Promise with empty response on success or error\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .vectors\\n\\t*   .createBucket('embeddings-prod')\\n\\t* ```\\n\\t*/\\n\\tasync createBucket(vectorBucketName) {\\n\\t\\tvar _superprop_getCreateBucket = () => super.createBucket, _this = this;\\n\\t\\treturn _superprop_getCreateBucket().call(_this, vectorBucketName);\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Retrieves metadata for a specific vector bucket\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param vectorBucketName - Name of the vector bucket\\n\\t* @returns Promise with bucket metadata or error\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .vectors\\n\\t*   .getBucket('embeddings-prod')\\n\\t*\\n\\t* console.log('Bucket created:', data?.vectorBucket.creationTime)\\n\\t* ```\\n\\t*/\\n\\tasync getBucket(vectorBucketName) {\\n\\t\\tvar _superprop_getGetBucket = () => super.getBucket, _this2 = this;\\n\\t\\treturn _superprop_getGetBucket().call(_this2, vectorBucketName);\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Lists all vector buckets with optional filtering and pagination\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param options - Optional filters (prefix, maxResults, nextToken)\\n\\t* @returns Promise with list of buckets or error\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .vectors\\n\\t*   .listBuckets({ prefix: 'embeddings-' })\\n\\t*\\n\\t* data?.vectorBuckets.forEach(bucket => {\\n\\t*   console.log(bucket.vectorBucketName)\\n\\t* })\\n\\t* ```\\n\\t*/\\n\\tasync listBuckets(options = {}) {\\n\\t\\tvar _superprop_getListBuckets = () => super.listBuckets, _this3 = this;\\n\\t\\treturn _superprop_getListBuckets().call(_this3, options);\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Deletes a vector bucket (bucket must be empty)\\n\\t* All indexes must be deleted before deleting the bucket\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param vectorBucketName - Name of the vector bucket to delete\\n\\t* @returns Promise with empty response on success or error\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .vectors\\n\\t*   .deleteBucket('embeddings-old')\\n\\t* ```\\n\\t*/\\n\\tasync deleteBucket(vectorBucketName) {\\n\\t\\tvar _superprop_getDeleteBucket = () => super.deleteBucket, _this4 = this;\\n\\t\\treturn _superprop_getDeleteBucket().call(_this4, vectorBucketName);\\n\\t}\\n};\\n/**\\n*\\n* @alpha\\n*\\n* Scoped client for operations within a specific vector bucket\\n* Provides index management and access to vector operations\\n*\\n* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n*/\\nvar VectorBucketScope = class extends VectorIndexApi {\\n\\t/**\\n\\t* @alpha\\n\\t*\\n\\t* Creates a helper that automatically scopes all index operations to the provided bucket.\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @example\\n\\t* ```typescript\\n\\t* const bucket = supabase.storage.vectors.from('embeddings-prod')\\n\\t* ```\\n\\t*/\\n\\tconstructor(url, headers, vectorBucketName, fetch$1) {\\n\\t\\tsuper(url, headers, fetch$1);\\n\\t\\tthis.vectorBucketName = vectorBucketName;\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Creates a new vector index in this bucket\\n\\t* Convenience method that automatically includes the bucket name\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param options - Index configuration (vectorBucketName is automatically set)\\n\\t* @returns Promise with empty response on success or error\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const bucket = supabase.storage.vectors.from('embeddings-prod')\\n\\t* await bucket.createIndex({\\n\\t*   indexName: 'documents-openai',\\n\\t*   dataType: 'float32',\\n\\t*   dimension: 1536,\\n\\t*   distanceMetric: 'cosine',\\n\\t*   metadataConfiguration: {\\n\\t*     nonFilterableMetadataKeys: ['raw_text']\\n\\t*   }\\n\\t* })\\n\\t* ```\\n\\t*/\\n\\tasync createIndex(options) {\\n\\t\\tvar _superprop_getCreateIndex = () => super.createIndex, _this5 = this;\\n\\t\\treturn _superprop_getCreateIndex().call(_this5, _objectSpread2(_objectSpread2({}, options), {}, { vectorBucketName: _this5.vectorBucketName }));\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Lists indexes in this bucket\\n\\t* Convenience method that automatically includes the bucket name\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param options - Listing options (vectorBucketName is automatically set)\\n\\t* @returns Promise with response containing indexes array and pagination token or error\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const bucket = supabase.storage.vectors.from('embeddings-prod')\\n\\t* const { data } = await bucket.listIndexes({ prefix: 'documents-' })\\n\\t* ```\\n\\t*/\\n\\tasync listIndexes(options = {}) {\\n\\t\\tvar _superprop_getListIndexes = () => super.listIndexes, _this6 = this;\\n\\t\\treturn _superprop_getListIndexes().call(_this6, _objectSpread2(_objectSpread2({}, options), {}, { vectorBucketName: _this6.vectorBucketName }));\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Retrieves metadata for a specific index in this bucket\\n\\t* Convenience method that automatically includes the bucket name\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param indexName - Name of the index to retrieve\\n\\t* @returns Promise with index metadata or error\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const bucket = supabase.storage.vectors.from('embeddings-prod')\\n\\t* const { data } = await bucket.getIndex('documents-openai')\\n\\t* console.log('Dimension:', data?.index.dimension)\\n\\t* ```\\n\\t*/\\n\\tasync getIndex(indexName) {\\n\\t\\tvar _superprop_getGetIndex = () => super.getIndex, _this7 = this;\\n\\t\\treturn _superprop_getGetIndex().call(_this7, _this7.vectorBucketName, indexName);\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Deletes an index from this bucket\\n\\t* Convenience method that automatically includes the bucket name\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param indexName - Name of the index to delete\\n\\t* @returns Promise with empty response on success or error\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const bucket = supabase.storage.vectors.from('embeddings-prod')\\n\\t* await bucket.deleteIndex('old-index')\\n\\t* ```\\n\\t*/\\n\\tasync deleteIndex(indexName) {\\n\\t\\tvar _superprop_getDeleteIndex = () => super.deleteIndex, _this8 = this;\\n\\t\\treturn _superprop_getDeleteIndex().call(_this8, _this8.vectorBucketName, indexName);\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Access operations for a specific index within this bucket\\n\\t* Returns a scoped client for vector data operations\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param indexName - Name of the index\\n\\t* @returns Index-scoped client with vector data operations\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\\n\\t*\\n\\t* // Insert vectors\\n\\t* await index.putVectors({\\n\\t*   vectors: [\\n\\t*     { key: 'doc-1', data: { float32: [...] }, metadata: { title: 'Intro' } }\\n\\t*   ]\\n\\t* })\\n\\t*\\n\\t* // Query similar vectors\\n\\t* const { data } = await index.queryVectors({\\n\\t*   queryVector: { float32: [...] },\\n\\t*   topK: 5\\n\\t* })\\n\\t* ```\\n\\t*/\\n\\tindex(indexName) {\\n\\t\\treturn new VectorIndexScope(this.url, this.headers, this.vectorBucketName, indexName, this.fetch);\\n\\t}\\n};\\n/**\\n*\\n* @alpha\\n*\\n* Scoped client for operations within a specific vector index\\n* Provides vector data operations (put, get, list, query, delete)\\n*\\n* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n*/\\nvar VectorIndexScope = class extends VectorDataApi {\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Creates a helper that automatically scopes all vector operations to the provided bucket/index names.\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @example\\n\\t* ```typescript\\n\\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\\n\\t* ```\\n\\t*/\\n\\tconstructor(url, headers, vectorBucketName, indexName, fetch$1) {\\n\\t\\tsuper(url, headers, fetch$1);\\n\\t\\tthis.vectorBucketName = vectorBucketName;\\n\\t\\tthis.indexName = indexName;\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Inserts or updates vectors in this index\\n\\t* Convenience method that automatically includes bucket and index names\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param options - Vector insertion options (bucket and index names automatically set)\\n\\t* @returns Promise with empty response on success or error\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\\n\\t* await index.putVectors({\\n\\t*   vectors: [\\n\\t*     {\\n\\t*       key: 'doc-1',\\n\\t*       data: { float32: [0.1, 0.2, ...] },\\n\\t*       metadata: { title: 'Introduction', page: 1 }\\n\\t*     }\\n\\t*   ]\\n\\t* })\\n\\t* ```\\n\\t*/\\n\\tasync putVectors(options) {\\n\\t\\tvar _superprop_getPutVectors = () => super.putVectors, _this9 = this;\\n\\t\\treturn _superprop_getPutVectors().call(_this9, _objectSpread2(_objectSpread2({}, options), {}, {\\n\\t\\t\\tvectorBucketName: _this9.vectorBucketName,\\n\\t\\t\\tindexName: _this9.indexName\\n\\t\\t}));\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Retrieves vectors by keys from this index\\n\\t* Convenience method that automatically includes bucket and index names\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param options - Vector retrieval options (bucket and index names automatically set)\\n\\t* @returns Promise with response containing vectors array or error\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\\n\\t* const { data } = await index.getVectors({\\n\\t*   keys: ['doc-1', 'doc-2'],\\n\\t*   returnMetadata: true\\n\\t* })\\n\\t* ```\\n\\t*/\\n\\tasync getVectors(options) {\\n\\t\\tvar _superprop_getGetVectors = () => super.getVectors, _this10 = this;\\n\\t\\treturn _superprop_getGetVectors().call(_this10, _objectSpread2(_objectSpread2({}, options), {}, {\\n\\t\\t\\tvectorBucketName: _this10.vectorBucketName,\\n\\t\\t\\tindexName: _this10.indexName\\n\\t\\t}));\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Lists vectors in this index with pagination\\n\\t* Convenience method that automatically includes bucket and index names\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param options - Listing options (bucket and index names automatically set)\\n\\t* @returns Promise with response containing vectors array and pagination token or error\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\\n\\t* const { data } = await index.listVectors({\\n\\t*   maxResults: 500,\\n\\t*   returnMetadata: true\\n\\t* })\\n\\t* ```\\n\\t*/\\n\\tasync listVectors(options = {}) {\\n\\t\\tvar _superprop_getListVectors = () => super.listVectors, _this11 = this;\\n\\t\\treturn _superprop_getListVectors().call(_this11, _objectSpread2(_objectSpread2({}, options), {}, {\\n\\t\\t\\tvectorBucketName: _this11.vectorBucketName,\\n\\t\\t\\tindexName: _this11.indexName\\n\\t\\t}));\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Queries for similar vectors in this index\\n\\t* Convenience method that automatically includes bucket and index names\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param options - Query options (bucket and index names automatically set)\\n\\t* @returns Promise with response containing matches array of similar vectors ordered by distance or error\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\\n\\t* const { data } = await index.queryVectors({\\n\\t*   queryVector: { float32: [0.1, 0.2, ...] },\\n\\t*   topK: 5,\\n\\t*   filter: { category: 'technical' },\\n\\t*   returnDistance: true,\\n\\t*   returnMetadata: true\\n\\t* })\\n\\t* ```\\n\\t*/\\n\\tasync queryVectors(options) {\\n\\t\\tvar _superprop_getQueryVectors = () => super.queryVectors, _this12 = this;\\n\\t\\treturn _superprop_getQueryVectors().call(_this12, _objectSpread2(_objectSpread2({}, options), {}, {\\n\\t\\t\\tvectorBucketName: _this12.vectorBucketName,\\n\\t\\t\\tindexName: _this12.indexName\\n\\t\\t}));\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Deletes vectors by keys from this index\\n\\t* Convenience method that automatically includes bucket and index names\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param options - Deletion options (bucket and index names automatically set)\\n\\t* @returns Promise with empty response on success or error\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\\n\\t* await index.deleteVectors({\\n\\t*   keys: ['doc-1', 'doc-2', 'doc-3']\\n\\t* })\\n\\t* ```\\n\\t*/\\n\\tasync deleteVectors(options) {\\n\\t\\tvar _superprop_getDeleteVectors = () => super.deleteVectors, _this13 = this;\\n\\t\\treturn _superprop_getDeleteVectors().call(_this13, _objectSpread2(_objectSpread2({}, options), {}, {\\n\\t\\t\\tvectorBucketName: _this13.vectorBucketName,\\n\\t\\t\\tindexName: _this13.indexName\\n\\t\\t}));\\n\\t}\\n};\\n\\n//#endregion\\n//#region src/StorageClient.ts\\nvar StorageClient = class extends StorageBucketApi {\\n\\t/**\\n\\t* Creates a client for Storage buckets, files, analytics, and vectors.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @example\\n\\t* ```ts\\n\\t* import { StorageClient } from '@supabase/storage-js'\\n\\t*\\n\\t* const storage = new StorageClient('https://xyzcompany.supabase.co/storage/v1', {\\n\\t*   apikey: 'public-anon-key',\\n\\t* })\\n\\t* const avatars = storage.from('avatars')\\n\\t* ```\\n\\t*/\\n\\tconstructor(url, headers = {}, fetch$1, opts) {\\n\\t\\tsuper(url, headers, fetch$1, opts);\\n\\t}\\n\\t/**\\n\\t* Perform file operation in a bucket.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param id The bucket id to operate on.\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const avatars = supabase.storage.from('avatars')\\n\\t* ```\\n\\t*/\\n\\tfrom(id) {\\n\\t\\treturn new StorageFileApi(this.url, this.headers, id, this.fetch);\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Access vector storage operations.\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @returns A StorageVectorsClient instance configured with the current storage settings.\\n\\t*/\\n\\tget vectors() {\\n\\t\\treturn new StorageVectorsClient(this.url + \\\"/vector\\\", {\\n\\t\\t\\theaders: this.headers,\\n\\t\\t\\tfetch: this.fetch\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Access analytics storage operations using Iceberg tables.\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Analytics Buckets\\n\\t* @returns A StorageAnalyticsClient instance configured with the current storage settings.\\n\\t*/\\n\\tget analytics() {\\n\\t\\treturn new StorageAnalyticsClient(this.url + \\\"/iceberg\\\", this.headers, this.fetch);\\n\\t}\\n};\\n\\n//#endregion\\nexports.StorageAnalyticsClient = StorageAnalyticsClient;\\nexports.StorageApiError = StorageApiError;\\nexports.StorageClient = StorageClient;\\nexports.StorageError = StorageError;\\nexports.StorageUnknownError = StorageUnknownError;\\nexports.StorageVectorsApiError = StorageVectorsApiError;\\nexports.StorageVectorsClient = StorageVectorsClient;\\nexports.StorageVectorsError = StorageVectorsError;\\nexports.StorageVectorsErrorCode = StorageVectorsErrorCode;\\nexports.StorageVectorsUnknownError = StorageVectorsUnknownError;\\nexports.VectorBucketApi = VectorBucketApi;\\nexports.VectorBucketScope = VectorBucketScope;\\nexports.VectorDataApi = VectorDataApi;\\nexports.VectorIndexApi = VectorIndexApi;\\nexports.VectorIndexScope = VectorIndexScope;\\nexports.isStorageError = isStorageError;\\nexports.isStorageVectorsError = isStorageVectorsError;\\n//# sourceMappingURL=index.cjs.map\\n};\"],\n\"names\":[\"shadow$provide\",\"require\",\"module\",\"exports\",\"isStorageError\",\"error\",\"_typeof\",\"o\",\"Symbol\",\"iterator\",\"o$1\",\"constructor\",\"prototype\",\"ownKeys\",\"e\",\"r\",\"t\",\"Object\",\"keys\",\"getOwnPropertySymbols\",\"filter\",\"r$1\",\"getOwnPropertyDescriptor\",\"enumerable\",\"push\",\"apply\",\"_objectSpread2\",\"arguments\",\"length\",\"forEach\",\"toPrimitive\",\"i\",\"call\",\"TypeError\",\"String\",\"defineProperty\",\"value\",\"configurable\",\"writable\",\"getOwnPropertyDescriptors\",\"defineProperties\",\"_handleRequest\",\"fetcher\",\"method\",\"url\",\"options\",\"parameters\",\"body\",\"namespace\",\"Promise\",\"resolve\",\"reject\",\"_getRequestParams\",\"then\",\"result\",\"ok\",\"noResolveJson\",\"contentType\",\"headers\",\"get\",\"status\",\"includes\",\"json\",\"data\",\"catch\",\"handleError\",\"createFetchApi\",\"post\",\"put\",\"head\",\"remove\",\"Buffer\",\"iceberg_js\",\"StorageError\",\"Error\",\"message\",\"statusCode\",\"__isStorageError\",\"name\",\"StorageApiError\",\"toJSON\",\"StorageUnknownError\",\"originalError\",\"StorageVectorsError\",\"StorageVectorsApiError\",\"StorageVectorsUnknownError\",\"StorageVectorsErrorCode\",\"StorageVectorsErrorCode$1\",\"resolveFetch\",\"customFetch\",\"args\",\"fetch\",\"recursiveToCamel\",\"item\",\"Array\",\"isArray\",\"map\",\"el\",\"entries\",\"key\",\"newKey\",\"replace\",\"c\",\"toUpperCase\",\"isValidBucketName\",\"bucketName\",\"trim\",\"test\",\"_getErrorMessage\",\"err\",\"_err$error\",\"msg\",\"error_description\",\"JSON\",\"stringify\",\"code\",\"statusText\",\"params\",\"getPrototypeOf\",\"toStringTag\",\"duplex\",\"defaultApi\",\"vectorsApi\",\"BaseApiClient\",\"fetch$1\",\"shouldThrowOnError\",\"throwOnError\",\"setHeader\",\"handleOperation\",\"operation\",\"_this\",\"StreamDownloadBuilder\",\"downloadFn\",\"onfulfilled\",\"onrejected\",\"execute\",\"_Symbol$toStringTag\",\"BlobDownloadBuilder\",\"promise\",\"asStream\",\"getPromise\",\"finally\",\"onfinally\",\"blob\",\"DEFAULT_SEARCH_OPTIONS\",\"limit\",\"offset\",\"sortBy\",\"column\",\"order\",\"DEFAULT_FILE_OPTIONS\",\"cacheControl\",\"upsert\",\"StorageFileApi\",\"bucketId\",\"uploadOrUpdate\",\"path\",\"fileBody\",\"fileOptions\",\"metadata\",\"Blob\",\"FormData\",\"append\",\"encodeMetadata\",\"has\",\"toBase64\",\"ReadableStream\",\"pipe\",\"cleanPath\",\"_removeEmptyFolders\",\"_path\",\"_getFinalPath\",\"id\",\"Id\",\"fullPath\",\"Key\",\"upload\",\"uploadToSignedUrl\",\"token\",\"_this3\",\"URL\",\"searchParams\",\"set\",\"toString\",\"createSignedUploadUrl\",\"_this4\",\"signedUrl\",\"update\",\"move\",\"fromPath\",\"toPath\",\"_this6\",\"sourceKey\",\"destinationKey\",\"destinationBucket\",\"copy\",\"_this7\",\"createSignedUrl\",\"expiresIn\",\"_this8\",\"transform\",\"encodeURI\",\"signedURL\",\"downloadQueryParam\",\"download\",\"createSignedUrls\",\"paths\",\"_this9\",\"datum\",\"renderPath\",\"queryString\",\"transformationQuery\",\"transformOptsToQueryString\",\"info\",\"_this10\",\"exists\",\"_this11\",\"getPublicUrl\",\"_queryString\",\"join\",\"publicUrl\",\"_this12\",\"prefixes\",\"list\",\"_this13\",\"prefix\",\"listV2\",\"_this14\",\"from\",\"btoa\",\"width\",\"height\",\"resize\",\"format\",\"quality\",\"DEFAULT_HEADERS\",\"StorageBucketApi\",\"opts\",\"baseUrl\",\"useNewHostname\",\"hostname\",\"finalUrl\",\"href\",\"finalHeaders\",\"listBuckets\",\"listBucketOptionsToQueryString\",\"getBucket\",\"_this2\",\"createBucket\",\"public\",\"type\",\"file_size_limit\",\"fileSizeLimit\",\"allowed_mime_types\",\"allowedMimeTypes\",\"updateBucket\",\"emptyBucket\",\"_this5\",\"deleteBucket\",\"search\",\"sortColumn\",\"sortOrder\",\"URLSearchParams\",\"StorageAnalyticsClient\",\"queryParams\",\"catalog\",\"IcebergRestCatalog\",\"catalogName\",\"auth\",\"getHeaders\",\"Proxy\",\"target\",\"prop\",\"VectorIndexApi\",\"createIndex\",\"getIndex\",\"vectorBucketName\",\"indexName\",\"listIndexes\",\"deleteIndex\",\"VectorDataApi\",\"putVectors\",\"vectors\",\"getVectors\",\"listVectors\",\"segmentCount\",\"segmentIndex\",\"queryVectors\",\"deleteVectors\",\"VectorBucketApi\",\"StorageVectorsClient\",\"VectorBucketScope\",\"_superprop_getCreateBucket\",\"_superprop_getGetBucket\",\"_superprop_getListBuckets\",\"_superprop_getDeleteBucket\",\"_superprop_getCreateIndex\",\"_superprop_getListIndexes\",\"_superprop_getGetIndex\",\"_superprop_getDeleteIndex\",\"index\",\"VectorIndexScope\",\"_superprop_getPutVectors\",\"_superprop_getGetVectors\",\"_superprop_getListVectors\",\"_superprop_getQueryVectors\",\"_superprop_getDeleteVectors\",\"StorageClient\",\"isStorageVectorsError\"]\n}\n"]