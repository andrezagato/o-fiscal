["^ ","~:resource-id",["~:shadow.build.npm/resource","node_modules/@supabase/storage-js/dist/index.cjs"],"~:js","shadow$provide[35]=function(S,ka,a){function I(g){return typeof g===\"object\"&&g!==null&&\"__isStorageError\"in g}function q(g){\"@babel/helpers - typeof\";return q=\"function\"==typeof Symbol&&\"symbol\"==typeof Symbol.iterator?function(n){return typeof n}:function(n){return n&&\"function\"==typeof Symbol&&n.constructor===Symbol&&n!==Symbol.prototype?\"symbol\":typeof n},q(g)}function D(g,n){var F=Object.keys(g);if(Object.getOwnPropertySymbols){var Q=Object.getOwnPropertySymbols(g);n&&(Q=Q.filter(function(ea){return Object.getOwnPropertyDescriptor(g,\nea).enumerable}));F.push.apply(F,Q)}return F}function C(g){for(var n=1;n<arguments.length;n++){var F=null!=arguments[n]?arguments[n]:{};n%2?D(Object(F),!0).forEach(function(Q){var ea,oa=F[Q];a:if(\"object\"==q(Q)&&Q){var Da=Q[Symbol.toPrimitive];if(void 0!==Da){Q=Da.call(Q,\"string\");if(\"object\"!=q(Q))break a;throw new TypeError(\"@@toPrimitive must return a primitive value.\");}Q=String(Q)}(ea=\"symbol\"==q(Q)?Q:Q+\"\")in g?Object.defineProperty(g,ea,{value:oa,enumerable:!0,configurable:!0,writable:!0}):\ng[ea]=oa}):Object.getOwnPropertyDescriptors?Object.defineProperties(g,Object.getOwnPropertyDescriptors(F)):D(Object(F)).forEach(function(Q){Object.defineProperty(g,Q,Object.getOwnPropertyDescriptor(F,Q))})}return g}async function G(g,n,F,Q,ea,oa,Da){return new Promise((Fa,Ga)=>{g(F,w(n,Q,ea,oa)).then(Ma=>{if(!Ma.ok)throw Ma;if(Q===null||Q===void 0?0:Q.noResolveJson)return Ma;if(Da===\"vectors\"){const re=Ma.headers.get(\"content-type\");if(Ma.headers.get(\"content-length\")===\"0\"||Ma.status===204||!re||\n!re.includes(\"application/json\"))return{}}return Ma.json()}).then(Ma=>Fa(Ma)).catch(Ma=>x(Ma,Ga,Q,Da))})}function E(g=\"storage\"){return{get:async(n,F,Q,ea)=>G(n,\"GET\",F,Q,ea,void 0,g),post:async(n,F,Q,ea,oa)=>G(n,\"POST\",F,ea,oa,Q,g),put:async(n,F,Q,ea,oa)=>G(n,\"PUT\",F,ea,oa,Q,g),head:async(n,F,Q,ea)=>G(n,\"HEAD\",F,C(C({},Q),{},{noResolveJson:!0}),ea,void 0,g),remove:async(n,F,Q,ea,oa)=>G(n,\"DELETE\",F,ea,oa,Q,g)}}var M=S(34).Buffer;let d=S(31);var K=class extends Error{constructor(g,n=\"storage\",F,Q){super(g);\nthis.__isStorageError=!0;this.namespace=n;this.name=n===\"vectors\"?\"StorageVectorsError\":\"StorageError\";this.status=F;this.statusCode=Q}},p=class extends K{constructor(g,n,F,Q=\"storage\"){super(g,Q,n,F);this.name=Q===\"vectors\"?\"StorageVectorsApiError\":\"StorageApiError\";this.status=n;this.statusCode=F}toJSON(){return{name:this.name,message:this.message,status:this.status,statusCode:this.statusCode}}},k=class extends K{constructor(g,n,F=\"storage\"){super(g,F);this.name=F===\"vectors\"?\"StorageVectorsUnknownError\":\n\"StorageUnknownError\";this.originalError=n}};S=class extends K{constructor(g){super(g,\"vectors\")}};ka=class extends p{constructor(g,n,F){super(g,n,F,\"vectors\")}};var y=class extends k{constructor(g,n){super(g,n,\"vectors\")}};let v=function(g){g.InternalError=\"InternalError\";g.S3VectorConflictException=\"S3VectorConflictException\";g.S3VectorNotFoundException=\"S3VectorNotFoundException\";g.S3VectorBucketNotEmpty=\"S3VectorBucketNotEmpty\";g.S3VectorMaxBucketsExceeded=\"S3VectorMaxBucketsExceeded\";g.S3VectorMaxIndexesExceeded=\n\"S3VectorMaxIndexesExceeded\";return g}({});const z=g=>g?(...n)=>g(...n):(...n)=>fetch(...n),J=g=>{if(Array.isArray(g))return g.map(F=>J(F));if(typeof g===\"function\"||g!==Object(g))return g;const n={};Object.entries(g).forEach(([F,Q])=>{F=F.replace(/([-_][a-z])/gi,ea=>ea.toUpperCase().replace(/[-_]/g,\"\"));n[F]=J(Q)});return n},l=g=>!g||typeof g!==\"string\"||g.length===0||g.length>100||g.trim()!==g||g.includes(\"/\")||g.includes(\"\\\\\")?!1:/^[\\w!.\\*'() &$@=;:+,?-]+$/.test(g),t=g=>{var n;return g.msg||g.message||\ng.error_description||(typeof g.error===\"string\"?g.error:(n=g.error)===null||n===void 0?void 0:n.message)||JSON.stringify(g)},x=async(g,n,F,Q)=>{if(g&&typeof g===\"object\"&&\"status\"in g&&\"ok\"in g&&typeof g.status===\"number\"&&(F===null||F===void 0||!F.noResolveJson)){const ea=g.status||500;typeof g.json===\"function\"?g.json().then(oa=>{const Da=(oa===null||oa===void 0?void 0:oa.statusCode)||(oa===null||oa===void 0?void 0:oa.code)||ea+\"\";n(new p(t(oa),ea,Da,Q))}).catch(()=>{n(new p(g.statusText||`HTTP ${ea} error`,\nea,ea+\"\",Q))}):n(new p(g.statusText||`HTTP ${ea} error`,ea,ea+\"\",Q))}else n(new k(t(g),g,Q))},w=(g,n,F,Q)=>{const ea={method:g,headers:(n===null||n===void 0?void 0:n.headers)||{}};if(g===\"GET\"||g===\"HEAD\"||!Q)return C(C({},ea),F);typeof Q!==\"object\"||Q===null?g=!1:(g=Object.getPrototypeOf(Q),g=(g===null||g===Object.prototype||Object.getPrototypeOf(g)===null)&&!(Symbol.toStringTag in Q)&&!(Symbol.iterator in Q));g?(ea.headers=C({\"Content-Type\":\"application/json\"},n===null||n===void 0?void 0:n.headers),\nea.body=JSON.stringify(Q)):ea.body=Q;if(n===null||n===void 0?0:n.duplex)ea.duplex=n.duplex;return C(C({},ea),F)};var A=E(\"storage\");const {get:L,post:P,put:T,head:Y,remove:ha}=A,da=E(\"vectors\");var fa=class{constructor(g,n={},F,Q=\"storage\"){this.shouldThrowOnError=!1;this.url=g;this.headers=n;this.fetch=z(F);this.namespace=Q}throwOnError(){this.shouldThrowOnError=!0;return this}setHeader(g,n){this.headers=C(C({},this.headers),{},{[g]:n});return this}async handleOperation(g){try{return{data:await g(),\nerror:null}}catch(n){if(this.shouldThrowOnError)throw n;if(I(n))return{data:null,error:n};throw n;}}},ja=class{constructor(g,n){this.downloadFn=g;this.shouldThrowOnError=n}then(g,n){return this.execute().then(g,n)}async execute(){try{return{data:(await this.downloadFn()).body,error:null}}catch(g){if(this.shouldThrowOnError)throw g;if(I(g))return{data:null,error:g};throw g;}}};let la;la=Symbol.toStringTag;var ta=class{constructor(g,n){this.downloadFn=g;this.shouldThrowOnError=n;this[la]=\"BlobDownloadBuilder\";\nthis.promise=null}asStream(){return new ja(this.downloadFn,this.shouldThrowOnError)}then(g,n){return this.getPromise().then(g,n)}catch(g){return this.getPromise().catch(g)}finally(g){return this.getPromise().finally(g)}getPromise(){this.promise||(this.promise=this.execute());return this.promise}async execute(){try{return{data:await (await this.downloadFn()).blob(),error:null}}catch(g){if(this.shouldThrowOnError)throw g;if(I(g))return{data:null,error:g};throw g;}}};const O={limit:100,offset:0,sortBy:{column:\"name\",\norder:\"asc\"}},W={cacheControl:\"3600\",contentType:\"text/plain;charset\\x3dUTF-8\",upsert:!1};var Z=class extends fa{constructor(g,n={},F,Q){super(g,n,Q,\"storage\");this.bucketId=F}async uploadOrUpdate(g,n,F,Q){var ea=this;return ea.handleOperation(async()=>{const oa=C(C({},W),Q);let Da=C(C({},ea.headers),g===\"POST\"&&{\"x-upsert\":String(oa.upsert)});var Fa=oa.metadata;if(typeof Blob!==\"undefined\"&&F instanceof Blob){var Ga=new FormData;Ga.append(\"cacheControl\",oa.cacheControl);Fa&&Ga.append(\"metadata\",\nea.encodeMetadata(Fa));Ga.append(\"\",F)}else typeof FormData!==\"undefined\"&&F instanceof FormData?(Ga=F,Ga.has(\"cacheControl\")||Ga.append(\"cacheControl\",oa.cacheControl),Fa&&!Ga.has(\"metadata\")&&Ga.append(\"metadata\",ea.encodeMetadata(Fa))):(Ga=F,Da[\"cache-control\"]=`max-age=${oa.cacheControl}`,Da[\"content-type\"]=oa.contentType,Fa&&(Da[\"x-metadata\"]=ea.toBase64(ea.encodeMetadata(Fa))),(typeof ReadableStream!==\"undefined\"&&Ga instanceof ReadableStream||Ga&&typeof Ga===\"object\"&&\"pipe\"in Ga&&typeof Ga.pipe===\n\"function\")&&!oa.duplex&&(oa.duplex=\"half\"));if(Q===null||Q===void 0?0:Q.headers)Da=C(C({},Da),Q.headers);Fa=ea._removeEmptyFolders(n);const Ma=ea._getFinalPath(Fa);Ga=await (g==\"PUT\"?T:P)(ea.fetch,`${ea.url}/object/${Ma}`,Ga,C({headers:Da},(oa===null||oa===void 0?0:oa.duplex)?{duplex:oa.duplex}:{}));return{path:Fa,id:Ga.Id,fullPath:Ga.Key}})}async upload(g,n,F){return this.uploadOrUpdate(\"POST\",g,n,F)}async uploadToSignedUrl(g,n,F,Q){var ea=this;const oa=ea._removeEmptyFolders(g);g=ea._getFinalPath(oa);\nconst Da=new URL(ea.url+`/object/upload/sign/${g}`);Da.searchParams.set(\"token\",n);return ea.handleOperation(async()=>{let Fa;const Ga=C({upsert:W.upsert},Q),Ma=C(C({},ea.headers),{\"x-upsert\":String(Ga.upsert)});typeof Blob!==\"undefined\"&&F instanceof Blob?(Fa=new FormData,Fa.append(\"cacheControl\",Ga.cacheControl),Fa.append(\"\",F)):typeof FormData!==\"undefined\"&&F instanceof FormData?(Fa=F,Fa.append(\"cacheControl\",Ga.cacheControl)):(Fa=F,Ma[\"cache-control\"]=`max-age=${Ga.cacheControl}`,Ma[\"content-type\"]=\nGa.contentType);return{path:oa,fullPath:(await T(ea.fetch,Da.toString(),Fa,{headers:Ma})).Key}})}async createSignedUploadUrl(g,n){var F=this;return F.handleOperation(async()=>{var Q=F._getFinalPath(g),ea=C({},F.headers);if(n===null||n===void 0?0:n.upsert)ea[\"x-upsert\"]=\"true\";Q=await P(F.fetch,`${F.url}/object/upload/sign/${Q}`,{},{headers:ea});Q=new URL(F.url+Q.url);ea=Q.searchParams.get(\"token\");if(!ea)throw new K(\"No token returned by API\");return{signedUrl:Q.toString(),path:g,token:ea}})}async update(g,\nn,F){return this.uploadOrUpdate(\"PUT\",g,n,F)}async move(g,n,F){var Q=this;return Q.handleOperation(async()=>await P(Q.fetch,`${Q.url}/object/move`,{bucketId:Q.bucketId,sourceKey:g,destinationKey:n,destinationBucket:F===null||F===void 0?void 0:F.destinationBucket},{headers:Q.headers}))}async copy(g,n,F){var Q=this;return Q.handleOperation(async()=>({path:(await P(Q.fetch,`${Q.url}/object/copy`,{bucketId:Q.bucketId,sourceKey:g,destinationKey:n,destinationBucket:F===null||F===void 0?void 0:F.destinationBucket},\n{headers:Q.headers})).Key}))}async createSignedUrl(g,n,F){var Q=this;return Q.handleOperation(async()=>{var ea=Q._getFinalPath(g);ea=await P(Q.fetch,`${Q.url}/object/sign/${ea}`,C({expiresIn:n},(F===null||F===void 0?0:F.transform)?{transform:F.transform}:{}),{headers:Q.headers});return{signedUrl:encodeURI(`${Q.url}${ea.signedURL}${(F===null||F===void 0?0:F.download)?`&download=${F.download===!0?\"\":F.download}`:\"\"}`)}})}async createSignedUrls(g,n,F){var Q=this;return Q.handleOperation(async()=>{const ea=\nawait P(Q.fetch,`${Q.url}/object/sign/${Q.bucketId}`,{expiresIn:n,paths:g},{headers:Q.headers}),oa=(F===null||F===void 0?0:F.download)?`&download=${F.download===!0?\"\":F.download}`:\"\";return ea.map(Da=>C(C({},Da),{},{signedUrl:Da.signedURL?encodeURI(`${Q.url}${Da.signedURL}${oa}`):null}))})}download(g,n,F){const Q=typeof(n===null||n===void 0?void 0:n.transform)!==\"undefined\"?\"render/image/authenticated\":\"object\",ea=(n=this.transformOptsToQueryString((n===null||n===void 0?void 0:n.transform)||{}))?\n`?${n}`:\"\",oa=this._getFinalPath(g);return new ta(()=>L(this.fetch,`${this.url}/${Q}/${oa}${ea}`,{headers:this.headers,noResolveJson:!0},F),this.shouldThrowOnError)}async info(g){var n=this;const F=n._getFinalPath(g);return n.handleOperation(async()=>J(await L(n.fetch,`${n.url}/object/info/${F}`,{headers:n.headers})))}async exists(g){g=this._getFinalPath(g);try{return await Y(this.fetch,`${this.url}/object/${g}`,{headers:this.headers}),{data:!0,error:null}}catch(n){if(this.shouldThrowOnError)throw n;\nif(I(n)&&n instanceof k&&(g=n.originalError,[400,404].includes(g===null||g===void 0?void 0:g.status)))return{data:!1,error:n};throw n;}}getPublicUrl(g,n){g=this._getFinalPath(g);const F=[];var Q=(n===null||n===void 0?0:n.download)?`download=${n.download===!0?\"\":n.download}`:\"\";Q!==\"\"&&F.push(Q);Q=typeof(n===null||n===void 0?void 0:n.transform)!==\"undefined\"?\"render/image\":\"object\";n=this.transformOptsToQueryString((n===null||n===void 0?void 0:n.transform)||{});n!==\"\"&&F.push(n);n=F.join(\"\\x26\");n!==\n\"\"&&(n=`?${n}`);return{data:{publicUrl:encodeURI(`${this.url}/${Q}/public/${g}${n}`)}}}async remove(g){var n=this;return n.handleOperation(async()=>await ha(n.fetch,`${n.url}/object/${n.bucketId}`,{prefixes:g},{headers:n.headers}))}async list(g,n,F){var Q=this;return Q.handleOperation(async()=>{const ea=C(C(C({},O),n),{},{prefix:g||\"\"});return await P(Q.fetch,`${Q.url}/object/list/${Q.bucketId}`,ea,{headers:Q.headers},F)})}async listV2(g,n){var F=this;return F.handleOperation(async()=>{const Q=C({},\ng);return await P(F.fetch,`${F.url}/object/list-v2/${F.bucketId}`,Q,{headers:F.headers},n)})}encodeMetadata(g){return JSON.stringify(g)}toBase64(g){return typeof M!==\"undefined\"?M.from(g).toString(\"base64\"):btoa(g)}_getFinalPath(g){return`${this.bucketId}/${g.replace(/^\\/+/,\"\")}`}_removeEmptyFolders(g){return g.replace(/^\\/|\\/$/g,\"\").replace(/\\/+/g,\"/\")}transformOptsToQueryString(g){const n=[];g.width&&n.push(`width=${g.width}`);g.height&&n.push(`height=${g.height}`);g.resize&&n.push(`resize=${g.resize}`);\ng.format&&n.push(`format=${g.format}`);g.quality&&n.push(`quality=${g.quality}`);return n.join(\"\\x26\")}};const ia={\"X-Client-Info\":\"storage-js/2.97.0\"};var ma=class extends fa{constructor(g,n={},F,Q){g=new URL(g);(Q===null||Q===void 0?0:Q.useNewHostname)&&/supabase\\.(co|in|red)$/.test(g.hostname)&&!g.hostname.includes(\"storage.supabase.\")&&(g.hostname=g.hostname.replace(\"supabase.\",\"storage.supabase.\"));Q=g.href.replace(/\\/$/,\"\");n=C(C({},ia),n);super(Q,n,F,\"storage\")}async listBuckets(g){var n=this;\nreturn n.handleOperation(async()=>{const F=n.listBucketOptionsToQueryString(g);return await L(n.fetch,`${n.url}/bucket${F}`,{headers:n.headers})})}async getBucket(g){var n=this;return n.handleOperation(async()=>await L(n.fetch,`${n.url}/bucket/${g}`,{headers:n.headers}))}async createBucket(g,n={public:!1}){var F=this;return F.handleOperation(async()=>await P(F.fetch,`${F.url}/bucket`,{id:g,name:g,type:n.type,public:n.public,file_size_limit:n.fileSizeLimit,allowed_mime_types:n.allowedMimeTypes},{headers:F.headers}))}async updateBucket(g,\nn){var F=this;return F.handleOperation(async()=>await T(F.fetch,`${F.url}/bucket/${g}`,{id:g,name:g,public:n.public,file_size_limit:n.fileSizeLimit,allowed_mime_types:n.allowedMimeTypes},{headers:F.headers}))}async emptyBucket(g){var n=this;return n.handleOperation(async()=>await P(n.fetch,`${n.url}/bucket/${g}/empty`,{},{headers:n.headers}))}async deleteBucket(g){var n=this;return n.handleOperation(async()=>await ha(n.fetch,`${n.url}/bucket/${g}`,{},{headers:n.headers}))}listBucketOptionsToQueryString(g){const n=\n{};g&&(\"limit\"in g&&(n.limit=String(g.limit)),\"offset\"in g&&(n.offset=String(g.offset)),g.search&&(n.search=g.search),g.sortColumn&&(n.sortColumn=g.sortColumn),g.sortOrder&&(n.sortOrder=g.sortOrder));return Object.keys(n).length>0?\"?\"+(new URLSearchParams(n)).toString():\"\"}},sa=class extends fa{constructor(g,n={},F){g=g.replace(/\\/$/,\"\");n=C(C({},ia),n);super(g,n,F,\"storage\")}async createBucket(g){var n=this;return n.handleOperation(async()=>await P(n.fetch,`${n.url}/bucket`,{name:g},{headers:n.headers}))}async listBuckets(g){var n=\nthis;return n.handleOperation(async()=>{var F=new URLSearchParams;(g===null||g===void 0?void 0:g.limit)!==void 0&&F.set(\"limit\",g.limit.toString());(g===null||g===void 0?void 0:g.offset)!==void 0&&F.set(\"offset\",g.offset.toString());(g===null||g===void 0?0:g.sortColumn)&&F.set(\"sortColumn\",g.sortColumn);(g===null||g===void 0?0:g.sortOrder)&&F.set(\"sortOrder\",g.sortOrder);(g===null||g===void 0?0:g.search)&&F.set(\"search\",g.search);F=F.toString();return await L(n.fetch,F?`${n.url}/bucket?${F}`:`${n.url}/bucket`,\n{headers:n.headers})})}async deleteBucket(g){var n=this;return n.handleOperation(async()=>await ha(n.fetch,`${n.url}/bucket/${g}`,{},{headers:n.headers}))}from(g){var n=this;if(!l(g))throw new K(\"Invalid bucket name: File, folder, and bucket names must follow AWS object key naming guidelines and should avoid the use of any other characters.\");g=new d.IcebergRestCatalog({baseUrl:this.url,catalogName:g,auth:{type:\"custom\",getHeaders:async()=>n.headers},fetch:this.fetch});const F=this.shouldThrowOnError;\nreturn new Proxy(g,{get(Q,ea){const oa=Q[ea];return typeof oa!==\"function\"?oa:async(...Da)=>{try{return{data:await oa.apply(Q,Da),error:null}}catch(Fa){if(F)throw Fa;return{data:null,error:Fa}}}}})}};A=class extends fa{constructor(g,n={},F){g=g.replace(/\\/$/,\"\");n=C(C({},ia),{},{\"Content-Type\":\"application/json\"},n);super(g,n,F,\"vectors\")}async createIndex(g){var n=this;return n.handleOperation(async()=>await da.post(n.fetch,`${n.url}/CreateIndex`,g,{headers:n.headers})||{})}async getIndex(g,n){var F=\nthis;return F.handleOperation(async()=>await da.post(F.fetch,`${F.url}/GetIndex`,{vectorBucketName:g,indexName:n},{headers:F.headers}))}async listIndexes(g){var n=this;return n.handleOperation(async()=>await da.post(n.fetch,`${n.url}/ListIndexes`,g,{headers:n.headers}))}async deleteIndex(g,n){var F=this;return F.handleOperation(async()=>await da.post(F.fetch,`${F.url}/DeleteIndex`,{vectorBucketName:g,indexName:n},{headers:F.headers})||{})}};var ya=class extends fa{constructor(g,n={},F){g=g.replace(/\\/$/,\n\"\");n=C(C({},ia),{},{\"Content-Type\":\"application/json\"},n);super(g,n,F,\"vectors\")}async putVectors(g){var n=this;if(g.vectors.length<1||g.vectors.length>500)throw Error(\"Vector batch size must be between 1 and 500 items\");return n.handleOperation(async()=>await da.post(n.fetch,`${n.url}/PutVectors`,g,{headers:n.headers})||{})}async getVectors(g){var n=this;return n.handleOperation(async()=>await da.post(n.fetch,`${n.url}/GetVectors`,g,{headers:n.headers}))}async listVectors(g){var n=this;if(g.segmentCount!==\nvoid 0){if(g.segmentCount<1||g.segmentCount>16)throw Error(\"segmentCount must be between 1 and 16\");if(g.segmentIndex!==void 0&&(g.segmentIndex<0||g.segmentIndex>=g.segmentCount))throw Error(`segmentIndex must be between 0 and ${g.segmentCount-1}`);}return n.handleOperation(async()=>await da.post(n.fetch,`${n.url}/ListVectors`,g,{headers:n.headers}))}async queryVectors(g){var n=this;return n.handleOperation(async()=>await da.post(n.fetch,`${n.url}/QueryVectors`,g,{headers:n.headers}))}async deleteVectors(g){var n=\nthis;if(g.keys.length<1||g.keys.length>500)throw Error(\"Keys batch size must be between 1 and 500 items\");return n.handleOperation(async()=>await da.post(n.fetch,`${n.url}/DeleteVectors`,g,{headers:n.headers})||{})}};fa=class extends fa{constructor(g,n={},F){g=g.replace(/\\/$/,\"\");n=C(C({},ia),{},{\"Content-Type\":\"application/json\"},n);super(g,n,F,\"vectors\")}async createBucket(g){var n=this;return n.handleOperation(async()=>await da.post(n.fetch,`${n.url}/CreateVectorBucket`,{vectorBucketName:g},{headers:n.headers})||\n{})}async getBucket(g){var n=this;return n.handleOperation(async()=>await da.post(n.fetch,`${n.url}/GetVectorBucket`,{vectorBucketName:g},{headers:n.headers}))}async listBuckets(g={}){var n=this;return n.handleOperation(async()=>await da.post(n.fetch,`${n.url}/ListVectorBuckets`,g,{headers:n.headers}))}async deleteBucket(g){var n=this;return n.handleOperation(async()=>await da.post(n.fetch,`${n.url}/DeleteVectorBucket`,{vectorBucketName:g},{headers:n.headers})||{})}};var Ea=class extends fa{constructor(g,\nn={}){super(g,n.headers||{},n.fetch)}from(g){return new h(this.url,this.headers,g,this.fetch)}async createBucket(g){return(()=>super.createBucket)().call(this,g)}async getBucket(g){return(()=>super.getBucket)().call(this,g)}async listBuckets(g={}){return(()=>super.listBuckets)().call(this,g)}async deleteBucket(g){return(()=>super.deleteBucket)().call(this,g)}},h=class extends A{constructor(g,n,F,Q){super(g,n,Q);this.vectorBucketName=F}async createIndex(g){return(()=>super.createIndex)().call(this,\nC(C({},g),{},{vectorBucketName:this.vectorBucketName}))}async listIndexes(g={}){return(()=>super.listIndexes)().call(this,C(C({},g),{},{vectorBucketName:this.vectorBucketName}))}async getIndex(g){return(()=>super.getIndex)().call(this,this.vectorBucketName,g)}async deleteIndex(g){return(()=>super.deleteIndex)().call(this,this.vectorBucketName,g)}index(g){return new r(this.url,this.headers,this.vectorBucketName,g,this.fetch)}},r=class extends ya{constructor(g,n,F,Q,ea){super(g,n,ea);this.vectorBucketName=\nF;this.indexName=Q}async putVectors(g){return(()=>super.putVectors)().call(this,C(C({},g),{},{vectorBucketName:this.vectorBucketName,indexName:this.indexName}))}async getVectors(g){return(()=>super.getVectors)().call(this,C(C({},g),{},{vectorBucketName:this.vectorBucketName,indexName:this.indexName}))}async listVectors(g={}){return(()=>super.listVectors)().call(this,C(C({},g),{},{vectorBucketName:this.vectorBucketName,indexName:this.indexName}))}async queryVectors(g){return(()=>super.queryVectors)().call(this,\nC(C({},g),{},{vectorBucketName:this.vectorBucketName,indexName:this.indexName}))}async deleteVectors(g){return(()=>super.deleteVectors)().call(this,C(C({},g),{},{vectorBucketName:this.vectorBucketName,indexName:this.indexName}))}};ma=class extends ma{constructor(g,n={},F,Q){super(g,n,F,Q)}from(g){return new Z(this.url,this.headers,g,this.fetch)}get vectors(){return new Ea(this.url+\"/vector\",{headers:this.headers,fetch:this.fetch})}get analytics(){return new sa(this.url+\"/iceberg\",this.headers,this.fetch)}};\na.StorageAnalyticsClient=sa;a.StorageApiError=p;a.StorageClient=ma;a.StorageError=K;a.StorageUnknownError=k;a.StorageVectorsApiError=ka;a.StorageVectorsClient=Ea;a.StorageVectorsError=S;a.StorageVectorsErrorCode=v;a.StorageVectorsUnknownError=y;a.VectorBucketApi=fa;a.VectorBucketScope=h;a.VectorDataApi=ya;a.VectorIndexApi=A;a.VectorIndexScope=r;a.isStorageError=I;a.isStorageVectorsError=function(g){return I(g)&&g.namespace===\"vectors\"}}","~:source","shadow$provide[35] = function(require,module,exports) {\nvar Buffer = require('buffer').Buffer;\nlet iceberg_js = require(\"iceberg-js\");\n\n//#region src/lib/common/errors.ts\n/**\n* Base error class for all Storage errors\n* Supports both 'storage' and 'vectors' namespaces\n*/\nvar StorageError = class extends Error {\n\tconstructor(message, namespace = \"storage\", status, statusCode) {\n\t\tsuper(message);\n\t\tthis.__isStorageError = true;\n\t\tthis.namespace = namespace;\n\t\tthis.name = namespace === \"vectors\" ? \"StorageVectorsError\" : \"StorageError\";\n\t\tthis.status = status;\n\t\tthis.statusCode = statusCode;\n\t}\n};\n/**\n* Type guard to check if an error is a StorageError\n* @param error - The error to check\n* @returns True if the error is a StorageError\n*/\nfunction isStorageError(error) {\n\treturn typeof error === \"object\" && error !== null && \"__isStorageError\" in error;\n}\n/**\n* API error returned from Storage service\n* Includes HTTP status code and service-specific error code\n*/\nvar StorageApiError = class extends StorageError {\n\tconstructor(message, status, statusCode, namespace = \"storage\") {\n\t\tsuper(message, namespace, status, statusCode);\n\t\tthis.name = namespace === \"vectors\" ? \"StorageVectorsApiError\" : \"StorageApiError\";\n\t\tthis.status = status;\n\t\tthis.statusCode = statusCode;\n\t}\n\ttoJSON() {\n\t\treturn {\n\t\t\tname: this.name,\n\t\t\tmessage: this.message,\n\t\t\tstatus: this.status,\n\t\t\tstatusCode: this.statusCode\n\t\t};\n\t}\n};\n/**\n* Unknown error that doesn't match expected error patterns\n* Wraps the original error for debugging\n*/\nvar StorageUnknownError = class extends StorageError {\n\tconstructor(message, originalError, namespace = \"storage\") {\n\t\tsuper(message, namespace);\n\t\tthis.name = namespace === \"vectors\" ? \"StorageVectorsUnknownError\" : \"StorageUnknownError\";\n\t\tthis.originalError = originalError;\n\t}\n};\n/**\n* @deprecated Use StorageError with namespace='vectors' instead\n* Alias for backward compatibility with existing vector storage code\n*/\nvar StorageVectorsError = class extends StorageError {\n\tconstructor(message) {\n\t\tsuper(message, \"vectors\");\n\t}\n};\n/**\n* Type guard to check if an error is a StorageVectorsError\n* @param error - The error to check\n* @returns True if the error is a StorageVectorsError\n*/\nfunction isStorageVectorsError(error) {\n\treturn isStorageError(error) && error[\"namespace\"] === \"vectors\";\n}\n/**\n* @deprecated Use StorageApiError with namespace='vectors' instead\n* Alias for backward compatibility with existing vector storage code\n*/\nvar StorageVectorsApiError = class extends StorageApiError {\n\tconstructor(message, status, statusCode) {\n\t\tsuper(message, status, statusCode, \"vectors\");\n\t}\n};\n/**\n* @deprecated Use StorageUnknownError with namespace='vectors' instead\n* Alias for backward compatibility with existing vector storage code\n*/\nvar StorageVectorsUnknownError = class extends StorageUnknownError {\n\tconstructor(message, originalError) {\n\t\tsuper(message, originalError, \"vectors\");\n\t}\n};\n/**\n* Error codes specific to S3 Vectors API\n* Maps AWS service errors to application-friendly error codes\n*/\nlet StorageVectorsErrorCode = /* @__PURE__ */ function(StorageVectorsErrorCode$1) {\n\t/** Internal server fault (HTTP 500) */\n\tStorageVectorsErrorCode$1[\"InternalError\"] = \"InternalError\";\n\t/** Resource already exists / conflict (HTTP 409) */\n\tStorageVectorsErrorCode$1[\"S3VectorConflictException\"] = \"S3VectorConflictException\";\n\t/** Resource not found (HTTP 404) */\n\tStorageVectorsErrorCode$1[\"S3VectorNotFoundException\"] = \"S3VectorNotFoundException\";\n\t/** Delete bucket while not empty (HTTP 400) */\n\tStorageVectorsErrorCode$1[\"S3VectorBucketNotEmpty\"] = \"S3VectorBucketNotEmpty\";\n\t/** Exceeds bucket quota/limit (HTTP 400) */\n\tStorageVectorsErrorCode$1[\"S3VectorMaxBucketsExceeded\"] = \"S3VectorMaxBucketsExceeded\";\n\t/** Exceeds index quota/limit (HTTP 400) */\n\tStorageVectorsErrorCode$1[\"S3VectorMaxIndexesExceeded\"] = \"S3VectorMaxIndexesExceeded\";\n\treturn StorageVectorsErrorCode$1;\n}({});\n\n//#endregion\n//#region src/lib/common/helpers.ts\n/**\n* Resolves the fetch implementation to use\n* Uses custom fetch if provided, otherwise uses native fetch\n*\n* @param customFetch - Optional custom fetch implementation\n* @returns Resolved fetch function\n*/\nconst resolveFetch = (customFetch) => {\n\tif (customFetch) return (...args) => customFetch(...args);\n\treturn (...args) => fetch(...args);\n};\n/**\n* Determine if input is a plain object\n* An object is plain if it's created by either {}, new Object(), or Object.create(null)\n*\n* @param value - Value to check\n* @returns True if value is a plain object\n* @source https://github.com/sindresorhus/is-plain-obj\n*/\nconst isPlainObject = (value) => {\n\tif (typeof value !== \"object\" || value === null) return false;\n\tconst prototype = Object.getPrototypeOf(value);\n\treturn (prototype === null || prototype === Object.prototype || Object.getPrototypeOf(prototype) === null) && !(Symbol.toStringTag in value) && !(Symbol.iterator in value);\n};\n/**\n* Recursively converts object keys from snake_case to camelCase\n* Used for normalizing API responses\n*\n* @param item - Object to convert\n* @returns Converted object with camelCase keys\n*/\nconst recursiveToCamel = (item) => {\n\tif (Array.isArray(item)) return item.map((el) => recursiveToCamel(el));\n\telse if (typeof item === \"function\" || item !== Object(item)) return item;\n\tconst result = {};\n\tObject.entries(item).forEach(([key, value]) => {\n\t\tconst newKey = key.replace(/([-_][a-z])/gi, (c) => c.toUpperCase().replace(/[-_]/g, \"\"));\n\t\tresult[newKey] = recursiveToCamel(value);\n\t});\n\treturn result;\n};\n/**\n* Validates if a given bucket name is valid according to Supabase Storage API rules\n* Mirrors backend validation from: storage/src/storage/limits.ts:isValidBucketName()\n*\n* Rules:\n* - Length: 1-100 characters\n* - Allowed characters: alphanumeric (a-z, A-Z, 0-9), underscore (_), and safe special characters\n* - Safe special characters: ! - . * ' ( ) space & $ @ = ; : + , ?\n* - Forbidden: path separators (/, \\), path traversal (..), leading/trailing whitespace\n*\n* AWS S3 Reference: https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-keys.html\n*\n* @param bucketName - The bucket name to validate\n* @returns true if valid, false otherwise\n*/\nconst isValidBucketName = (bucketName) => {\n\tif (!bucketName || typeof bucketName !== \"string\") return false;\n\tif (bucketName.length === 0 || bucketName.length > 100) return false;\n\tif (bucketName.trim() !== bucketName) return false;\n\tif (bucketName.includes(\"/\") || bucketName.includes(\"\\\\\")) return false;\n\treturn /^[\\w!.\\*'() &$@=;:+,?-]+$/.test(bucketName);\n};\n\n//#endregion\n//#region \\0@oxc-project+runtime@0.101.0/helpers/typeof.js\nfunction _typeof(o) {\n\t\"@babel/helpers - typeof\";\n\treturn _typeof = \"function\" == typeof Symbol && \"symbol\" == typeof Symbol.iterator ? function(o$1) {\n\t\treturn typeof o$1;\n\t} : function(o$1) {\n\t\treturn o$1 && \"function\" == typeof Symbol && o$1.constructor === Symbol && o$1 !== Symbol.prototype ? \"symbol\" : typeof o$1;\n\t}, _typeof(o);\n}\n\n//#endregion\n//#region \\0@oxc-project+runtime@0.101.0/helpers/toPrimitive.js\nfunction toPrimitive(t, r) {\n\tif (\"object\" != _typeof(t) || !t) return t;\n\tvar e = t[Symbol.toPrimitive];\n\tif (void 0 !== e) {\n\t\tvar i = e.call(t, r || \"default\");\n\t\tif (\"object\" != _typeof(i)) return i;\n\t\tthrow new TypeError(\"@@toPrimitive must return a primitive value.\");\n\t}\n\treturn (\"string\" === r ? String : Number)(t);\n}\n\n//#endregion\n//#region \\0@oxc-project+runtime@0.101.0/helpers/toPropertyKey.js\nfunction toPropertyKey(t) {\n\tvar i = toPrimitive(t, \"string\");\n\treturn \"symbol\" == _typeof(i) ? i : i + \"\";\n}\n\n//#endregion\n//#region \\0@oxc-project+runtime@0.101.0/helpers/defineProperty.js\nfunction _defineProperty(e, r, t) {\n\treturn (r = toPropertyKey(r)) in e ? Object.defineProperty(e, r, {\n\t\tvalue: t,\n\t\tenumerable: !0,\n\t\tconfigurable: !0,\n\t\twritable: !0\n\t}) : e[r] = t, e;\n}\n\n//#endregion\n//#region \\0@oxc-project+runtime@0.101.0/helpers/objectSpread2.js\nfunction ownKeys(e, r) {\n\tvar t = Object.keys(e);\n\tif (Object.getOwnPropertySymbols) {\n\t\tvar o = Object.getOwnPropertySymbols(e);\n\t\tr && (o = o.filter(function(r$1) {\n\t\t\treturn Object.getOwnPropertyDescriptor(e, r$1).enumerable;\n\t\t})), t.push.apply(t, o);\n\t}\n\treturn t;\n}\nfunction _objectSpread2(e) {\n\tfor (var r = 1; r < arguments.length; r++) {\n\t\tvar t = null != arguments[r] ? arguments[r] : {};\n\t\tr % 2 ? ownKeys(Object(t), !0).forEach(function(r$1) {\n\t\t\t_defineProperty(e, r$1, t[r$1]);\n\t\t}) : Object.getOwnPropertyDescriptors ? Object.defineProperties(e, Object.getOwnPropertyDescriptors(t)) : ownKeys(Object(t)).forEach(function(r$1) {\n\t\t\tObject.defineProperty(e, r$1, Object.getOwnPropertyDescriptor(t, r$1));\n\t\t});\n\t}\n\treturn e;\n}\n\n//#endregion\n//#region src/lib/common/fetch.ts\n/**\n* Extracts error message from various error response formats\n* @param err - Error object from API\n* @returns Human-readable error message\n*/\nconst _getErrorMessage = (err) => {\n\tvar _err$error;\n\treturn err.msg || err.message || err.error_description || (typeof err.error === \"string\" ? err.error : (_err$error = err.error) === null || _err$error === void 0 ? void 0 : _err$error.message) || JSON.stringify(err);\n};\n/**\n* Handles fetch errors and converts them to Storage error types\n* @param error - The error caught from fetch\n* @param reject - Promise rejection function\n* @param options - Fetch options that may affect error handling\n* @param namespace - Error namespace ('storage' or 'vectors')\n*/\nconst handleError = async (error, reject, options, namespace) => {\n\tif (error && typeof error === \"object\" && \"status\" in error && \"ok\" in error && typeof error.status === \"number\" && !(options === null || options === void 0 ? void 0 : options.noResolveJson)) {\n\t\tconst responseError = error;\n\t\tconst status = responseError.status || 500;\n\t\tif (typeof responseError.json === \"function\") responseError.json().then((err) => {\n\t\t\tconst statusCode = (err === null || err === void 0 ? void 0 : err.statusCode) || (err === null || err === void 0 ? void 0 : err.code) || status + \"\";\n\t\t\treject(new StorageApiError(_getErrorMessage(err), status, statusCode, namespace));\n\t\t}).catch(() => {\n\t\t\tif (namespace === \"vectors\") {\n\t\t\t\tconst statusCode = status + \"\";\n\t\t\t\treject(new StorageApiError(responseError.statusText || `HTTP ${status} error`, status, statusCode, namespace));\n\t\t\t} else {\n\t\t\t\tconst statusCode = status + \"\";\n\t\t\t\treject(new StorageApiError(responseError.statusText || `HTTP ${status} error`, status, statusCode, namespace));\n\t\t\t}\n\t\t});\n\t\telse {\n\t\t\tconst statusCode = status + \"\";\n\t\t\treject(new StorageApiError(responseError.statusText || `HTTP ${status} error`, status, statusCode, namespace));\n\t\t}\n\t} else reject(new StorageUnknownError(_getErrorMessage(error), error, namespace));\n};\n/**\n* Builds request parameters for fetch calls\n* @param method - HTTP method\n* @param options - Custom fetch options\n* @param parameters - Additional fetch parameters like AbortSignal\n* @param body - Request body (will be JSON stringified if plain object)\n* @returns Complete fetch request parameters\n*/\nconst _getRequestParams = (method, options, parameters, body) => {\n\tconst params = {\n\t\tmethod,\n\t\theaders: (options === null || options === void 0 ? void 0 : options.headers) || {}\n\t};\n\tif (method === \"GET\" || method === \"HEAD\" || !body) return _objectSpread2(_objectSpread2({}, params), parameters);\n\tif (isPlainObject(body)) {\n\t\tparams.headers = _objectSpread2({ \"Content-Type\": \"application/json\" }, options === null || options === void 0 ? void 0 : options.headers);\n\t\tparams.body = JSON.stringify(body);\n\t} else params.body = body;\n\tif (options === null || options === void 0 ? void 0 : options.duplex) params.duplex = options.duplex;\n\treturn _objectSpread2(_objectSpread2({}, params), parameters);\n};\n/**\n* Internal request handler that wraps fetch with error handling\n* @param fetcher - Fetch function to use\n* @param method - HTTP method\n* @param url - Request URL\n* @param options - Custom fetch options\n* @param parameters - Additional fetch parameters\n* @param body - Request body\n* @param namespace - Error namespace ('storage' or 'vectors')\n* @returns Promise with parsed response or error\n*/\nasync function _handleRequest(fetcher, method, url, options, parameters, body, namespace) {\n\treturn new Promise((resolve, reject) => {\n\t\tfetcher(url, _getRequestParams(method, options, parameters, body)).then((result) => {\n\t\t\tif (!result.ok) throw result;\n\t\t\tif (options === null || options === void 0 ? void 0 : options.noResolveJson) return result;\n\t\t\tif (namespace === \"vectors\") {\n\t\t\t\tconst contentType = result.headers.get(\"content-type\");\n\t\t\t\tif (result.headers.get(\"content-length\") === \"0\" || result.status === 204) return {};\n\t\t\t\tif (!contentType || !contentType.includes(\"application/json\")) return {};\n\t\t\t}\n\t\t\treturn result.json();\n\t\t}).then((data) => resolve(data)).catch((error) => handleError(error, reject, options, namespace));\n\t});\n}\n/**\n* Creates a fetch API with the specified namespace\n* @param namespace - Error namespace ('storage' or 'vectors')\n* @returns Object with HTTP method functions\n*/\nfunction createFetchApi(namespace = \"storage\") {\n\treturn {\n\t\tget: async (fetcher, url, options, parameters) => {\n\t\t\treturn _handleRequest(fetcher, \"GET\", url, options, parameters, void 0, namespace);\n\t\t},\n\t\tpost: async (fetcher, url, body, options, parameters) => {\n\t\t\treturn _handleRequest(fetcher, \"POST\", url, options, parameters, body, namespace);\n\t\t},\n\t\tput: async (fetcher, url, body, options, parameters) => {\n\t\t\treturn _handleRequest(fetcher, \"PUT\", url, options, parameters, body, namespace);\n\t\t},\n\t\thead: async (fetcher, url, options, parameters) => {\n\t\t\treturn _handleRequest(fetcher, \"HEAD\", url, _objectSpread2(_objectSpread2({}, options), {}, { noResolveJson: true }), parameters, void 0, namespace);\n\t\t},\n\t\tremove: async (fetcher, url, body, options, parameters) => {\n\t\t\treturn _handleRequest(fetcher, \"DELETE\", url, options, parameters, body, namespace);\n\t\t}\n\t};\n}\nconst defaultApi = createFetchApi(\"storage\");\nconst { get, post, put, head, remove } = defaultApi;\nconst vectorsApi = createFetchApi(\"vectors\");\n\n//#endregion\n//#region src/lib/common/BaseApiClient.ts\n/**\n* @ignore\n* Base API client class for all Storage API classes\n* Provides common infrastructure for error handling and configuration\n*\n* @typeParam TError - The error type (StorageError or subclass)\n*/\nvar BaseApiClient = class {\n\t/**\n\t* Creates a new BaseApiClient instance\n\t* @param url - Base URL for API requests\n\t* @param headers - Default headers for API requests\n\t* @param fetch - Optional custom fetch implementation\n\t* @param namespace - Error namespace ('storage' or 'vectors')\n\t*/\n\tconstructor(url, headers = {}, fetch$1, namespace = \"storage\") {\n\t\tthis.shouldThrowOnError = false;\n\t\tthis.url = url;\n\t\tthis.headers = headers;\n\t\tthis.fetch = resolveFetch(fetch$1);\n\t\tthis.namespace = namespace;\n\t}\n\t/**\n\t* Enable throwing errors instead of returning them.\n\t* When enabled, errors are thrown instead of returned in { data, error } format.\n\t*\n\t* @returns this - For method chaining\n\t*/\n\tthrowOnError() {\n\t\tthis.shouldThrowOnError = true;\n\t\treturn this;\n\t}\n\t/**\n\t* Set an HTTP header for the request.\n\t* Creates a shallow copy of headers to avoid mutating shared state.\n\t*\n\t* @param name - Header name\n\t* @param value - Header value\n\t* @returns this - For method chaining\n\t*/\n\tsetHeader(name, value) {\n\t\tthis.headers = _objectSpread2(_objectSpread2({}, this.headers), {}, { [name]: value });\n\t\treturn this;\n\t}\n\t/**\n\t* Handles API operation with standardized error handling\n\t* Eliminates repetitive try-catch blocks across all API methods\n\t*\n\t* This wrapper:\n\t* 1. Executes the operation\n\t* 2. Returns { data, error: null } on success\n\t* 3. Returns { data: null, error } on failure (if shouldThrowOnError is false)\n\t* 4. Throws error on failure (if shouldThrowOnError is true)\n\t*\n\t* @typeParam T - The expected data type from the operation\n\t* @param operation - Async function that performs the API call\n\t* @returns Promise with { data, error } tuple\n\t*\n\t* @example\n\t* ```typescript\n\t* async listBuckets() {\n\t*   return this.handleOperation(async () => {\n\t*     return await get(this.fetch, `${this.url}/bucket`, {\n\t*       headers: this.headers,\n\t*     })\n\t*   })\n\t* }\n\t* ```\n\t*/\n\tasync handleOperation(operation) {\n\t\tvar _this = this;\n\t\ttry {\n\t\t\treturn {\n\t\t\t\tdata: await operation(),\n\t\t\t\terror: null\n\t\t\t};\n\t\t} catch (error) {\n\t\t\tif (_this.shouldThrowOnError) throw error;\n\t\t\tif (isStorageError(error)) return {\n\t\t\t\tdata: null,\n\t\t\t\terror\n\t\t\t};\n\t\t\tthrow error;\n\t\t}\n\t}\n};\n\n//#endregion\n//#region src/packages/StreamDownloadBuilder.ts\nvar StreamDownloadBuilder = class {\n\tconstructor(downloadFn, shouldThrowOnError) {\n\t\tthis.downloadFn = downloadFn;\n\t\tthis.shouldThrowOnError = shouldThrowOnError;\n\t}\n\tthen(onfulfilled, onrejected) {\n\t\treturn this.execute().then(onfulfilled, onrejected);\n\t}\n\tasync execute() {\n\t\tvar _this = this;\n\t\ttry {\n\t\t\treturn {\n\t\t\t\tdata: (await _this.downloadFn()).body,\n\t\t\t\terror: null\n\t\t\t};\n\t\t} catch (error) {\n\t\t\tif (_this.shouldThrowOnError) throw error;\n\t\t\tif (isStorageError(error)) return {\n\t\t\t\tdata: null,\n\t\t\t\terror\n\t\t\t};\n\t\t\tthrow error;\n\t\t}\n\t}\n};\n\n//#endregion\n//#region src/packages/BlobDownloadBuilder.ts\nlet _Symbol$toStringTag;\n_Symbol$toStringTag = Symbol.toStringTag;\nvar BlobDownloadBuilder = class {\n\tconstructor(downloadFn, shouldThrowOnError) {\n\t\tthis.downloadFn = downloadFn;\n\t\tthis.shouldThrowOnError = shouldThrowOnError;\n\t\tthis[_Symbol$toStringTag] = \"BlobDownloadBuilder\";\n\t\tthis.promise = null;\n\t}\n\tasStream() {\n\t\treturn new StreamDownloadBuilder(this.downloadFn, this.shouldThrowOnError);\n\t}\n\tthen(onfulfilled, onrejected) {\n\t\treturn this.getPromise().then(onfulfilled, onrejected);\n\t}\n\tcatch(onrejected) {\n\t\treturn this.getPromise().catch(onrejected);\n\t}\n\tfinally(onfinally) {\n\t\treturn this.getPromise().finally(onfinally);\n\t}\n\tgetPromise() {\n\t\tif (!this.promise) this.promise = this.execute();\n\t\treturn this.promise;\n\t}\n\tasync execute() {\n\t\tvar _this = this;\n\t\ttry {\n\t\t\treturn {\n\t\t\t\tdata: await (await _this.downloadFn()).blob(),\n\t\t\t\terror: null\n\t\t\t};\n\t\t} catch (error) {\n\t\t\tif (_this.shouldThrowOnError) throw error;\n\t\t\tif (isStorageError(error)) return {\n\t\t\t\tdata: null,\n\t\t\t\terror\n\t\t\t};\n\t\t\tthrow error;\n\t\t}\n\t}\n};\n\n//#endregion\n//#region src/packages/StorageFileApi.ts\nconst DEFAULT_SEARCH_OPTIONS = {\n\tlimit: 100,\n\toffset: 0,\n\tsortBy: {\n\t\tcolumn: \"name\",\n\t\torder: \"asc\"\n\t}\n};\nconst DEFAULT_FILE_OPTIONS = {\n\tcacheControl: \"3600\",\n\tcontentType: \"text/plain;charset=UTF-8\",\n\tupsert: false\n};\nvar StorageFileApi = class extends BaseApiClient {\n\tconstructor(url, headers = {}, bucketId, fetch$1) {\n\t\tsuper(url, headers, fetch$1, \"storage\");\n\t\tthis.bucketId = bucketId;\n\t}\n\t/**\n\t* Uploads a file to an existing bucket or replaces an existing file at the specified path with a new one.\n\t*\n\t* @param method HTTP method.\n\t* @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n\t* @param fileBody The body of the file to be stored in the bucket.\n\t*/\n\tasync uploadOrUpdate(method, path, fileBody, fileOptions) {\n\t\tvar _this = this;\n\t\treturn _this.handleOperation(async () => {\n\t\t\tlet body;\n\t\t\tconst options = _objectSpread2(_objectSpread2({}, DEFAULT_FILE_OPTIONS), fileOptions);\n\t\t\tlet headers = _objectSpread2(_objectSpread2({}, _this.headers), method === \"POST\" && { \"x-upsert\": String(options.upsert) });\n\t\t\tconst metadata = options.metadata;\n\t\t\tif (typeof Blob !== \"undefined\" && fileBody instanceof Blob) {\n\t\t\t\tbody = new FormData();\n\t\t\t\tbody.append(\"cacheControl\", options.cacheControl);\n\t\t\t\tif (metadata) body.append(\"metadata\", _this.encodeMetadata(metadata));\n\t\t\t\tbody.append(\"\", fileBody);\n\t\t\t} else if (typeof FormData !== \"undefined\" && fileBody instanceof FormData) {\n\t\t\t\tbody = fileBody;\n\t\t\t\tif (!body.has(\"cacheControl\")) body.append(\"cacheControl\", options.cacheControl);\n\t\t\t\tif (metadata && !body.has(\"metadata\")) body.append(\"metadata\", _this.encodeMetadata(metadata));\n\t\t\t} else {\n\t\t\t\tbody = fileBody;\n\t\t\t\theaders[\"cache-control\"] = `max-age=${options.cacheControl}`;\n\t\t\t\theaders[\"content-type\"] = options.contentType;\n\t\t\t\tif (metadata) headers[\"x-metadata\"] = _this.toBase64(_this.encodeMetadata(metadata));\n\t\t\t\tif ((typeof ReadableStream !== \"undefined\" && body instanceof ReadableStream || body && typeof body === \"object\" && \"pipe\" in body && typeof body.pipe === \"function\") && !options.duplex) options.duplex = \"half\";\n\t\t\t}\n\t\t\tif (fileOptions === null || fileOptions === void 0 ? void 0 : fileOptions.headers) headers = _objectSpread2(_objectSpread2({}, headers), fileOptions.headers);\n\t\t\tconst cleanPath = _this._removeEmptyFolders(path);\n\t\t\tconst _path = _this._getFinalPath(cleanPath);\n\t\t\tconst data = await (method == \"PUT\" ? put : post)(_this.fetch, `${_this.url}/object/${_path}`, body, _objectSpread2({ headers }, (options === null || options === void 0 ? void 0 : options.duplex) ? { duplex: options.duplex } : {}));\n\t\t\treturn {\n\t\t\t\tpath: cleanPath,\n\t\t\t\tid: data.Id,\n\t\t\t\tfullPath: data.Key\n\t\t\t};\n\t\t});\n\t}\n\t/**\n\t* Uploads a file to an existing bucket.\n\t*\n\t* @category File Buckets\n\t* @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n\t* @param fileBody The body of the file to be stored in the bucket.\n\t* @param fileOptions Optional file upload options including cacheControl, contentType, upsert, and metadata.\n\t* @returns Promise with response containing file path, id, and fullPath or error\n\t*\n\t* @example Upload file\n\t* ```js\n\t* const avatarFile = event.target.files[0]\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .upload('public/avatar1.png', avatarFile, {\n\t*     cacheControl: '3600',\n\t*     upsert: false\n\t*   })\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"path\": \"public/avatar1.png\",\n\t*     \"fullPath\": \"avatars/public/avatar1.png\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*\n\t* @example Upload file using `ArrayBuffer` from base64 file data\n\t* ```js\n\t* import { decode } from 'base64-arraybuffer'\n\t*\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .upload('public/avatar1.png', decode('base64FileData'), {\n\t*     contentType: 'image/png'\n\t*   })\n\t* ```\n\t*/\n\tasync upload(path, fileBody, fileOptions) {\n\t\treturn this.uploadOrUpdate(\"POST\", path, fileBody, fileOptions);\n\t}\n\t/**\n\t* Upload a file with a token generated from `createSignedUploadUrl`.\n\t*\n\t* @category File Buckets\n\t* @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n\t* @param token The token generated from `createSignedUploadUrl`\n\t* @param fileBody The body of the file to be stored in the bucket.\n\t* @param fileOptions HTTP headers (cacheControl, contentType, etc.).\n\t* **Note:** The `upsert` option has no effect here. To enable upsert behavior,\n\t* pass `{ upsert: true }` when calling `createSignedUploadUrl()` instead.\n\t* @returns Promise with response containing file path and fullPath or error\n\t*\n\t* @example Upload to a signed URL\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .uploadToSignedUrl('folder/cat.jpg', 'token-from-createSignedUploadUrl', file)\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"path\": \"folder/cat.jpg\",\n\t*     \"fullPath\": \"avatars/folder/cat.jpg\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync uploadToSignedUrl(path, token, fileBody, fileOptions) {\n\t\tvar _this3 = this;\n\t\tconst cleanPath = _this3._removeEmptyFolders(path);\n\t\tconst _path = _this3._getFinalPath(cleanPath);\n\t\tconst url = new URL(_this3.url + `/object/upload/sign/${_path}`);\n\t\turl.searchParams.set(\"token\", token);\n\t\treturn _this3.handleOperation(async () => {\n\t\t\tlet body;\n\t\t\tconst options = _objectSpread2({ upsert: DEFAULT_FILE_OPTIONS.upsert }, fileOptions);\n\t\t\tconst headers = _objectSpread2(_objectSpread2({}, _this3.headers), { \"x-upsert\": String(options.upsert) });\n\t\t\tif (typeof Blob !== \"undefined\" && fileBody instanceof Blob) {\n\t\t\t\tbody = new FormData();\n\t\t\t\tbody.append(\"cacheControl\", options.cacheControl);\n\t\t\t\tbody.append(\"\", fileBody);\n\t\t\t} else if (typeof FormData !== \"undefined\" && fileBody instanceof FormData) {\n\t\t\t\tbody = fileBody;\n\t\t\t\tbody.append(\"cacheControl\", options.cacheControl);\n\t\t\t} else {\n\t\t\t\tbody = fileBody;\n\t\t\t\theaders[\"cache-control\"] = `max-age=${options.cacheControl}`;\n\t\t\t\theaders[\"content-type\"] = options.contentType;\n\t\t\t}\n\t\t\treturn {\n\t\t\t\tpath: cleanPath,\n\t\t\t\tfullPath: (await put(_this3.fetch, url.toString(), body, { headers })).Key\n\t\t\t};\n\t\t});\n\t}\n\t/**\n\t* Creates a signed upload URL.\n\t* Signed upload URLs can be used to upload files to the bucket without further authentication.\n\t* They are valid for 2 hours.\n\t*\n\t* @category File Buckets\n\t* @param path The file path, including the current file name. For example `folder/image.png`.\n\t* @param options.upsert If set to true, allows the file to be overwritten if it already exists.\n\t* @returns Promise with response containing signed upload URL, token, and path or error\n\t*\n\t* @example Create Signed Upload URL\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .createSignedUploadUrl('folder/cat.jpg')\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"signedUrl\": \"https://example.supabase.co/storage/v1/object/upload/sign/avatars/folder/cat.jpg?token=<TOKEN>\",\n\t*     \"path\": \"folder/cat.jpg\",\n\t*     \"token\": \"<TOKEN>\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync createSignedUploadUrl(path, options) {\n\t\tvar _this4 = this;\n\t\treturn _this4.handleOperation(async () => {\n\t\t\tlet _path = _this4._getFinalPath(path);\n\t\t\tconst headers = _objectSpread2({}, _this4.headers);\n\t\t\tif (options === null || options === void 0 ? void 0 : options.upsert) headers[\"x-upsert\"] = \"true\";\n\t\t\tconst data = await post(_this4.fetch, `${_this4.url}/object/upload/sign/${_path}`, {}, { headers });\n\t\t\tconst url = new URL(_this4.url + data.url);\n\t\t\tconst token = url.searchParams.get(\"token\");\n\t\t\tif (!token) throw new StorageError(\"No token returned by API\");\n\t\t\treturn {\n\t\t\t\tsignedUrl: url.toString(),\n\t\t\t\tpath,\n\t\t\t\ttoken\n\t\t\t};\n\t\t});\n\t}\n\t/**\n\t* Replaces an existing file at the specified path with a new one.\n\t*\n\t* @category File Buckets\n\t* @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to update.\n\t* @param fileBody The body of the file to be stored in the bucket.\n\t* @param fileOptions Optional file upload options including cacheControl, contentType, upsert, and metadata.\n\t* @returns Promise with response containing file path, id, and fullPath or error\n\t*\n\t* @example Update file\n\t* ```js\n\t* const avatarFile = event.target.files[0]\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .update('public/avatar1.png', avatarFile, {\n\t*     cacheControl: '3600',\n\t*     upsert: true\n\t*   })\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"path\": \"public/avatar1.png\",\n\t*     \"fullPath\": \"avatars/public/avatar1.png\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*\n\t* @example Update file using `ArrayBuffer` from base64 file data\n\t* ```js\n\t* import {decode} from 'base64-arraybuffer'\n\t*\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .update('public/avatar1.png', decode('base64FileData'), {\n\t*     contentType: 'image/png'\n\t*   })\n\t* ```\n\t*/\n\tasync update(path, fileBody, fileOptions) {\n\t\treturn this.uploadOrUpdate(\"PUT\", path, fileBody, fileOptions);\n\t}\n\t/**\n\t* Moves an existing file to a new path in the same bucket.\n\t*\n\t* @category File Buckets\n\t* @param fromPath The original file path, including the current file name. For example `folder/image.png`.\n\t* @param toPath The new file path, including the new file name. For example `folder/image-new.png`.\n\t* @param options The destination options.\n\t* @returns Promise with response containing success message or error\n\t*\n\t* @example Move file\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .move('public/avatar1.png', 'private/avatar2.png')\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"message\": \"Successfully moved\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync move(fromPath, toPath, options) {\n\t\tvar _this6 = this;\n\t\treturn _this6.handleOperation(async () => {\n\t\t\treturn await post(_this6.fetch, `${_this6.url}/object/move`, {\n\t\t\t\tbucketId: _this6.bucketId,\n\t\t\t\tsourceKey: fromPath,\n\t\t\t\tdestinationKey: toPath,\n\t\t\t\tdestinationBucket: options === null || options === void 0 ? void 0 : options.destinationBucket\n\t\t\t}, { headers: _this6.headers });\n\t\t});\n\t}\n\t/**\n\t* Copies an existing file to a new path in the same bucket.\n\t*\n\t* @category File Buckets\n\t* @param fromPath The original file path, including the current file name. For example `folder/image.png`.\n\t* @param toPath The new file path, including the new file name. For example `folder/image-copy.png`.\n\t* @param options The destination options.\n\t* @returns Promise with response containing copied file path or error\n\t*\n\t* @example Copy file\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .copy('public/avatar1.png', 'private/avatar2.png')\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"path\": \"avatars/private/avatar2.png\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync copy(fromPath, toPath, options) {\n\t\tvar _this7 = this;\n\t\treturn _this7.handleOperation(async () => {\n\t\t\treturn { path: (await post(_this7.fetch, `${_this7.url}/object/copy`, {\n\t\t\t\tbucketId: _this7.bucketId,\n\t\t\t\tsourceKey: fromPath,\n\t\t\t\tdestinationKey: toPath,\n\t\t\t\tdestinationBucket: options === null || options === void 0 ? void 0 : options.destinationBucket\n\t\t\t}, { headers: _this7.headers })).Key };\n\t\t});\n\t}\n\t/**\n\t* Creates a signed URL. Use a signed URL to share a file for a fixed amount of time.\n\t*\n\t* @category File Buckets\n\t* @param path The file path, including the current file name. For example `folder/image.png`.\n\t* @param expiresIn The number of seconds until the signed URL expires. For example, `60` for a URL which is valid for one minute.\n\t* @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n\t* @param options.transform Transform the asset before serving it to the client.\n\t* @returns Promise with response containing signed URL or error\n\t*\n\t* @example Create Signed URL\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .createSignedUrl('folder/avatar1.png', 60)\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*\n\t* @example Create a signed URL for an asset with transformations\n\t* ```js\n\t* const { data } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .createSignedUrl('folder/avatar1.png', 60, {\n\t*     transform: {\n\t*       width: 100,\n\t*       height: 100,\n\t*     }\n\t*   })\n\t* ```\n\t*\n\t* @example Create a signed URL which triggers the download of the asset\n\t* ```js\n\t* const { data } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .createSignedUrl('folder/avatar1.png', 60, {\n\t*     download: true,\n\t*   })\n\t* ```\n\t*/\n\tasync createSignedUrl(path, expiresIn, options) {\n\t\tvar _this8 = this;\n\t\treturn _this8.handleOperation(async () => {\n\t\t\tlet _path = _this8._getFinalPath(path);\n\t\t\tlet data = await post(_this8.fetch, `${_this8.url}/object/sign/${_path}`, _objectSpread2({ expiresIn }, (options === null || options === void 0 ? void 0 : options.transform) ? { transform: options.transform } : {}), { headers: _this8.headers });\n\t\t\tconst downloadQueryParam = (options === null || options === void 0 ? void 0 : options.download) ? `&download=${options.download === true ? \"\" : options.download}` : \"\";\n\t\t\treturn { signedUrl: encodeURI(`${_this8.url}${data.signedURL}${downloadQueryParam}`) };\n\t\t});\n\t}\n\t/**\n\t* Creates multiple signed URLs. Use a signed URL to share a file for a fixed amount of time.\n\t*\n\t* @category File Buckets\n\t* @param paths The file paths to be downloaded, including the current file names. For example `['folder/image.png', 'folder2/image2.png']`.\n\t* @param expiresIn The number of seconds until the signed URLs expire. For example, `60` for URLs which are valid for one minute.\n\t* @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n\t* @returns Promise with response containing array of objects with signedUrl, path, and error or error\n\t*\n\t* @example Create Signed URLs\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .createSignedUrls(['folder/avatar1.png', 'folder/avatar2.png'], 60)\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": [\n\t*     {\n\t*       \"error\": null,\n\t*       \"path\": \"folder/avatar1.png\",\n\t*       \"signedURL\": \"/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\",\n\t*       \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\"\n\t*     },\n\t*     {\n\t*       \"error\": null,\n\t*       \"path\": \"folder/avatar2.png\",\n\t*       \"signedURL\": \"/object/sign/avatars/folder/avatar2.png?token=<TOKEN>\",\n\t*       \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar2.png?token=<TOKEN>\"\n\t*     }\n\t*   ],\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync createSignedUrls(paths, expiresIn, options) {\n\t\tvar _this9 = this;\n\t\treturn _this9.handleOperation(async () => {\n\t\t\tconst data = await post(_this9.fetch, `${_this9.url}/object/sign/${_this9.bucketId}`, {\n\t\t\t\texpiresIn,\n\t\t\t\tpaths\n\t\t\t}, { headers: _this9.headers });\n\t\t\tconst downloadQueryParam = (options === null || options === void 0 ? void 0 : options.download) ? `&download=${options.download === true ? \"\" : options.download}` : \"\";\n\t\t\treturn data.map((datum) => _objectSpread2(_objectSpread2({}, datum), {}, { signedUrl: datum.signedURL ? encodeURI(`${_this9.url}${datum.signedURL}${downloadQueryParam}`) : null }));\n\t\t});\n\t}\n\t/**\n\t* Downloads a file from a private bucket. For public buckets, make a request to the URL returned from `getPublicUrl` instead.\n\t*\n\t* @category File Buckets\n\t* @param path The full path and file name of the file to be downloaded. For example `folder/image.png`.\n\t* @param options.transform Transform the asset before serving it to the client.\n\t* @param parameters Additional fetch parameters like signal for cancellation. Supports standard fetch options including cache control.\n\t* @returns BlobDownloadBuilder instance for downloading the file\n\t*\n\t* @example Download file\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .download('folder/avatar1.png')\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": <BLOB>,\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*\n\t* @example Download file with transformations\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .download('folder/avatar1.png', {\n\t*     transform: {\n\t*       width: 100,\n\t*       height: 100,\n\t*       quality: 80\n\t*     }\n\t*   })\n\t* ```\n\t*\n\t* @example Download with cache control (useful in Edge Functions)\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .download('folder/avatar1.png', {}, { cache: 'no-store' })\n\t* ```\n\t*\n\t* @example Download with abort signal\n\t* ```js\n\t* const controller = new AbortController()\n\t* setTimeout(() => controller.abort(), 5000)\n\t*\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .download('folder/avatar1.png', {}, { signal: controller.signal })\n\t* ```\n\t*/\n\tdownload(path, options, parameters) {\n\t\tconst renderPath = typeof (options === null || options === void 0 ? void 0 : options.transform) !== \"undefined\" ? \"render/image/authenticated\" : \"object\";\n\t\tconst transformationQuery = this.transformOptsToQueryString((options === null || options === void 0 ? void 0 : options.transform) || {});\n\t\tconst queryString = transformationQuery ? `?${transformationQuery}` : \"\";\n\t\tconst _path = this._getFinalPath(path);\n\t\tconst downloadFn = () => get(this.fetch, `${this.url}/${renderPath}/${_path}${queryString}`, {\n\t\t\theaders: this.headers,\n\t\t\tnoResolveJson: true\n\t\t}, parameters);\n\t\treturn new BlobDownloadBuilder(downloadFn, this.shouldThrowOnError);\n\t}\n\t/**\n\t* Retrieves the details of an existing file.\n\t*\n\t* @category File Buckets\n\t* @param path The file path, including the file name. For example `folder/image.png`.\n\t* @returns Promise with response containing file metadata or error\n\t*\n\t* @example Get file info\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .info('folder/avatar1.png')\n\t* ```\n\t*/\n\tasync info(path) {\n\t\tvar _this10 = this;\n\t\tconst _path = _this10._getFinalPath(path);\n\t\treturn _this10.handleOperation(async () => {\n\t\t\treturn recursiveToCamel(await get(_this10.fetch, `${_this10.url}/object/info/${_path}`, { headers: _this10.headers }));\n\t\t});\n\t}\n\t/**\n\t* Checks the existence of a file.\n\t*\n\t* @category File Buckets\n\t* @param path The file path, including the file name. For example `folder/image.png`.\n\t* @returns Promise with response containing boolean indicating file existence or error\n\t*\n\t* @example Check file existence\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .exists('folder/avatar1.png')\n\t* ```\n\t*/\n\tasync exists(path) {\n\t\tvar _this11 = this;\n\t\tconst _path = _this11._getFinalPath(path);\n\t\ttry {\n\t\t\tawait head(_this11.fetch, `${_this11.url}/object/${_path}`, { headers: _this11.headers });\n\t\t\treturn {\n\t\t\t\tdata: true,\n\t\t\t\terror: null\n\t\t\t};\n\t\t} catch (error) {\n\t\t\tif (_this11.shouldThrowOnError) throw error;\n\t\t\tif (isStorageError(error) && error instanceof StorageUnknownError) {\n\t\t\t\tconst originalError = error.originalError;\n\t\t\t\tif ([400, 404].includes(originalError === null || originalError === void 0 ? void 0 : originalError.status)) return {\n\t\t\t\t\tdata: false,\n\t\t\t\t\terror\n\t\t\t\t};\n\t\t\t}\n\t\t\tthrow error;\n\t\t}\n\t}\n\t/**\n\t* A simple convenience function to get the URL for an asset in a public bucket. If you do not want to use this function, you can construct the public URL by concatenating the bucket URL with the path to the asset.\n\t* This function does not verify if the bucket is public. If a public URL is created for a bucket which is not public, you will not be able to download the asset.\n\t*\n\t* @category File Buckets\n\t* @param path The path and name of the file to generate the public URL for. For example `folder/image.png`.\n\t* @param options.download Triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n\t* @param options.transform Transform the asset before serving it to the client.\n\t* @returns Object with public URL\n\t*\n\t* @example Returns the URL for an asset in a public bucket\n\t* ```js\n\t* const { data } = supabase\n\t*   .storage\n\t*   .from('public-bucket')\n\t*   .getPublicUrl('folder/avatar1.png')\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"publicUrl\": \"https://example.supabase.co/storage/v1/object/public/public-bucket/folder/avatar1.png\"\n\t*   }\n\t* }\n\t* ```\n\t*\n\t* @example Returns the URL for an asset in a public bucket with transformations\n\t* ```js\n\t* const { data } = supabase\n\t*   .storage\n\t*   .from('public-bucket')\n\t*   .getPublicUrl('folder/avatar1.png', {\n\t*     transform: {\n\t*       width: 100,\n\t*       height: 100,\n\t*     }\n\t*   })\n\t* ```\n\t*\n\t* @example Returns the URL which triggers the download of an asset in a public bucket\n\t* ```js\n\t* const { data } = supabase\n\t*   .storage\n\t*   .from('public-bucket')\n\t*   .getPublicUrl('folder/avatar1.png', {\n\t*     download: true,\n\t*   })\n\t* ```\n\t*/\n\tgetPublicUrl(path, options) {\n\t\tconst _path = this._getFinalPath(path);\n\t\tconst _queryString = [];\n\t\tconst downloadQueryParam = (options === null || options === void 0 ? void 0 : options.download) ? `download=${options.download === true ? \"\" : options.download}` : \"\";\n\t\tif (downloadQueryParam !== \"\") _queryString.push(downloadQueryParam);\n\t\tconst renderPath = typeof (options === null || options === void 0 ? void 0 : options.transform) !== \"undefined\" ? \"render/image\" : \"object\";\n\t\tconst transformationQuery = this.transformOptsToQueryString((options === null || options === void 0 ? void 0 : options.transform) || {});\n\t\tif (transformationQuery !== \"\") _queryString.push(transformationQuery);\n\t\tlet queryString = _queryString.join(\"&\");\n\t\tif (queryString !== \"\") queryString = `?${queryString}`;\n\t\treturn { data: { publicUrl: encodeURI(`${this.url}/${renderPath}/public/${_path}${queryString}`) } };\n\t}\n\t/**\n\t* Deletes files within the same bucket\n\t*\n\t* @category File Buckets\n\t* @param paths An array of files to delete, including the path and file name. For example [`'folder/image.png'`].\n\t* @returns Promise with response containing array of deleted file objects or error\n\t*\n\t* @example Delete file\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .remove(['folder/avatar1.png'])\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": [],\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync remove(paths) {\n\t\tvar _this12 = this;\n\t\treturn _this12.handleOperation(async () => {\n\t\t\treturn await remove(_this12.fetch, `${_this12.url}/object/${_this12.bucketId}`, { prefixes: paths }, { headers: _this12.headers });\n\t\t});\n\t}\n\t/**\n\t* Get file metadata\n\t* @param id the file id to retrieve metadata\n\t*/\n\t/**\n\t* Update file metadata\n\t* @param id the file id to update metadata\n\t* @param meta the new file metadata\n\t*/\n\t/**\n\t* Lists all the files and folders within a path of the bucket.\n\t*\n\t* @category File Buckets\n\t* @param path The folder path.\n\t* @param options Search options including limit (defaults to 100), offset, sortBy, and search\n\t* @param parameters Optional fetch parameters including signal for cancellation\n\t* @returns Promise with response containing array of files or error\n\t*\n\t* @example List files in a bucket\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .list('folder', {\n\t*     limit: 100,\n\t*     offset: 0,\n\t*     sortBy: { column: 'name', order: 'asc' },\n\t*   })\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": [\n\t*     {\n\t*       \"name\": \"avatar1.png\",\n\t*       \"id\": \"e668cf7f-821b-4a2f-9dce-7dfa5dd1cfd2\",\n\t*       \"updated_at\": \"2024-05-22T23:06:05.580Z\",\n\t*       \"created_at\": \"2024-05-22T23:04:34.443Z\",\n\t*       \"last_accessed_at\": \"2024-05-22T23:04:34.443Z\",\n\t*       \"metadata\": {\n\t*         \"eTag\": \"\\\"c5e8c553235d9af30ef4f6e280790b92\\\"\",\n\t*         \"size\": 32175,\n\t*         \"mimetype\": \"image/png\",\n\t*         \"cacheControl\": \"max-age=3600\",\n\t*         \"lastModified\": \"2024-05-22T23:06:05.574Z\",\n\t*         \"contentLength\": 32175,\n\t*         \"httpStatusCode\": 200\n\t*       }\n\t*     }\n\t*   ],\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*\n\t* @example Search files in a bucket\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .from('avatars')\n\t*   .list('folder', {\n\t*     limit: 100,\n\t*     offset: 0,\n\t*     sortBy: { column: 'name', order: 'asc' },\n\t*     search: 'jon'\n\t*   })\n\t* ```\n\t*/\n\tasync list(path, options, parameters) {\n\t\tvar _this13 = this;\n\t\treturn _this13.handleOperation(async () => {\n\t\t\tconst body = _objectSpread2(_objectSpread2(_objectSpread2({}, DEFAULT_SEARCH_OPTIONS), options), {}, { prefix: path || \"\" });\n\t\t\treturn await post(_this13.fetch, `${_this13.url}/object/list/${_this13.bucketId}`, body, { headers: _this13.headers }, parameters);\n\t\t});\n\t}\n\t/**\n\t* @experimental this method signature might change in the future\n\t*\n\t* @category File Buckets\n\t* @param options search options\n\t* @param parameters\n\t*/\n\tasync listV2(options, parameters) {\n\t\tvar _this14 = this;\n\t\treturn _this14.handleOperation(async () => {\n\t\t\tconst body = _objectSpread2({}, options);\n\t\t\treturn await post(_this14.fetch, `${_this14.url}/object/list-v2/${_this14.bucketId}`, body, { headers: _this14.headers }, parameters);\n\t\t});\n\t}\n\tencodeMetadata(metadata) {\n\t\treturn JSON.stringify(metadata);\n\t}\n\ttoBase64(data) {\n\t\tif (typeof Buffer !== \"undefined\") return Buffer.from(data).toString(\"base64\");\n\t\treturn btoa(data);\n\t}\n\t_getFinalPath(path) {\n\t\treturn `${this.bucketId}/${path.replace(/^\\/+/, \"\")}`;\n\t}\n\t_removeEmptyFolders(path) {\n\t\treturn path.replace(/^\\/|\\/$/g, \"\").replace(/\\/+/g, \"/\");\n\t}\n\ttransformOptsToQueryString(transform) {\n\t\tconst params = [];\n\t\tif (transform.width) params.push(`width=${transform.width}`);\n\t\tif (transform.height) params.push(`height=${transform.height}`);\n\t\tif (transform.resize) params.push(`resize=${transform.resize}`);\n\t\tif (transform.format) params.push(`format=${transform.format}`);\n\t\tif (transform.quality) params.push(`quality=${transform.quality}`);\n\t\treturn params.join(\"&\");\n\t}\n};\n\n//#endregion\n//#region src/lib/version.ts\nconst version = \"2.97.0\";\n\n//#endregion\n//#region src/lib/constants.ts\nconst DEFAULT_HEADERS = { \"X-Client-Info\": `storage-js/${version}` };\n\n//#endregion\n//#region src/packages/StorageBucketApi.ts\nvar StorageBucketApi = class extends BaseApiClient {\n\tconstructor(url, headers = {}, fetch$1, opts) {\n\t\tconst baseUrl = new URL(url);\n\t\tif (opts === null || opts === void 0 ? void 0 : opts.useNewHostname) {\n\t\t\tif (/supabase\\.(co|in|red)$/.test(baseUrl.hostname) && !baseUrl.hostname.includes(\"storage.supabase.\")) baseUrl.hostname = baseUrl.hostname.replace(\"supabase.\", \"storage.supabase.\");\n\t\t}\n\t\tconst finalUrl = baseUrl.href.replace(/\\/$/, \"\");\n\t\tconst finalHeaders = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), headers);\n\t\tsuper(finalUrl, finalHeaders, fetch$1, \"storage\");\n\t}\n\t/**\n\t* Retrieves the details of all Storage buckets within an existing project.\n\t*\n\t* @category File Buckets\n\t* @param options Query parameters for listing buckets\n\t* @param options.limit Maximum number of buckets to return\n\t* @param options.offset Number of buckets to skip\n\t* @param options.sortColumn Column to sort by ('id', 'name', 'created_at', 'updated_at')\n\t* @param options.sortOrder Sort order ('asc' or 'desc')\n\t* @param options.search Search term to filter bucket names\n\t* @returns Promise with response containing array of buckets or error\n\t*\n\t* @example List buckets\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .listBuckets()\n\t* ```\n\t*\n\t* @example List buckets with options\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .listBuckets({\n\t*     limit: 10,\n\t*     offset: 0,\n\t*     sortColumn: 'created_at',\n\t*     sortOrder: 'desc',\n\t*     search: 'prod'\n\t*   })\n\t* ```\n\t*/\n\tasync listBuckets(options) {\n\t\tvar _this = this;\n\t\treturn _this.handleOperation(async () => {\n\t\t\tconst queryString = _this.listBucketOptionsToQueryString(options);\n\t\t\treturn await get(_this.fetch, `${_this.url}/bucket${queryString}`, { headers: _this.headers });\n\t\t});\n\t}\n\t/**\n\t* Retrieves the details of an existing Storage bucket.\n\t*\n\t* @category File Buckets\n\t* @param id The unique identifier of the bucket you would like to retrieve.\n\t* @returns Promise with response containing bucket details or error\n\t*\n\t* @example Get bucket\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .getBucket('avatars')\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"id\": \"avatars\",\n\t*     \"name\": \"avatars\",\n\t*     \"owner\": \"\",\n\t*     \"public\": false,\n\t*     \"file_size_limit\": 1024,\n\t*     \"allowed_mime_types\": [\n\t*       \"image/png\"\n\t*     ],\n\t*     \"created_at\": \"2024-05-22T22:26:05.100Z\",\n\t*     \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync getBucket(id) {\n\t\tvar _this2 = this;\n\t\treturn _this2.handleOperation(async () => {\n\t\t\treturn await get(_this2.fetch, `${_this2.url}/bucket/${id}`, { headers: _this2.headers });\n\t\t});\n\t}\n\t/**\n\t* Creates a new Storage bucket\n\t*\n\t* @category File Buckets\n\t* @param id A unique identifier for the bucket you are creating.\n\t* @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations. By default, buckets are private.\n\t* @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\n\t* The global file size limit takes precedence over this value.\n\t* The default value is null, which doesn't set a per bucket file size limit.\n\t* @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\n\t* The default value is null, which allows files with all mime types to be uploaded.\n\t* Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\n\t* @param options.type (private-beta) specifies the bucket type. see `BucketType` for more details.\n\t*   - default bucket type is `STANDARD`\n\t* @returns Promise with response containing newly created bucket name or error\n\t*\n\t* @example Create bucket\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .createBucket('avatars', {\n\t*     public: false,\n\t*     allowedMimeTypes: ['image/png'],\n\t*     fileSizeLimit: 1024\n\t*   })\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"name\": \"avatars\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync createBucket(id, options = { public: false }) {\n\t\tvar _this3 = this;\n\t\treturn _this3.handleOperation(async () => {\n\t\t\treturn await post(_this3.fetch, `${_this3.url}/bucket`, {\n\t\t\t\tid,\n\t\t\t\tname: id,\n\t\t\t\ttype: options.type,\n\t\t\t\tpublic: options.public,\n\t\t\t\tfile_size_limit: options.fileSizeLimit,\n\t\t\t\tallowed_mime_types: options.allowedMimeTypes\n\t\t\t}, { headers: _this3.headers });\n\t\t});\n\t}\n\t/**\n\t* Updates a Storage bucket\n\t*\n\t* @category File Buckets\n\t* @param id A unique identifier for the bucket you are updating.\n\t* @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations.\n\t* @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\n\t* The global file size limit takes precedence over this value.\n\t* The default value is null, which doesn't set a per bucket file size limit.\n\t* @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\n\t* The default value is null, which allows files with all mime types to be uploaded.\n\t* Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\n\t* @returns Promise with response containing success message or error\n\t*\n\t* @example Update bucket\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .updateBucket('avatars', {\n\t*     public: false,\n\t*     allowedMimeTypes: ['image/png'],\n\t*     fileSizeLimit: 1024\n\t*   })\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"message\": \"Successfully updated\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync updateBucket(id, options) {\n\t\tvar _this4 = this;\n\t\treturn _this4.handleOperation(async () => {\n\t\t\treturn await put(_this4.fetch, `${_this4.url}/bucket/${id}`, {\n\t\t\t\tid,\n\t\t\t\tname: id,\n\t\t\t\tpublic: options.public,\n\t\t\t\tfile_size_limit: options.fileSizeLimit,\n\t\t\t\tallowed_mime_types: options.allowedMimeTypes\n\t\t\t}, { headers: _this4.headers });\n\t\t});\n\t}\n\t/**\n\t* Removes all objects inside a single bucket.\n\t*\n\t* @category File Buckets\n\t* @param id The unique identifier of the bucket you would like to empty.\n\t* @returns Promise with success message or error\n\t*\n\t* @example Empty bucket\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .emptyBucket('avatars')\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"message\": \"Successfully emptied\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync emptyBucket(id) {\n\t\tvar _this5 = this;\n\t\treturn _this5.handleOperation(async () => {\n\t\t\treturn await post(_this5.fetch, `${_this5.url}/bucket/${id}/empty`, {}, { headers: _this5.headers });\n\t\t});\n\t}\n\t/**\n\t* Deletes an existing bucket. A bucket can't be deleted with existing objects inside it.\n\t* You must first `empty()` the bucket.\n\t*\n\t* @category File Buckets\n\t* @param id The unique identifier of the bucket you would like to delete.\n\t* @returns Promise with success message or error\n\t*\n\t* @example Delete bucket\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .deleteBucket('avatars')\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"message\": \"Successfully deleted\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync deleteBucket(id) {\n\t\tvar _this6 = this;\n\t\treturn _this6.handleOperation(async () => {\n\t\t\treturn await remove(_this6.fetch, `${_this6.url}/bucket/${id}`, {}, { headers: _this6.headers });\n\t\t});\n\t}\n\tlistBucketOptionsToQueryString(options) {\n\t\tconst params = {};\n\t\tif (options) {\n\t\t\tif (\"limit\" in options) params.limit = String(options.limit);\n\t\t\tif (\"offset\" in options) params.offset = String(options.offset);\n\t\t\tif (options.search) params.search = options.search;\n\t\t\tif (options.sortColumn) params.sortColumn = options.sortColumn;\n\t\t\tif (options.sortOrder) params.sortOrder = options.sortOrder;\n\t\t}\n\t\treturn Object.keys(params).length > 0 ? \"?\" + new URLSearchParams(params).toString() : \"\";\n\t}\n};\n\n//#endregion\n//#region src/packages/StorageAnalyticsClient.ts\n/**\n* Client class for managing Analytics Buckets using Iceberg tables\n* Provides methods for creating, listing, and deleting analytics buckets\n*/\nvar StorageAnalyticsClient = class extends BaseApiClient {\n\t/**\n\t* @alpha\n\t*\n\t* Creates a new StorageAnalyticsClient instance\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Analytics Buckets\n\t* @param url - The base URL for the storage API\n\t* @param headers - HTTP headers to include in requests\n\t* @param fetch - Optional custom fetch implementation\n\t*\n\t* @example\n\t* ```typescript\n\t* const client = new StorageAnalyticsClient(url, headers)\n\t* ```\n\t*/\n\tconstructor(url, headers = {}, fetch$1) {\n\t\tconst finalUrl = url.replace(/\\/$/, \"\");\n\t\tconst finalHeaders = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), headers);\n\t\tsuper(finalUrl, finalHeaders, fetch$1, \"storage\");\n\t}\n\t/**\n\t* @alpha\n\t*\n\t* Creates a new analytics bucket using Iceberg tables\n\t* Analytics buckets are optimized for analytical queries and data processing\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Analytics Buckets\n\t* @param name A unique name for the bucket you are creating\n\t* @returns Promise with response containing newly created analytics bucket or error\n\t*\n\t* @example Create analytics bucket\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .analytics\n\t*   .createBucket('analytics-data')\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"name\": \"analytics-data\",\n\t*     \"type\": \"ANALYTICS\",\n\t*     \"format\": \"iceberg\",\n\t*     \"created_at\": \"2024-05-22T22:26:05.100Z\",\n\t*     \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync createBucket(name) {\n\t\tvar _this = this;\n\t\treturn _this.handleOperation(async () => {\n\t\t\treturn await post(_this.fetch, `${_this.url}/bucket`, { name }, { headers: _this.headers });\n\t\t});\n\t}\n\t/**\n\t* @alpha\n\t*\n\t* Retrieves the details of all Analytics Storage buckets within an existing project\n\t* Only returns buckets of type 'ANALYTICS'\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Analytics Buckets\n\t* @param options Query parameters for listing buckets\n\t* @param options.limit Maximum number of buckets to return\n\t* @param options.offset Number of buckets to skip\n\t* @param options.sortColumn Column to sort by ('name', 'created_at', 'updated_at')\n\t* @param options.sortOrder Sort order ('asc' or 'desc')\n\t* @param options.search Search term to filter bucket names\n\t* @returns Promise with response containing array of analytics buckets or error\n\t*\n\t* @example List analytics buckets\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .analytics\n\t*   .listBuckets({\n\t*     limit: 10,\n\t*     offset: 0,\n\t*     sortColumn: 'created_at',\n\t*     sortOrder: 'desc'\n\t*   })\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": [\n\t*     {\n\t*       \"name\": \"analytics-data\",\n\t*       \"type\": \"ANALYTICS\",\n\t*       \"format\": \"iceberg\",\n\t*       \"created_at\": \"2024-05-22T22:26:05.100Z\",\n\t*       \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n\t*     }\n\t*   ],\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync listBuckets(options) {\n\t\tvar _this2 = this;\n\t\treturn _this2.handleOperation(async () => {\n\t\t\tconst queryParams = new URLSearchParams();\n\t\t\tif ((options === null || options === void 0 ? void 0 : options.limit) !== void 0) queryParams.set(\"limit\", options.limit.toString());\n\t\t\tif ((options === null || options === void 0 ? void 0 : options.offset) !== void 0) queryParams.set(\"offset\", options.offset.toString());\n\t\t\tif (options === null || options === void 0 ? void 0 : options.sortColumn) queryParams.set(\"sortColumn\", options.sortColumn);\n\t\t\tif (options === null || options === void 0 ? void 0 : options.sortOrder) queryParams.set(\"sortOrder\", options.sortOrder);\n\t\t\tif (options === null || options === void 0 ? void 0 : options.search) queryParams.set(\"search\", options.search);\n\t\t\tconst queryString = queryParams.toString();\n\t\t\tconst url = queryString ? `${_this2.url}/bucket?${queryString}` : `${_this2.url}/bucket`;\n\t\t\treturn await get(_this2.fetch, url, { headers: _this2.headers });\n\t\t});\n\t}\n\t/**\n\t* @alpha\n\t*\n\t* Deletes an existing analytics bucket\n\t* A bucket can't be deleted with existing objects inside it\n\t* You must first empty the bucket before deletion\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Analytics Buckets\n\t* @param bucketName The unique identifier of the bucket you would like to delete\n\t* @returns Promise with response containing success message or error\n\t*\n\t* @example Delete analytics bucket\n\t* ```js\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .analytics\n\t*   .deleteBucket('analytics-data')\n\t* ```\n\t*\n\t* Response:\n\t* ```json\n\t* {\n\t*   \"data\": {\n\t*     \"message\": \"Successfully deleted\"\n\t*   },\n\t*   \"error\": null\n\t* }\n\t* ```\n\t*/\n\tasync deleteBucket(bucketName) {\n\t\tvar _this3 = this;\n\t\treturn _this3.handleOperation(async () => {\n\t\t\treturn await remove(_this3.fetch, `${_this3.url}/bucket/${bucketName}`, {}, { headers: _this3.headers });\n\t\t});\n\t}\n\t/**\n\t* @alpha\n\t*\n\t* Get an Iceberg REST Catalog client configured for a specific analytics bucket\n\t* Use this to perform advanced table and namespace operations within the bucket\n\t* The returned client provides full access to the Apache Iceberg REST Catalog API\n\t* with the Supabase `{ data, error }` pattern for consistent error handling on all operations.\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Analytics Buckets\n\t* @param bucketName - The name of the analytics bucket (warehouse) to connect to\n\t* @returns The wrapped Iceberg catalog client\n\t* @throws {StorageError} If the bucket name is invalid\n\t*\n\t* @example Get catalog and create table\n\t* ```js\n\t* // First, create an analytics bucket\n\t* const { data: bucket, error: bucketError } = await supabase\n\t*   .storage\n\t*   .analytics\n\t*   .createBucket('analytics-data')\n\t*\n\t* // Get the Iceberg catalog for that bucket\n\t* const catalog = supabase.storage.analytics.from('analytics-data')\n\t*\n\t* // Create a namespace\n\t* const { error: nsError } = await catalog.createNamespace({ namespace: ['default'] })\n\t*\n\t* // Create a table with schema\n\t* const { data: tableMetadata, error: tableError } = await catalog.createTable(\n\t*   { namespace: ['default'] },\n\t*   {\n\t*     name: 'events',\n\t*     schema: {\n\t*       type: 'struct',\n\t*       fields: [\n\t*         { id: 1, name: 'id', type: 'long', required: true },\n\t*         { id: 2, name: 'timestamp', type: 'timestamp', required: true },\n\t*         { id: 3, name: 'user_id', type: 'string', required: false }\n\t*       ],\n\t*       'schema-id': 0,\n\t*       'identifier-field-ids': [1]\n\t*     },\n\t*     'partition-spec': {\n\t*       'spec-id': 0,\n\t*       fields: []\n\t*     },\n\t*     'write-order': {\n\t*       'order-id': 0,\n\t*       fields: []\n\t*     },\n\t*     properties: {\n\t*       'write.format.default': 'parquet'\n\t*     }\n\t*   }\n\t* )\n\t* ```\n\t*\n\t* @example List tables in namespace\n\t* ```js\n\t* const catalog = supabase.storage.analytics.from('analytics-data')\n\t*\n\t* // List all tables in the default namespace\n\t* const { data: tables, error: listError } = await catalog.listTables({ namespace: ['default'] })\n\t* if (listError) {\n\t*   if (listError.isNotFound()) {\n\t*     console.log('Namespace not found')\n\t*   }\n\t*   return\n\t* }\n\t* console.log(tables) // [{ namespace: ['default'], name: 'events' }]\n\t* ```\n\t*\n\t* @example Working with namespaces\n\t* ```js\n\t* const catalog = supabase.storage.analytics.from('analytics-data')\n\t*\n\t* // List all namespaces\n\t* const { data: namespaces } = await catalog.listNamespaces()\n\t*\n\t* // Create namespace with properties\n\t* await catalog.createNamespace(\n\t*   { namespace: ['production'] },\n\t*   { properties: { owner: 'data-team', env: 'prod' } }\n\t* )\n\t* ```\n\t*\n\t* @example Cleanup operations\n\t* ```js\n\t* const catalog = supabase.storage.analytics.from('analytics-data')\n\t*\n\t* // Drop table with purge option (removes all data)\n\t* const { error: dropError } = await catalog.dropTable(\n\t*   { namespace: ['default'], name: 'events' },\n\t*   { purge: true }\n\t* )\n\t*\n\t* if (dropError?.isNotFound()) {\n\t*   console.log('Table does not exist')\n\t* }\n\t*\n\t* // Drop namespace (must be empty)\n\t* await catalog.dropNamespace({ namespace: ['default'] })\n\t* ```\n\t*\n\t* @remarks\n\t* This method provides a bridge between Supabase's bucket management and the standard\n\t* Apache Iceberg REST Catalog API. The bucket name maps to the Iceberg warehouse parameter.\n\t* All authentication and configuration is handled automatically using your Supabase credentials.\n\t*\n\t* **Error Handling**: Invalid bucket names throw immediately. All catalog\n\t* operations return `{ data, error }` where errors are `IcebergError` instances from iceberg-js.\n\t* Use helper methods like `error.isNotFound()` or check `error.status` for specific error handling.\n\t* Use `.throwOnError()` on the analytics client if you prefer exceptions for catalog operations.\n\t*\n\t* **Cleanup Operations**: When using `dropTable`, the `purge: true` option permanently\n\t* deletes all table data. Without it, the table is marked as deleted but data remains.\n\t*\n\t* **Library Dependency**: The returned catalog wraps `IcebergRestCatalog` from iceberg-js.\n\t* For complete API documentation and advanced usage, refer to the\n\t* [iceberg-js documentation](https://supabase.github.io/iceberg-js/).\n\t*/\n\tfrom(bucketName) {\n\t\tvar _this4 = this;\n\t\tif (!isValidBucketName(bucketName)) throw new StorageError(\"Invalid bucket name: File, folder, and bucket names must follow AWS object key naming guidelines and should avoid the use of any other characters.\");\n\t\tconst catalog = new iceberg_js.IcebergRestCatalog({\n\t\t\tbaseUrl: this.url,\n\t\t\tcatalogName: bucketName,\n\t\t\tauth: {\n\t\t\t\ttype: \"custom\",\n\t\t\t\tgetHeaders: async () => _this4.headers\n\t\t\t},\n\t\t\tfetch: this.fetch\n\t\t});\n\t\tconst shouldThrowOnError = this.shouldThrowOnError;\n\t\treturn new Proxy(catalog, { get(target, prop) {\n\t\t\tconst value = target[prop];\n\t\t\tif (typeof value !== \"function\") return value;\n\t\t\treturn async (...args) => {\n\t\t\t\ttry {\n\t\t\t\t\treturn {\n\t\t\t\t\t\tdata: await value.apply(target, args),\n\t\t\t\t\t\terror: null\n\t\t\t\t\t};\n\t\t\t\t} catch (error) {\n\t\t\t\t\tif (shouldThrowOnError) throw error;\n\t\t\t\t\treturn {\n\t\t\t\t\t\tdata: null,\n\t\t\t\t\t\terror\n\t\t\t\t\t};\n\t\t\t\t}\n\t\t\t};\n\t\t} });\n\t}\n};\n\n//#endregion\n//#region src/packages/VectorIndexApi.ts\n/**\n* @hidden\n* Base implementation for vector index operations.\n* Use {@link VectorBucketScope} via `supabase.storage.vectors.from('bucket')` instead.\n*/\nvar VectorIndexApi = class extends BaseApiClient {\n\t/** Creates a new VectorIndexApi instance */\n\tconstructor(url, headers = {}, fetch$1) {\n\t\tconst finalUrl = url.replace(/\\/$/, \"\");\n\t\tconst finalHeaders = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), {}, { \"Content-Type\": \"application/json\" }, headers);\n\t\tsuper(finalUrl, finalHeaders, fetch$1, \"vectors\");\n\t}\n\t/** Creates a new vector index within a bucket */\n\tasync createIndex(options) {\n\t\tvar _this = this;\n\t\treturn _this.handleOperation(async () => {\n\t\t\treturn await vectorsApi.post(_this.fetch, `${_this.url}/CreateIndex`, options, { headers: _this.headers }) || {};\n\t\t});\n\t}\n\t/** Retrieves metadata for a specific vector index */\n\tasync getIndex(vectorBucketName, indexName) {\n\t\tvar _this2 = this;\n\t\treturn _this2.handleOperation(async () => {\n\t\t\treturn await vectorsApi.post(_this2.fetch, `${_this2.url}/GetIndex`, {\n\t\t\t\tvectorBucketName,\n\t\t\t\tindexName\n\t\t\t}, { headers: _this2.headers });\n\t\t});\n\t}\n\t/** Lists vector indexes within a bucket with optional filtering and pagination */\n\tasync listIndexes(options) {\n\t\tvar _this3 = this;\n\t\treturn _this3.handleOperation(async () => {\n\t\t\treturn await vectorsApi.post(_this3.fetch, `${_this3.url}/ListIndexes`, options, { headers: _this3.headers });\n\t\t});\n\t}\n\t/** Deletes a vector index and all its data */\n\tasync deleteIndex(vectorBucketName, indexName) {\n\t\tvar _this4 = this;\n\t\treturn _this4.handleOperation(async () => {\n\t\t\treturn await vectorsApi.post(_this4.fetch, `${_this4.url}/DeleteIndex`, {\n\t\t\t\tvectorBucketName,\n\t\t\t\tindexName\n\t\t\t}, { headers: _this4.headers }) || {};\n\t\t});\n\t}\n};\n\n//#endregion\n//#region src/packages/VectorDataApi.ts\n/**\n* @hidden\n* Base implementation for vector data operations.\n* Use {@link VectorIndexScope} via `supabase.storage.vectors.from('bucket').index('idx')` instead.\n*/\nvar VectorDataApi = class extends BaseApiClient {\n\t/** Creates a new VectorDataApi instance */\n\tconstructor(url, headers = {}, fetch$1) {\n\t\tconst finalUrl = url.replace(/\\/$/, \"\");\n\t\tconst finalHeaders = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), {}, { \"Content-Type\": \"application/json\" }, headers);\n\t\tsuper(finalUrl, finalHeaders, fetch$1, \"vectors\");\n\t}\n\t/** Inserts or updates vectors in batch (1-500 per request) */\n\tasync putVectors(options) {\n\t\tvar _this = this;\n\t\tif (options.vectors.length < 1 || options.vectors.length > 500) throw new Error(\"Vector batch size must be between 1 and 500 items\");\n\t\treturn _this.handleOperation(async () => {\n\t\t\treturn await vectorsApi.post(_this.fetch, `${_this.url}/PutVectors`, options, { headers: _this.headers }) || {};\n\t\t});\n\t}\n\t/** Retrieves vectors by their keys in batch */\n\tasync getVectors(options) {\n\t\tvar _this2 = this;\n\t\treturn _this2.handleOperation(async () => {\n\t\t\treturn await vectorsApi.post(_this2.fetch, `${_this2.url}/GetVectors`, options, { headers: _this2.headers });\n\t\t});\n\t}\n\t/** Lists vectors in an index with pagination */\n\tasync listVectors(options) {\n\t\tvar _this3 = this;\n\t\tif (options.segmentCount !== void 0) {\n\t\t\tif (options.segmentCount < 1 || options.segmentCount > 16) throw new Error(\"segmentCount must be between 1 and 16\");\n\t\t\tif (options.segmentIndex !== void 0) {\n\t\t\t\tif (options.segmentIndex < 0 || options.segmentIndex >= options.segmentCount) throw new Error(`segmentIndex must be between 0 and ${options.segmentCount - 1}`);\n\t\t\t}\n\t\t}\n\t\treturn _this3.handleOperation(async () => {\n\t\t\treturn await vectorsApi.post(_this3.fetch, `${_this3.url}/ListVectors`, options, { headers: _this3.headers });\n\t\t});\n\t}\n\t/** Queries for similar vectors using approximate nearest neighbor search */\n\tasync queryVectors(options) {\n\t\tvar _this4 = this;\n\t\treturn _this4.handleOperation(async () => {\n\t\t\treturn await vectorsApi.post(_this4.fetch, `${_this4.url}/QueryVectors`, options, { headers: _this4.headers });\n\t\t});\n\t}\n\t/** Deletes vectors by their keys in batch (1-500 per request) */\n\tasync deleteVectors(options) {\n\t\tvar _this5 = this;\n\t\tif (options.keys.length < 1 || options.keys.length > 500) throw new Error(\"Keys batch size must be between 1 and 500 items\");\n\t\treturn _this5.handleOperation(async () => {\n\t\t\treturn await vectorsApi.post(_this5.fetch, `${_this5.url}/DeleteVectors`, options, { headers: _this5.headers }) || {};\n\t\t});\n\t}\n};\n\n//#endregion\n//#region src/packages/VectorBucketApi.ts\n/**\n* @hidden\n* Base implementation for vector bucket operations.\n* Use {@link StorageVectorsClient} via `supabase.storage.vectors` instead.\n*/\nvar VectorBucketApi = class extends BaseApiClient {\n\t/** Creates a new VectorBucketApi instance */\n\tconstructor(url, headers = {}, fetch$1) {\n\t\tconst finalUrl = url.replace(/\\/$/, \"\");\n\t\tconst finalHeaders = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), {}, { \"Content-Type\": \"application/json\" }, headers);\n\t\tsuper(finalUrl, finalHeaders, fetch$1, \"vectors\");\n\t}\n\t/** Creates a new vector bucket */\n\tasync createBucket(vectorBucketName) {\n\t\tvar _this = this;\n\t\treturn _this.handleOperation(async () => {\n\t\t\treturn await vectorsApi.post(_this.fetch, `${_this.url}/CreateVectorBucket`, { vectorBucketName }, { headers: _this.headers }) || {};\n\t\t});\n\t}\n\t/** Retrieves metadata for a specific vector bucket */\n\tasync getBucket(vectorBucketName) {\n\t\tvar _this2 = this;\n\t\treturn _this2.handleOperation(async () => {\n\t\t\treturn await vectorsApi.post(_this2.fetch, `${_this2.url}/GetVectorBucket`, { vectorBucketName }, { headers: _this2.headers });\n\t\t});\n\t}\n\t/** Lists vector buckets with optional filtering and pagination */\n\tasync listBuckets(options = {}) {\n\t\tvar _this3 = this;\n\t\treturn _this3.handleOperation(async () => {\n\t\t\treturn await vectorsApi.post(_this3.fetch, `${_this3.url}/ListVectorBuckets`, options, { headers: _this3.headers });\n\t\t});\n\t}\n\t/** Deletes a vector bucket (must be empty first) */\n\tasync deleteBucket(vectorBucketName) {\n\t\tvar _this4 = this;\n\t\treturn _this4.handleOperation(async () => {\n\t\t\treturn await vectorsApi.post(_this4.fetch, `${_this4.url}/DeleteVectorBucket`, { vectorBucketName }, { headers: _this4.headers }) || {};\n\t\t});\n\t}\n};\n\n//#endregion\n//#region src/packages/StorageVectorsClient.ts\n/**\n*\n* @alpha\n*\n* Main client for interacting with S3 Vectors API\n* Provides access to bucket, index, and vector data operations\n*\n* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n*\n* **Usage Patterns:**\n*\n* ```typescript\n* const { data, error } = await supabase\n*  .storage\n*  .vectors\n*  .createBucket('embeddings-prod')\n*\n* // Access index operations via buckets\n* const bucket = supabase.storage.vectors.from('embeddings-prod')\n* await bucket.createIndex({\n*   indexName: 'documents',\n*   dataType: 'float32',\n*   dimension: 1536,\n*   distanceMetric: 'cosine'\n* })\n*\n* // Access vector operations via index\n* const index = bucket.index('documents')\n* await index.putVectors({\n*   vectors: [\n*     { key: 'doc-1', data: { float32: [...] }, metadata: { title: 'Intro' } }\n*   ]\n* })\n*\n* // Query similar vectors\n* const { data } = await index.queryVectors({\n*   queryVector: { float32: [...] },\n*   topK: 5,\n*   returnDistance: true\n* })\n* ```\n*/\nvar StorageVectorsClient = class extends VectorBucketApi {\n\t/**\n\t* @alpha\n\t*\n\t* Creates a StorageVectorsClient that can manage buckets, indexes, and vectors.\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param url - Base URL of the Storage Vectors REST API.\n\t* @param options.headers - Optional headers (for example `Authorization`) applied to every request.\n\t* @param options.fetch - Optional custom `fetch` implementation for non-browser runtimes.\n\t*\n\t* @example\n\t* ```typescript\n\t* const client = new StorageVectorsClient(url, options)\n\t* ```\n\t*/\n\tconstructor(url, options = {}) {\n\t\tsuper(url, options.headers || {}, options.fetch);\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Access operations for a specific vector bucket\n\t* Returns a scoped client for index and vector operations within the bucket\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param vectorBucketName - Name of the vector bucket\n\t* @returns Bucket-scoped client with index and vector operations\n\t*\n\t* @example\n\t* ```typescript\n\t* const bucket = supabase.storage.vectors.from('embeddings-prod')\n\t* ```\n\t*/\n\tfrom(vectorBucketName) {\n\t\treturn new VectorBucketScope(this.url, this.headers, vectorBucketName, this.fetch);\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Creates a new vector bucket\n\t* Vector buckets are containers for vector indexes and their data\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param vectorBucketName - Unique name for the vector bucket\n\t* @returns Promise with empty response on success or error\n\t*\n\t* @example\n\t* ```typescript\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .vectors\n\t*   .createBucket('embeddings-prod')\n\t* ```\n\t*/\n\tasync createBucket(vectorBucketName) {\n\t\tvar _superprop_getCreateBucket = () => super.createBucket, _this = this;\n\t\treturn _superprop_getCreateBucket().call(_this, vectorBucketName);\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Retrieves metadata for a specific vector bucket\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param vectorBucketName - Name of the vector bucket\n\t* @returns Promise with bucket metadata or error\n\t*\n\t* @example\n\t* ```typescript\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .vectors\n\t*   .getBucket('embeddings-prod')\n\t*\n\t* console.log('Bucket created:', data?.vectorBucket.creationTime)\n\t* ```\n\t*/\n\tasync getBucket(vectorBucketName) {\n\t\tvar _superprop_getGetBucket = () => super.getBucket, _this2 = this;\n\t\treturn _superprop_getGetBucket().call(_this2, vectorBucketName);\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Lists all vector buckets with optional filtering and pagination\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param options - Optional filters (prefix, maxResults, nextToken)\n\t* @returns Promise with list of buckets or error\n\t*\n\t* @example\n\t* ```typescript\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .vectors\n\t*   .listBuckets({ prefix: 'embeddings-' })\n\t*\n\t* data?.vectorBuckets.forEach(bucket => {\n\t*   console.log(bucket.vectorBucketName)\n\t* })\n\t* ```\n\t*/\n\tasync listBuckets(options = {}) {\n\t\tvar _superprop_getListBuckets = () => super.listBuckets, _this3 = this;\n\t\treturn _superprop_getListBuckets().call(_this3, options);\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Deletes a vector bucket (bucket must be empty)\n\t* All indexes must be deleted before deleting the bucket\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param vectorBucketName - Name of the vector bucket to delete\n\t* @returns Promise with empty response on success or error\n\t*\n\t* @example\n\t* ```typescript\n\t* const { data, error } = await supabase\n\t*   .storage\n\t*   .vectors\n\t*   .deleteBucket('embeddings-old')\n\t* ```\n\t*/\n\tasync deleteBucket(vectorBucketName) {\n\t\tvar _superprop_getDeleteBucket = () => super.deleteBucket, _this4 = this;\n\t\treturn _superprop_getDeleteBucket().call(_this4, vectorBucketName);\n\t}\n};\n/**\n*\n* @alpha\n*\n* Scoped client for operations within a specific vector bucket\n* Provides index management and access to vector operations\n*\n* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n*/\nvar VectorBucketScope = class extends VectorIndexApi {\n\t/**\n\t* @alpha\n\t*\n\t* Creates a helper that automatically scopes all index operations to the provided bucket.\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @example\n\t* ```typescript\n\t* const bucket = supabase.storage.vectors.from('embeddings-prod')\n\t* ```\n\t*/\n\tconstructor(url, headers, vectorBucketName, fetch$1) {\n\t\tsuper(url, headers, fetch$1);\n\t\tthis.vectorBucketName = vectorBucketName;\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Creates a new vector index in this bucket\n\t* Convenience method that automatically includes the bucket name\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param options - Index configuration (vectorBucketName is automatically set)\n\t* @returns Promise with empty response on success or error\n\t*\n\t* @example\n\t* ```typescript\n\t* const bucket = supabase.storage.vectors.from('embeddings-prod')\n\t* await bucket.createIndex({\n\t*   indexName: 'documents-openai',\n\t*   dataType: 'float32',\n\t*   dimension: 1536,\n\t*   distanceMetric: 'cosine',\n\t*   metadataConfiguration: {\n\t*     nonFilterableMetadataKeys: ['raw_text']\n\t*   }\n\t* })\n\t* ```\n\t*/\n\tasync createIndex(options) {\n\t\tvar _superprop_getCreateIndex = () => super.createIndex, _this5 = this;\n\t\treturn _superprop_getCreateIndex().call(_this5, _objectSpread2(_objectSpread2({}, options), {}, { vectorBucketName: _this5.vectorBucketName }));\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Lists indexes in this bucket\n\t* Convenience method that automatically includes the bucket name\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param options - Listing options (vectorBucketName is automatically set)\n\t* @returns Promise with response containing indexes array and pagination token or error\n\t*\n\t* @example\n\t* ```typescript\n\t* const bucket = supabase.storage.vectors.from('embeddings-prod')\n\t* const { data } = await bucket.listIndexes({ prefix: 'documents-' })\n\t* ```\n\t*/\n\tasync listIndexes(options = {}) {\n\t\tvar _superprop_getListIndexes = () => super.listIndexes, _this6 = this;\n\t\treturn _superprop_getListIndexes().call(_this6, _objectSpread2(_objectSpread2({}, options), {}, { vectorBucketName: _this6.vectorBucketName }));\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Retrieves metadata for a specific index in this bucket\n\t* Convenience method that automatically includes the bucket name\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param indexName - Name of the index to retrieve\n\t* @returns Promise with index metadata or error\n\t*\n\t* @example\n\t* ```typescript\n\t* const bucket = supabase.storage.vectors.from('embeddings-prod')\n\t* const { data } = await bucket.getIndex('documents-openai')\n\t* console.log('Dimension:', data?.index.dimension)\n\t* ```\n\t*/\n\tasync getIndex(indexName) {\n\t\tvar _superprop_getGetIndex = () => super.getIndex, _this7 = this;\n\t\treturn _superprop_getGetIndex().call(_this7, _this7.vectorBucketName, indexName);\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Deletes an index from this bucket\n\t* Convenience method that automatically includes the bucket name\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param indexName - Name of the index to delete\n\t* @returns Promise with empty response on success or error\n\t*\n\t* @example\n\t* ```typescript\n\t* const bucket = supabase.storage.vectors.from('embeddings-prod')\n\t* await bucket.deleteIndex('old-index')\n\t* ```\n\t*/\n\tasync deleteIndex(indexName) {\n\t\tvar _superprop_getDeleteIndex = () => super.deleteIndex, _this8 = this;\n\t\treturn _superprop_getDeleteIndex().call(_this8, _this8.vectorBucketName, indexName);\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Access operations for a specific index within this bucket\n\t* Returns a scoped client for vector data operations\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param indexName - Name of the index\n\t* @returns Index-scoped client with vector data operations\n\t*\n\t* @example\n\t* ```typescript\n\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n\t*\n\t* // Insert vectors\n\t* await index.putVectors({\n\t*   vectors: [\n\t*     { key: 'doc-1', data: { float32: [...] }, metadata: { title: 'Intro' } }\n\t*   ]\n\t* })\n\t*\n\t* // Query similar vectors\n\t* const { data } = await index.queryVectors({\n\t*   queryVector: { float32: [...] },\n\t*   topK: 5\n\t* })\n\t* ```\n\t*/\n\tindex(indexName) {\n\t\treturn new VectorIndexScope(this.url, this.headers, this.vectorBucketName, indexName, this.fetch);\n\t}\n};\n/**\n*\n* @alpha\n*\n* Scoped client for operations within a specific vector index\n* Provides vector data operations (put, get, list, query, delete)\n*\n* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n*/\nvar VectorIndexScope = class extends VectorDataApi {\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Creates a helper that automatically scopes all vector operations to the provided bucket/index names.\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @example\n\t* ```typescript\n\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n\t* ```\n\t*/\n\tconstructor(url, headers, vectorBucketName, indexName, fetch$1) {\n\t\tsuper(url, headers, fetch$1);\n\t\tthis.vectorBucketName = vectorBucketName;\n\t\tthis.indexName = indexName;\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Inserts or updates vectors in this index\n\t* Convenience method that automatically includes bucket and index names\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param options - Vector insertion options (bucket and index names automatically set)\n\t* @returns Promise with empty response on success or error\n\t*\n\t* @example\n\t* ```typescript\n\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n\t* await index.putVectors({\n\t*   vectors: [\n\t*     {\n\t*       key: 'doc-1',\n\t*       data: { float32: [0.1, 0.2, ...] },\n\t*       metadata: { title: 'Introduction', page: 1 }\n\t*     }\n\t*   ]\n\t* })\n\t* ```\n\t*/\n\tasync putVectors(options) {\n\t\tvar _superprop_getPutVectors = () => super.putVectors, _this9 = this;\n\t\treturn _superprop_getPutVectors().call(_this9, _objectSpread2(_objectSpread2({}, options), {}, {\n\t\t\tvectorBucketName: _this9.vectorBucketName,\n\t\t\tindexName: _this9.indexName\n\t\t}));\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Retrieves vectors by keys from this index\n\t* Convenience method that automatically includes bucket and index names\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param options - Vector retrieval options (bucket and index names automatically set)\n\t* @returns Promise with response containing vectors array or error\n\t*\n\t* @example\n\t* ```typescript\n\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n\t* const { data } = await index.getVectors({\n\t*   keys: ['doc-1', 'doc-2'],\n\t*   returnMetadata: true\n\t* })\n\t* ```\n\t*/\n\tasync getVectors(options) {\n\t\tvar _superprop_getGetVectors = () => super.getVectors, _this10 = this;\n\t\treturn _superprop_getGetVectors().call(_this10, _objectSpread2(_objectSpread2({}, options), {}, {\n\t\t\tvectorBucketName: _this10.vectorBucketName,\n\t\t\tindexName: _this10.indexName\n\t\t}));\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Lists vectors in this index with pagination\n\t* Convenience method that automatically includes bucket and index names\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param options - Listing options (bucket and index names automatically set)\n\t* @returns Promise with response containing vectors array and pagination token or error\n\t*\n\t* @example\n\t* ```typescript\n\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n\t* const { data } = await index.listVectors({\n\t*   maxResults: 500,\n\t*   returnMetadata: true\n\t* })\n\t* ```\n\t*/\n\tasync listVectors(options = {}) {\n\t\tvar _superprop_getListVectors = () => super.listVectors, _this11 = this;\n\t\treturn _superprop_getListVectors().call(_this11, _objectSpread2(_objectSpread2({}, options), {}, {\n\t\t\tvectorBucketName: _this11.vectorBucketName,\n\t\t\tindexName: _this11.indexName\n\t\t}));\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Queries for similar vectors in this index\n\t* Convenience method that automatically includes bucket and index names\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param options - Query options (bucket and index names automatically set)\n\t* @returns Promise with response containing matches array of similar vectors ordered by distance or error\n\t*\n\t* @example\n\t* ```typescript\n\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n\t* const { data } = await index.queryVectors({\n\t*   queryVector: { float32: [0.1, 0.2, ...] },\n\t*   topK: 5,\n\t*   filter: { category: 'technical' },\n\t*   returnDistance: true,\n\t*   returnMetadata: true\n\t* })\n\t* ```\n\t*/\n\tasync queryVectors(options) {\n\t\tvar _superprop_getQueryVectors = () => super.queryVectors, _this12 = this;\n\t\treturn _superprop_getQueryVectors().call(_this12, _objectSpread2(_objectSpread2({}, options), {}, {\n\t\t\tvectorBucketName: _this12.vectorBucketName,\n\t\t\tindexName: _this12.indexName\n\t\t}));\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Deletes vectors by keys from this index\n\t* Convenience method that automatically includes bucket and index names\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @param options - Deletion options (bucket and index names automatically set)\n\t* @returns Promise with empty response on success or error\n\t*\n\t* @example\n\t* ```typescript\n\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n\t* await index.deleteVectors({\n\t*   keys: ['doc-1', 'doc-2', 'doc-3']\n\t* })\n\t* ```\n\t*/\n\tasync deleteVectors(options) {\n\t\tvar _superprop_getDeleteVectors = () => super.deleteVectors, _this13 = this;\n\t\treturn _superprop_getDeleteVectors().call(_this13, _objectSpread2(_objectSpread2({}, options), {}, {\n\t\t\tvectorBucketName: _this13.vectorBucketName,\n\t\t\tindexName: _this13.indexName\n\t\t}));\n\t}\n};\n\n//#endregion\n//#region src/StorageClient.ts\nvar StorageClient = class extends StorageBucketApi {\n\t/**\n\t* Creates a client for Storage buckets, files, analytics, and vectors.\n\t*\n\t* @category File Buckets\n\t* @example\n\t* ```ts\n\t* import { StorageClient } from '@supabase/storage-js'\n\t*\n\t* const storage = new StorageClient('https://xyzcompany.supabase.co/storage/v1', {\n\t*   apikey: 'public-anon-key',\n\t* })\n\t* const avatars = storage.from('avatars')\n\t* ```\n\t*/\n\tconstructor(url, headers = {}, fetch$1, opts) {\n\t\tsuper(url, headers, fetch$1, opts);\n\t}\n\t/**\n\t* Perform file operation in a bucket.\n\t*\n\t* @category File Buckets\n\t* @param id The bucket id to operate on.\n\t*\n\t* @example\n\t* ```typescript\n\t* const avatars = supabase.storage.from('avatars')\n\t* ```\n\t*/\n\tfrom(id) {\n\t\treturn new StorageFileApi(this.url, this.headers, id, this.fetch);\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Access vector storage operations.\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Vector Buckets\n\t* @returns A StorageVectorsClient instance configured with the current storage settings.\n\t*/\n\tget vectors() {\n\t\treturn new StorageVectorsClient(this.url + \"/vector\", {\n\t\t\theaders: this.headers,\n\t\t\tfetch: this.fetch\n\t\t});\n\t}\n\t/**\n\t*\n\t* @alpha\n\t*\n\t* Access analytics storage operations using Iceberg tables.\n\t*\n\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n\t*\n\t* @category Analytics Buckets\n\t* @returns A StorageAnalyticsClient instance configured with the current storage settings.\n\t*/\n\tget analytics() {\n\t\treturn new StorageAnalyticsClient(this.url + \"/iceberg\", this.headers, this.fetch);\n\t}\n};\n\n//#endregion\nexports.StorageAnalyticsClient = StorageAnalyticsClient;\nexports.StorageApiError = StorageApiError;\nexports.StorageClient = StorageClient;\nexports.StorageError = StorageError;\nexports.StorageUnknownError = StorageUnknownError;\nexports.StorageVectorsApiError = StorageVectorsApiError;\nexports.StorageVectorsClient = StorageVectorsClient;\nexports.StorageVectorsError = StorageVectorsError;\nexports.StorageVectorsErrorCode = StorageVectorsErrorCode;\nexports.StorageVectorsUnknownError = StorageVectorsUnknownError;\nexports.VectorBucketApi = VectorBucketApi;\nexports.VectorBucketScope = VectorBucketScope;\nexports.VectorDataApi = VectorDataApi;\nexports.VectorIndexApi = VectorIndexApi;\nexports.VectorIndexScope = VectorIndexScope;\nexports.isStorageError = isStorageError;\nexports.isStorageVectorsError = isStorageVectorsError;\n//# sourceMappingURL=index.cjs.map\n};","~:removed-requires",["~#set",[]],"~:actual-requires",["^5",["~$shadow.js","~$module$node_modules$iceberg_js$dist$index_cjs","~$module$node_modules$buffer$index"]],"~:properties",["^5",["sortBy","message","destinationKey","VectorBucketScope","fetch","promise","hostname","noResolveJson","StorageVectorsErrorCode","url","VectorIndexScope","token","indexName","__isStorageError","body","prefixes","StorageVectorsUnknownError","offset","originalError","vectorBucketName","isStorageVectorsError","prefix","put","StorageVectorsError","VectorDataApi","duplex","method","catalogName","file_size_limit","auth","path","StorageAnalyticsClient","destinationBucket","error","id","upsert","transform","post","fullPath","paths","name","configurable","limit","value","StorageVectorsClient","enumerable","baseUrl","statusCode","VectorBucketApi","status","sourceKey","remove","writable","StorageError","shouldThrowOnError","sortColumn","StorageApiError","StorageClient","head","isStorageError","order","column","StorageUnknownError","StorageVectorsApiError","publicUrl","type","downloadFn","cacheControl","public","contentType","allowed_mime_types","sortOrder","signedUrl","namespace","expiresIn","search","data","get","bucketId","VectorIndexApi","getHeaders","headers"]],"~:compiled-at",1771991938841,"~:source-map-json","{\n\"version\":3,\n\"file\":\"module$node_modules$$supabase$storage_js$dist$index_cjs.js\",\n\"lineCount\":41,\n\"mappings\":\"AAAAA,cAAA,CAAe,EAAf,CAAA,CAAqB,QAAQ,CAACC,CAAD,CAASC,EAAT,CAAgBC,CAAhB,CAAyB,CAwBtDC,QAASA,EAAc,CAACC,CAAD,CAAQ,CAC9B,MAAO,OAAOA,EAAd,GAAwB,QAAxB,EAAoCA,CAApC,GAA8C,IAA9C,EAAsD,kBAAtD,EAA4EA,EAD9C,CA6J/BC,QAASA,EAAO,CAACC,CAAD,CAAI,CACnB,yBACA,OAAOD,EAAA,CAAU,UAAA,EAAc,MAAOE,OAArB,EAA+B,QAA/B,EAA2C,MAAOA,OAAOC,CAAAA,QAAzD,CAAoE,QAAQ,CAACC,CAAD,CAAM,CAClG,MAAO,OAAOA,EADoF,CAAlF,CAEb,QAAQ,CAACA,CAAD,CAAM,CACjB,MAAOA,EAAA,EAAO,UAAP,EAAqB,MAAOF,OAA5B,EAAsCE,CAAIC,CAAAA,WAA1C,GAA0DH,MAA1D,EAAoEE,CAApE,GAA4EF,MAAOI,CAAAA,SAAnF,CAA+F,QAA/F,CAA0G,MAAOF,EADvG,CAFX,CAIJJ,CAAA,CAAQC,CAAR,CANgB,CA0CpBM,QAASA,EAAO,CAACC,CAAD,CAAIC,CAAJ,CAAO,CACtB,IAAIC,EAAIC,MAAOC,CAAAA,IAAP,CAAYJ,CAAZ,CACR,IAAIG,MAAOE,CAAAA,qBAAX,CAAkC,CACjC,IAAIZ,EAAIU,MAAOE,CAAAA,qBAAP,CAA6BL,CAA7B,CACRC,EAAA,GAAMR,CAAN,CAAUA,CAAEa,CAAAA,MAAF,CAAS,QAAQ,CAACC,EAAD,CAAM,CAChC,MAAOJ,OAAOK,CAAAA,wBAAP,CAAgCR,CAAhC;AAAmCO,EAAnC,CAAwCE,CAAAA,UADf,CAAvB,CAAV,CAEKP,EAAEQ,CAAAA,IAAKC,CAAAA,KAAP,CAAaT,CAAb,CAAgBT,CAAhB,CAJ4B,CAMlC,MAAOS,EARe,CAUvBU,QAASA,EAAc,CAACZ,CAAD,CAAI,CAC1B,IAAK,IAAIC,EAAI,CAAb,CAAgBA,CAAhB,CAAoBY,SAAUC,CAAAA,MAA9B,CAAsCb,CAAA,EAAtC,CAA2C,CAC1C,IAAIC,EAAI,IAAA,EAAQW,SAAA,CAAUZ,CAAV,CAAR,CAAuBY,SAAA,CAAUZ,CAAV,CAAvB,CAAsC,EAC9CA,EAAA,CAAI,CAAJ,CAAQF,CAAA,CAAQI,MAAA,CAAOD,CAAP,CAAR,CAAmB,CAAA,CAAnB,CAAuBa,CAAAA,OAAvB,CAA+B,QAAQ,CAACR,CAAD,CAAM,CACjCA,IAAAA,EAAAA,CAAK,GAAAL,CAAA,CAAEK,CAAF,CA7CA,EAAA,CAC1B,GAAI,QAAJ,EAAgBf,CAAA,CAAQU,CAAR,CAAhB,EAA+BA,CAA/B,CAAA,CACA,IAAIF,GAAIE,CAAA,CAAER,MAAOsB,CAAAA,WAAT,CACR,IAAI,IAAK,EAAT,GAAehB,EAAf,CAAkB,CACbiB,CAAAA,CAAIjB,EAAEkB,CAAAA,IAAF,CAAOhB,CAAP,CAUcD,QAVd,CACR,IAAI,QAAJ,EAAgBT,CAAA,CAAQyB,CAAR,CAAhB,CAA4B,MAAA,CAC5B,MAAM,KAAIE,SAAJ,CAAc,8CAAd,CAAN,CAHiB,CAKlB,CAAA,CAAyBC,MAAlB,CAAmClB,CAAnC,CAPP,CAoBO,CAACD,EAAD,CANA,QAAA,EAAYT,CAAA,CAAQyB,CAAR,CAAZ,CAAyBA,CAAzB,CAA6BA,CAA7B,CAAiC,EAMjC,GAwBWjB,EAxBX,CAA8BG,MAAOkB,CAAAA,cAAP,CAwBnBrB,CAxBmB,CAAyBC,EAAzB,CAA4B,CAChEqB,MAAOpB,EADyD,CAEhEO,WAAY,CAAA,CAFoD,CAGhEc,aAAc,CAAA,CAHkD,CAIhEC,SAAU,CAAA,CAJsD,CAA5B,CAA9B;AAwBWxB,CAnBb,CAAEC,EAAF,CALE,CAKKC,EAkB0C,CAA7C,CAAR,CAEKC,MAAOsB,CAAAA,yBAAP,CAAmCtB,MAAOuB,CAAAA,gBAAP,CAAwB1B,CAAxB,CAA2BG,MAAOsB,CAAAA,yBAAP,CAAiCvB,CAAjC,CAA3B,CAAnC,CAAqGH,CAAA,CAAQI,MAAA,CAAOD,CAAP,CAAR,CAAmBa,CAAAA,OAAnB,CAA2B,QAAQ,CAACR,CAAD,CAAM,CAClJJ,MAAOkB,CAAAA,cAAP,CAAsBrB,CAAtB,CAAyBO,CAAzB,CAA8BJ,MAAOK,CAAAA,wBAAP,CAAgCN,CAAhC,CAAmCK,CAAnC,CAA9B,CADkJ,CAAzC,CAJhE,CAQ3C,MAAOP,EATmB,CAoF3B2B,cAAeA,EAAc,CAACC,CAAD,CAAUC,CAAV,CAAkBC,CAAlB,CAAuBC,CAAvB,CAAgCC,EAAhC,CAA4CC,EAA5C,CAAkDC,EAAlD,CAA6D,CACzF,MAAO,KAAIC,OAAJ,CAAY,CAACC,EAAD,CAAUC,EAAV,CAAA,EAAqB,CACvCT,CAAA,CAAQE,CAAR,CAAaQ,CAAA,CAAkBT,CAAlB,CAA0BE,CAA1B,CAAmCC,EAAnC,CAA+CC,EAA/C,CAAb,CAAmEM,CAAAA,IAAnE,CAAyEC,EAAD,EAAY,CACnF,GAAI,CAACA,EAAOC,CAAAA,EAAZ,CAAgB,KAAMD,GAAN,CAChB,GAAIT,CAAA,GAAY,IAAZ,EAAoBA,CAApB,GAAgC,IAAK,EAArC,CAAyC,CAAzC,CAAkDA,CAAQW,CAAAA,aAA9D,CAA6E,MAAOF,GACpF,IAAIN,EAAJ,GAAkB,SAAlB,CAA6B,CAC5B,MAAMS,GAAcH,EAAOI,CAAAA,OAAQC,CAAAA,GAAf,CAAmB,cAAnB,CAEpB,IADIL,EAAOI,CAAAA,OAAQC,CAAAA,GAAf,CAAmB,gBAAnB,CACJ,GAD6C,GAC7C,EADoDL,EAAOM,CAAAA,MAC3D,GADsE,GACtE,EAAI,CAACH,EAAL;AAAoB,CAACA,EAAYI,CAAAA,QAAZ,CAAqB,kBAArB,CAArB,CAA+D,MAAO,EAH1C,CAK7B,MAAOP,GAAOQ,CAAAA,IAAP,EAR4E,CAApF,CASGT,CAAAA,IATH,CASSU,EAAD,EAAUb,EAAA,CAAQa,EAAR,CATlB,CASiCC,CAAAA,KATjC,CASwC3D,EAAD,EAAW4D,CAAA,CAAY5D,EAAZ,CAAmB8C,EAAnB,CAA2BN,CAA3B,CAAoCG,EAApC,CATlD,CADuC,CAAjC,CADkF,CAmB1FkB,QAASA,EAAc,CAAClB,CAAA,CAAY,SAAb,CAAwB,CAC9C,MAAO,CACNW,IAAKA,KAAM,CAACjB,CAAD,CAAUE,CAAV,CAAeC,CAAf,CAAwBC,EAAxB,CAANa,EACGlB,CAAA,CAAeC,CAAf,CAAwB,KAAxB,CAA+BE,CAA/B,CAAoCC,CAApC,CAA6CC,EAA7C,CAAyD,IAAK,EAA9D,CAAiEE,CAAjE,CAFF,CAINmB,KAAMA,KAAM,CAACzB,CAAD,CAAUE,CAAV,CAAeG,CAAf,CAAqBF,EAArB,CAA8BC,EAA9B,CAANqB,EACE1B,CAAA,CAAeC,CAAf,CAAwB,MAAxB,CAAgCE,CAAhC,CAAqCC,EAArC,CAA8CC,EAA9C,CAA0DC,CAA1D,CAAgEC,CAAhE,CALF,CAONoB,IAAKA,KAAM,CAAC1B,CAAD,CAAUE,CAAV,CAAeG,CAAf,CAAqBF,EAArB,CAA8BC,EAA9B,CAANsB,EACG3B,CAAA,CAAeC,CAAf,CAAwB,KAAxB,CAA+BE,CAA/B,CAAoCC,EAApC,CAA6CC,EAA7C,CAAyDC,CAAzD,CAA+DC,CAA/D,CARF,CAUNqB,KAAMA,KAAM,CAAC3B,CAAD,CAAUE,CAAV,CAAeC,CAAf,CAAwBC,EAAxB,CAANuB,EACE5B,CAAA,CAAeC,CAAf,CAAwB,MAAxB,CAAgCE,CAAhC,CAAqClB,CAAA,CAAeA,CAAA,CAAe,EAAf,CAAmBmB,CAAnB,CAAf,CAA4C,EAA5C,CAAgD,CAAEW,cAAe,CAAA,CAAjB,CAAhD,CAArC,CAA+GV,EAA/G,CAA2H,IAAK,EAAhI,CAAmIE,CAAnI,CAXF,CAaNsB,OAAQA,KAAM,CAAC5B,CAAD,CAAUE,CAAV,CAAeG,CAAf,CAAqBF,EAArB,CAA8BC,EAA9B,CAANwB,EACA7B,CAAA,CAAeC,CAAf,CAAwB,QAAxB,CAAkCE,CAAlC,CAAuCC,EAAvC,CAAgDC,EAAhD,CAA4DC,CAA5D,CAAkEC,CAAlE,CAdF,CADuC,CA/U/C,IAAIuB,EAAStE,CAAA,CAAQ,EAAR,CAAkBsE,CAAAA,MAC/B,KAAIC,EAAavE,CAAA,CAAQ,EAAR,CAOjB,KAAIwE,EAAe,aAAcC,MAAd,CAClB/D,WAAW,CAACgE,CAAD,CAAU3B,CAAA,CAAY,SAAtB,CAAiCY,CAAjC,CAAyCgB,CAAzC,CAAqD,CAC/D,KAAA,CAAMD,CAAN,CACA;IAAKE,CAAAA,gBAAL,CAAwB,CAAA,CACxB,KAAK7B,CAAAA,SAAL,CAAiBA,CACjB,KAAK8B,CAAAA,IAAL,CAAY9B,CAAA,GAAc,SAAd,CAA0B,qBAA1B,CAAkD,cAC9D,KAAKY,CAAAA,MAAL,CAAcA,CACd,KAAKgB,CAAAA,UAAL,CAAkBA,CAN6C,CAD9C,CAAnB,CAsBIG,EAAkB,aAAcN,EAAd,CACrB9D,WAAW,CAACgE,CAAD,CAAUf,CAAV,CAAkBgB,CAAlB,CAA8B5B,CAAA,CAAY,SAA1C,CAAqD,CAC/D,KAAA,CAAM2B,CAAN,CAAe3B,CAAf,CAA0BY,CAA1B,CAAkCgB,CAAlC,CACA,KAAKE,CAAAA,IAAL,CAAY9B,CAAA,GAAc,SAAd,CAA0B,wBAA1B,CAAqD,iBACjE,KAAKY,CAAAA,MAAL,CAAcA,CACd,KAAKgB,CAAAA,UAAL,CAAkBA,CAJ6C,CAMhEI,MAAM,EAAG,CACR,MAAO,CACNF,KAAM,IAAKA,CAAAA,IADL,CAENH,QAAS,IAAKA,CAAAA,OAFR,CAGNf,OAAQ,IAAKA,CAAAA,MAHP,CAINgB,WAAY,IAAKA,CAAAA,UAJX,CADC,CAPY,CAtBtB,CA0CIK,EAAsB,aAAcR,EAAd,CACzB9D,WAAW,CAACgE,CAAD,CAAUO,CAAV,CAAyBlC,CAAA,CAAY,SAArC,CAAgD,CAC1D,KAAA,CAAM2B,CAAN,CAAe3B,CAAf,CACA,KAAK8B,CAAAA,IAAL,CAAY9B,CAAA,GAAc,SAAd,CAA0B,4BAA1B;AAAyD,qBACrE,KAAKkC,CAAAA,aAAL,CAAqBA,CAHqC,CADlC,CAWtBC,EAAAA,CAAsB,aAAcV,EAAd,CACzB9D,WAAW,CAACgE,CAAD,CAAU,CACpB,KAAA,CAAMA,CAAN,CAAe,SAAf,CADoB,CADI,CAiBtBS,GAAAA,CAAyB,aAAcL,EAAd,CAC5BpE,WAAW,CAACgE,CAAD,CAAUf,CAAV,CAAkBgB,CAAlB,CAA8B,CACxC,KAAA,CAAMD,CAAN,CAAef,CAAf,CAAuBgB,CAAvB,CAAmC,SAAnC,CADwC,CADb,CAS7B,KAAIS,EAA6B,aAAcJ,EAAd,CAChCtE,WAAW,CAACgE,CAAD,CAAUO,CAAV,CAAyB,CACnC,KAAA,CAAMP,CAAN,CAAeO,CAAf,CAA8B,SAA9B,CADmC,CADJ,CASjC,KAAII,EAA0C,QAAQ,CAACC,CAAD,CAA4B,CAEjFA,CAAA,CAAA,aAAA,CAA6C,eAE7CA,EAAA,CAAA,yBAAA,CAAyD,2BAEzDA,EAAA,CAAA,yBAAA,CAAyD,2BAEzDA,EAAA,CAAA,sBAAA,CAAsD,wBAEtDA,EAAA,CAAA,0BAAA,CAA0D,4BAE1DA,EAAA,CAAA,0BAAA;AAA0D,4BAC1D,OAAOA,EAb0E,CAApC,CAc5C,EAd4C,CAyB9C,OAAMC,EAAgBC,CAADD,EAChBC,CAAJ,CAAwB,CAAC,GAAGC,CAAJ,CAAA,EAAaD,CAAA,CAAY,GAAGC,CAAf,CAArC,CACO,CAAC,GAAGA,CAAJ,CAAA,EAAaC,KAAA,CAAM,GAAGD,CAAT,CAFrB,CAwBME,EAAoBC,CAADD,EAAU,CAClC,GAAIE,KAAMC,CAAAA,OAAN,CAAcF,CAAd,CAAJ,CAAyB,MAAOA,EAAKG,CAAAA,GAAL,CAAUC,CAAD,EAAQL,CAAA,CAAiBK,CAAjB,CAAjB,CAC3B,IAAI,MAAOJ,EAAX,GAAoB,UAApB,EAAkCA,CAAlC,GAA2C5E,MAAA,CAAO4E,CAAP,CAA3C,CAAyD,MAAOA,EACrE,OAAMvC,EAAS,EACfrC,OAAOiF,CAAAA,OAAP,CAAeL,CAAf,CAAqBhE,CAAAA,OAArB,CAA6B,CAAC,CAACsE,CAAD,CAAM/D,CAAN,CAAD,CAAA,EAAkB,CACxCgE,CAAAA,CAASD,CAAIE,CAAAA,OAAJ,CAAY,eAAZ,CAA8BC,EAAD,EAAOA,EAAEC,CAAAA,WAAF,EAAgBF,CAAAA,OAAhB,CAAwB,OAAxB,CAAiC,EAAjC,CAApC,CACf/C,EAAA,CAAO8C,CAAP,CAAA,CAAiBR,CAAA,CAAiBxD,CAAjB,CAF6B,CAA/C,CAIA,OAAOkB,EAR2B,CAxBnC,CAiDMkD,EAAqBC,CAADD,EACrB,CAACC,CAGL,EAHmB,MAAOA,EAG1B,GAHyC,QAGzC,EAFIA,CAAW7E,CAAAA,MAEf,GAF0B,CAE1B,EAF+B6E,CAAW7E,CAAAA,MAE1C,CAFmD,GAEnD,EADI6E,CAAWC,CAAAA,IAAX,EACJ,GAD0BD,CAC1B,EAAIA,CAAW5C,CAAAA,QAAX,CAAoB,GAApB,CAAJ,EAAgC4C,CAAW5C,CAAAA,QAAX,CAAoB,IAApB,CAAhC,CAAkE,CAAA,CAAlE,CACO,2BAA4B8C,CAAAA,IAA5B,CAAiCF,CAAjC,CAtDR,CAkIMG,EAAoBC,CAADD,EAAS,CACjC,IAAIE,CACJ,OAAOD,EAAIE,CAAAA,GAAX,EAAkBF,CAAIlC,CAAAA,OAAtB;AAAiCkC,CAAIG,CAAAA,iBAArC,GAA2D,MAAOH,EAAIxG,CAAAA,KAAX,GAAqB,QAArB,CAAgCwG,CAAIxG,CAAAA,KAApC,CAA4C,CAACyG,CAAD,CAAcD,CAAIxG,CAAAA,KAAlB,IAA6B,IAA7B,EAAqCyG,CAArC,GAAoD,IAAK,EAAzD,CAA6D,IAAK,EAAlE,CAAsEA,CAAWnC,CAAAA,OAAxL,GAAoMsC,IAAKC,CAAAA,SAAL,CAAeL,CAAf,CAFnK,CAlIlC,CA6IM5C,EAAcA,KAAM,CAAC5D,CAAD,CAAQ8C,CAAR,CAAgBN,CAAhB,CAAyBG,CAAzB,CAANiB,EAA6C,CAChE,GAAI5D,CAAJ,EAAa,MAAOA,EAApB,GAA8B,QAA9B,EAA0C,QAA1C,EAAsDA,EAAtD,EAA+D,IAA/D,EAAuEA,EAAvE,EAAgF,MAAOA,EAAMuD,CAAAA,MAA7F,GAAwG,QAAxG,GAAsHf,CAAtH,GAAkI,IAAlI,EAA0IA,CAA1I,GAAsJ,IAAK,EAA3J,EAAgLW,CAARX,CAAQW,CAAAA,aAAhL,EAAgM,CAE/L,MAAMI,GADgBvD,CACOuD,CAAAA,MAAvBA,EAAiC,GACnC,OAFkBvD,EAEGyD,CAAAA,IAAzB,GAAkC,UAAlC,CAFsBzD,CAEsCyD,CAAAA,IAAd,EAAqBT,CAAAA,IAArB,CAA2BwD,EAAD,EAAS,CAChF,MAAMjC,IAAciC,EAAA,GAAQ,IAAR,EAAgBA,EAAhB,GAAwB,IAAK,EAA7B,CAAiC,IAAK,EAAtC,CAA0CA,EAAIjC,CAAAA,UAA5DA,IAA4EiC,EAAA,GAAQ,IAAR,EAAgBA,EAAhB,GAAwB,IAAK,EAA7B,CAAiC,IAAK,EAAtC,CAA0CA,EAAIM,CAAAA,IAA1HvC,GAAmIhB,EAAnIgB,CAA4I,EAClJzB,EAAA,CAAO,IAAI4B,CAAJ,CAAoB6B,CAAA,CAAiBC,EAAjB,CAApB,CAA2CjD,EAA3C,CAAmDgB,EAAnD,CAA+D5B,CAA/D,CAAP,CAFgF,CAAnC,CAG3CgB,CAAAA,KAH2C,CAGrC,EAAA,EAAM,CAGbb,CAAA,CAAO,IAAI4B,CAAJ,CARa1E,CAQqB+G,CAAAA,UAAlC,EAAiD,QAAOxD,EAAP,QAAjD;AAAwEA,EAAxE,CADYA,EACZ,CADqB,EACrB,CAA4FZ,CAA5F,CAAP,CAHa,CAH+B,CAA9C,CAcCG,CAAA,CAAO,IAAI4B,CAAJ,CAhBc1E,CAgBoB+G,CAAAA,UAAlC,EAAiD,QAAOxD,EAAP,QAAjD,CAAwEA,EAAxE,CADYA,EACZ,CADqB,EACrB,CAA4FZ,CAA5F,CAAP,CAjB8L,CAAhM,IAmBOG,EAAA,CAAO,IAAI8B,CAAJ,CAAwB2B,CAAA,CAAiBvG,CAAjB,CAAxB,CAAiDA,CAAjD,CAAwD2C,CAAxD,CAAP,CApByD,CA7IjE,CA2KMI,EAAoB,CAACT,CAAD,CAASE,CAAT,CAAkBC,CAAlB,CAA8BC,CAA9B,CAAAK,EAAuC,CAChE,MAAMiE,GAAS,CACd1E,OAAAA,CADc,CAEde,SAAUb,CAAA,GAAY,IAAZ,EAAoBA,CAApB,GAAgC,IAAK,EAArC,CAAyC,IAAK,EAA9C,CAAkDA,CAAQa,CAAAA,OAApEA,GAAgF,EAFlE,CAIf,IAAIf,CAAJ,GAAe,KAAf,EAAwBA,CAAxB,GAAmC,MAAnC,EAA6C,CAACI,CAA9C,CAAoD,MAAOrB,EAAA,CAAeA,CAAA,CAAe,EAAf,CAAmB2F,EAAnB,CAAf,CAA2CvE,CAA3C,CAnKvD,OAoKcC,EApKlB,GAAqB,QAArB,EAoKkBA,CApKlB,GAA2C,IAA3C,CAAiD,CAAjD,CAAwD,CAAA,CAAxD,EACMnC,CACN,CADkBK,MAAOqG,CAAAA,cAAP,CAmKAvE,CAnKA,CAClB,CAAA,CAAA,EAAQnC,CAAR,GAAsB,IAAtB,EAA8BA,CAA9B,GAA4CK,MAAOL,CAAAA,SAAnD,EAAgEK,MAAOqG,CAAAA,cAAP,CAAsB1G,CAAtB,CAAhE,GAAqG,IAArG,GAA8G,EAAEJ,MAAO+G,CAAAA,WAAT,GAkK5FxE,EAlK4F,CAA9G,EAAgJ,EAAEvC,MAAOC,CAAAA,QAAT,GAkK9HsC,EAlK8H,CAFhJ,CAoKI,EAAJ,EACCsE,EAAO3D,CAAAA,OACP,CADiBhC,CAAA,CAAe,CAAE,eAAgB,kBAAlB,CAAf,CAAuDmB,CAAA,GAAY,IAAZ,EAAoBA,CAApB,GAAgC,IAAK,EAArC,CAAyC,IAAK,EAA9C,CAAkDA,CAAQa,CAAAA,OAAjH,CACjB;AAAA2D,EAAOtE,CAAAA,IAAP,CAAckE,IAAKC,CAAAA,SAAL,CAAenE,CAAf,CAFf,EAGOsE,EAAOtE,CAAAA,IAHd,CAGqBA,CACrB,IAAIF,CAAA,GAAY,IAAZ,EAAoBA,CAApB,GAAgC,IAAK,EAArC,CAAyC,CAAzC,CAAkDA,CAAQ2E,CAAAA,MAA9D,CAAsEH,EAAOG,CAAAA,MAAP,CAAgB3E,CAAQ2E,CAAAA,MAC9F,OAAO9F,EAAA,CAAeA,CAAA,CAAe,EAAf,CAAmB2F,EAAnB,CAAf,CAA2CvE,CAA3C,CAXyD,CA8DjE,KAAM2E,EAAavD,CAAA,CAAe,SAAf,CACnB,OAAM,CAAE,IAAAP,CAAF,CAAO,KAAAQ,CAAP,CAAa,IAAAC,CAAb,CAAkB,KAAAC,CAAlB,CAAwB,OAAAC,EAAxB,CAAA,CAAmCmD,CAAzC,CACMC,GAAaxD,CAAA,CAAe,SAAf,CAWnB,KAAIyD,GAAgB,KAAA,CAQnBhH,WAAW,CAACiC,CAAD,CAAMc,CAAA,CAAU,EAAhB,CAAoBkE,CAApB,CAA6B5E,CAAA,CAAY,SAAzC,CAAoD,CAC9D,IAAK6E,CAAAA,kBAAL,CAA0B,CAAA,CAC1B,KAAKjF,CAAAA,GAAL,CAAWA,CACX,KAAKc,CAAAA,OAAL,CAAeA,CACf,KAAKiC,CAAAA,KAAL,CAAaH,CAAA,CAAaoC,CAAb,CACb,KAAK5E,CAAAA,SAAL,CAAiBA,CAL6C,CAa/D8E,YAAY,EAAG,CACd,IAAKD,CAAAA,kBAAL,CAA0B,CAAA,CAC1B,OAAO,KAFO,CAYfE,SAAS,CAACjD,CAAD,CAAO1C,CAAP,CAAc,CACtB,IAAKsB,CAAAA,OAAL,CAAehC,CAAA,CAAeA,CAAA,CAAe,EAAf,CAAmB,IAAKgC,CAAAA,OAAxB,CAAf,CAAiD,EAAjD,CAAqD,CAAE,CAACoB,CAAD,EAAQ1C,CAAV,CAArD,CACf,OAAO,KAFe,CA6BjB4F,qBAAe,CAACC,CAAD,CAAY,CAEhC,GAAI,CACH,MAAO,CACNlE,KAAM,MAAMkE,CAAA,EADN;AAEN5H,MAAO,IAFD,CADJ,CAKF,MAAOA,CAAP,CAAc,CACf,GAPW6H,IAODL,CAAAA,kBAAV,CAA8B,KAAMxH,EAAN,CAC9B,GAAID,CAAA,CAAeC,CAAf,CAAJ,CAA2B,MAAO,CACjC0D,KAAM,IAD2B,CAEjC1D,MAAAA,CAFiC,CAIlC,MAAMA,EAAN,CANe,CAPgB,CA9Dd,CAApB,CAkFI8H,GAAwB,KAAA,CAC3BxH,WAAW,CAACyH,CAAD,CAAaP,CAAb,CAAiC,CAC3C,IAAKO,CAAAA,UAAL,CAAkBA,CAClB,KAAKP,CAAAA,kBAAL,CAA0BA,CAFiB,CAI5CxE,IAAI,CAACgF,CAAD,CAAcC,CAAd,CAA0B,CAC7B,MAAO,KAAKC,CAAAA,OAAL,EAAelF,CAAAA,IAAf,CAAoBgF,CAApB,CAAiCC,CAAjC,CADsB,CAGxBC,aAAO,EAAG,CAEf,GAAI,CACH,MAAO,CACNxE,KAAiChB,CAA1B,MAHGmF,IAGSE,CAAAA,UAAN,EAAoBrF,EAAAA,IAD3B,CAEN1C,MAAO,IAFD,CADJ,CAKF,MAAOA,CAAP,CAAc,CACf,GAPW6H,IAODL,CAAAA,kBAAV,CAA8B,KAAMxH,EAAN,CAC9B,GAAID,CAAA,CAAeC,CAAf,CAAJ,CAA2B,MAAO,CACjC0D,KAAM,IAD2B,CAEjC1D,MAAAA,CAFiC,CAIlC,MAAMA,EAAN,CANe,CAPD,CARW,CA4B5B,KAAImI,EACJA,GAAA,CAAsBhI,MAAO+G,CAAAA,WAC7B,KAAIkB,GAAsB,KAAA,CACzB9H,WAAW,CAACyH,CAAD,CAAaP,CAAb,CAAiC,CAC3C,IAAKO,CAAAA,UAAL,CAAkBA,CAClB,KAAKP,CAAAA,kBAAL,CAA0BA,CAC1B,KAAA,CAAKW,EAAL,CAAA,CAA4B,qBAC5B;IAAKE,CAAAA,OAAL,CAAe,IAJ4B,CAM5CC,QAAQ,EAAG,CACV,MAAO,KAAIR,EAAJ,CAA0B,IAAKC,CAAAA,UAA/B,CAA2C,IAAKP,CAAAA,kBAAhD,CADG,CAGXxE,IAAI,CAACgF,CAAD,CAAcC,CAAd,CAA0B,CAC7B,MAAO,KAAKM,CAAAA,UAAL,EAAkBvF,CAAAA,IAAlB,CAAuBgF,CAAvB,CAAoCC,CAApC,CADsB,CAG9BtE,KAAK,CAACsE,CAAD,CAAa,CACjB,MAAO,KAAKM,CAAAA,UAAL,EAAkB5E,CAAAA,KAAlB,CAAwBsE,CAAxB,CADU,CAGlBO,OAAO,CAACC,CAAD,CAAY,CAClB,MAAO,KAAKF,CAAAA,UAAL,EAAkBC,CAAAA,OAAlB,CAA0BC,CAA1B,CADW,CAGnBF,UAAU,EAAG,CACP,IAAKF,CAAAA,OAAV,GAAmB,IAAKA,CAAAA,OAAxB,CAAkC,IAAKH,CAAAA,OAAL,EAAlC,CACA,OAAO,KAAKG,CAAAA,OAFA,CAIPH,aAAO,EAAG,CAEf,GAAI,CACH,MAAO,CACNxE,KAAM,MAAiCgF,CAA1B,MAHHb,IAGeE,CAAAA,UAAN,EAAoBW,EAAAA,IAA3B,EADN,CAEN1I,MAAO,IAFD,CADJ,CAKF,MAAOA,CAAP,CAAc,CACf,GAPW6H,IAODL,CAAAA,kBAAV,CAA8B,KAAMxH,EAAN,CAC9B,GAAID,CAAA,CAAeC,CAAf,CAAJ,CAA2B,MAAO,CACjC0D,KAAM,IAD2B,CAEjC1D,MAAAA,CAFiC,CAIlC,MAAMA,EAAN,CANe,CAPD,CAvBS,CA2C1B,OAAM2I,EAAyB,CAC9BC,MAAO,GADuB,CAE9BC,OAAQ,CAFsB,CAG9BC,OAAQ,CACPC,OAAQ,MADD;AAEPC,MAAO,KAFA,CAHsB,CAA/B,CAQMC,EAAuB,CAC5BC,aAAc,MADc,CAE5B9F,YAAa,6BAFe,CAG5B+F,OAAQ,CAAA,CAHoB,CAK7B,KAAIC,EAAiB,aAAc9B,GAAd,CACpBhH,WAAW,CAACiC,CAAD,CAAMc,CAAA,CAAU,EAAhB,CAAoBgG,CAApB,CAA8B9B,CAA9B,CAAuC,CACjD,KAAA,CAAMhF,CAAN,CAAWc,CAAX,CAAoBkE,CAApB,CAA6B,SAA7B,CACA,KAAK8B,CAAAA,QAAL,CAAgBA,CAFiC,CAW5CC,oBAAc,CAAChH,CAAD,CAASiH,CAAT,CAAeC,CAAf,CAAyBC,CAAzB,CAAsC,CACzD,IAAI5B,GAAQ,IACZ,OAAOA,GAAMF,CAAAA,eAAN,CAAsB,KAAM,EAAN,EAAY,CAExC,MAAMnF,GAAUnB,CAAA,CAAeA,CAAA,CAAe,EAAf,CAAmB4H,CAAnB,CAAf,CAAyDQ,CAAzD,CAChB,KAAIpG,GAAUhC,CAAA,CAAeA,CAAA,CAAe,EAAf,CAAmBwG,EAAMxE,CAAAA,OAAzB,CAAf,CAAkDf,CAAlD,GAA6D,MAA7D,EAAuE,CAAE,WAAYT,MAAA,CAAOW,EAAQ2G,CAAAA,MAAf,CAAd,CAAvE,CACd,KAAMO,GAAWlH,EAAQkH,CAAAA,QACzB,IAAI,MAAOC,KAAX,GAAoB,WAApB,EAAmCH,CAAnC,WAAuDG,KAAvD,CAA6D,CAC5D,IAAAjH,GAAO,IAAIkH,QACXlH,GAAKmH,CAAAA,MAAL,CAAY,cAAZ,CAA4BrH,EAAQ0G,CAAAA,YAApC,CACIQ,GAAJ,EAAchH,EAAKmH,CAAAA,MAAL,CAAY,UAAZ;AAAwBhC,EAAMiC,CAAAA,cAAN,CAAqBJ,EAArB,CAAxB,CACdhH,GAAKmH,CAAAA,MAAL,CAAY,EAAZ,CAAgBL,CAAhB,CAJ4D,CAA7D,IAKW,OAAOI,SAAX,GAAwB,WAAxB,EAAuCJ,CAAvC,WAA2DI,SAA3D,EACNlH,EAEA,CAFO8G,CAEP,CADK9G,EAAKqH,CAAAA,GAAL,CAAS,cAAT,CACL,EAD+BrH,EAAKmH,CAAAA,MAAL,CAAY,cAAZ,CAA4BrH,EAAQ0G,CAAAA,YAApC,CAC/B,CAAIQ,EAAJ,EAAgB,CAAChH,EAAKqH,CAAAA,GAAL,CAAS,UAAT,CAAjB,EAAuCrH,EAAKmH,CAAAA,MAAL,CAAY,UAAZ,CAAwBhC,EAAMiC,CAAAA,cAAN,CAAqBJ,EAArB,CAAxB,CAHjC,GAKNhH,EAIA,CAJO8G,CAIP,CAHAnG,EAAA,CAAQ,eAAR,CAGA,CAH4B,WAAUb,EAAQ0G,CAAAA,YAAlB,EAG5B,CAFA7F,EAAA,CAAQ,cAAR,CAEA,CAF0Bb,EAAQY,CAAAA,WAElC,CADIsG,EACJ,GADcrG,EAAA,CAAQ,YAAR,CACd,CADsCwE,EAAMmC,CAAAA,QAAN,CAAenC,EAAMiC,CAAAA,cAAN,CAAqBJ,EAArB,CAAf,CACtC,GAAK,MAAOO,eAAZ,GAA+B,WAA/B,EAA8CvH,EAA9C,WAA8DuH,eAA9D,EAAgFvH,EAAhF,EAAwF,MAAOA,GAA/F,GAAwG,QAAxG,EAAoH,MAApH,EAA8HA,GAA9H,EAAsI,MAAOA,GAAKwH,CAAAA,IAAlJ;AAA2J,UAA3J,GAA0K,CAAC1H,EAAQ2E,CAAAA,MAAnL,GAA2L3E,EAAQ2E,CAAAA,MAAnM,CAA4M,MAA5M,CATM,CAWP,IAAIsC,CAAA,GAAgB,IAAhB,EAAwBA,CAAxB,GAAwC,IAAK,EAA7C,CAAiD,CAAjD,CAA0DA,CAAYpG,CAAAA,OAA1E,CAAmFA,EAAA,CAAUhC,CAAA,CAAeA,CAAA,CAAe,EAAf,CAAmBgC,EAAnB,CAAf,CAA4CoG,CAAYpG,CAAAA,OAAxD,CACvF8G,GAAAA,CAAYtC,EAAMuC,CAAAA,mBAAN,CAA0Bb,CAA1B,CAClB,OAAMc,GAAQxC,EAAMyC,CAAAA,aAAN,CAAoBH,EAApB,CACRzG,GAAAA,CAAO,MAAM,CAACpB,CAAA,EAAU,KAAV,CAAkByB,CAAlB,CAAwBD,CAAzB,EAA+B+D,EAAMvC,CAAAA,KAArC,CAA6C,GAAEuC,EAAMtF,CAAAA,GAAR,WAAsB8H,EAAtB,EAA7C,CAA4E3H,EAA5E,CAAkFrB,CAAA,CAAe,CAAEgC,QAAAA,EAAF,CAAf,CAA4B,CAACb,EAAA,GAAY,IAAZ,EAAoBA,EAApB,GAAgC,IAAK,EAArC,CAAyC,CAAzC,CAAkDA,EAAQ2E,CAAAA,MAA3D,EAAqE,CAAEA,OAAQ3E,EAAQ2E,CAAAA,MAAlB,CAArE,CAAkG,EAA9H,CAAlF,CACnB,OAAO,CACNoC,KAAMY,EADA,CAENI,GAAI7G,EAAK8G,CAAAA,EAFH,CAGNC,SAAU/G,EAAKgH,CAAAA,GAHT,CAzBiC,CAAlC,CAFkD,CA8EpDC,YAAM,CAACpB,CAAD,CAAOC,CAAP,CAAiBC,CAAjB,CAA8B,CACzC,MAAO,KAAKH,CAAAA,cAAL,CAAoB,MAApB,CAA4BC,CAA5B,CAAkCC,CAAlC,CAA4CC,CAA5C,CADkC,CAkCpCmB,uBAAiB,CAACrB,CAAD,CAAOsB,CAAP,CAAcrB,CAAd,CAAwBC,CAAxB,CAAqC,CAC3D,IAAIqB,GAAS,IACb,OAAMX,GAAYW,EAAOV,CAAAA,mBAAP,CAA2Bb,CAA3B,CACZc,EAAAA,CAAQS,EAAOR,CAAAA,aAAP,CAAqBH,EAArB,CACd;MAAM5H,GAAM,IAAIwI,GAAJ,CAAQD,EAAOvI,CAAAA,GAAf,CAAsB,uBAAsB8H,CAAtB,EAAtB,CACZ9H,GAAIyI,CAAAA,YAAaC,CAAAA,GAAjB,CAAqB,OAArB,CAA8BJ,CAA9B,CACA,OAAOC,GAAOnD,CAAAA,eAAP,CAAuB,KAAM,EAAN,EAAY,CACzC,IAAIjF,EACJ,OAAMF,GAAUnB,CAAA,CAAe,CAAE8H,OAAQF,CAAqBE,CAAAA,MAA/B,CAAf,CAAwDM,CAAxD,CAAhB,CACMpG,GAAUhC,CAAA,CAAeA,CAAA,CAAe,EAAf,CAAmByJ,EAAOzH,CAAAA,OAA1B,CAAf,CAAmD,CAAE,WAAYxB,MAAA,CAAOW,EAAQ2G,CAAAA,MAAf,CAAd,CAAnD,CACZ,OAAOQ,KAAX,GAAoB,WAApB,EAAmCH,CAAnC,WAAuDG,KAAvD,EACCjH,EAEA,CAFO,IAAIkH,QAEX,CADAlH,EAAKmH,CAAAA,MAAL,CAAY,cAAZ,CAA4BrH,EAAQ0G,CAAAA,YAApC,CACA,CAAAxG,EAAKmH,CAAAA,MAAL,CAAY,EAAZ,CAAgBL,CAAhB,CAHD,EAIW,MAAOI,SAAX,GAAwB,WAAxB,EAAuCJ,CAAvC,WAA2DI,SAA3D,EACNlH,EACA,CADO8G,CACP,CAAA9G,EAAKmH,CAAAA,MAAL,CAAY,cAAZ,CAA4BrH,EAAQ0G,CAAAA,YAApC,CAFM,GAINxG,EAEA,CAFO8G,CAEP,CADAnG,EAAA,CAAQ,eAAR,CACA,CAD4B,WAAUb,EAAQ0G,CAAAA,YAAlB,EAC5B,CAAA7F,EAAA,CAAQ,cAAR,CAAA;AAA0Bb,EAAQY,CAAAA,WAN5B,CAQP,OAAO,CACNmG,KAAMY,EADA,CAENM,SAAuEC,CAA5D,MAAM3G,CAAA,CAAI+G,EAAOxF,CAAAA,KAAX,CAAkB/C,EAAI2I,CAAAA,QAAJ,EAAlB,CAAkCxI,EAAlC,CAAwC,CAAEW,QAAAA,EAAF,CAAxC,CAAsDqH,EAAAA,GAFjE,CAhBkC,CAAnC,CANoD,CA0DtDS,2BAAqB,CAAC5B,CAAD,CAAO/G,CAAP,CAAgB,CAC1C,IAAI4I,EAAS,IACb,OAAOA,EAAOzD,CAAAA,eAAP,CAAuB,KAAM,EAAN,EAAY,CACzC,IAAI0C,EAAQe,CAAOd,CAAAA,aAAP,CAAqBf,CAArB,CAAZ,CACMlG,GAAUhC,CAAA,CAAe,EAAf,CAAmB+J,CAAO/H,CAAAA,OAA1B,CAChB,IAAIb,CAAA,GAAY,IAAZ,EAAoBA,CAApB,GAAgC,IAAK,EAArC,CAAyC,CAAzC,CAAkDA,CAAQ2G,CAAAA,MAA9D,CAAsE9F,EAAA,CAAQ,UAAR,CAAA,CAAsB,MACtFK,EAAAA,CAAO,MAAMI,CAAA,CAAKsH,CAAO9F,CAAAA,KAAZ,CAAoB,GAAE8F,CAAO7I,CAAAA,GAAT,uBAAmC8H,CAAnC,EAApB,CAAgE,EAAhE,CAAoE,CAAEhH,QAAAA,EAAF,CAApE,CACbd,EAAAA,CAAM,IAAIwI,GAAJ,CAAQK,CAAO7I,CAAAA,GAAf,CAAqBmB,CAAKnB,CAAAA,GAA1B,CACNsI,GAAAA,CAAQtI,CAAIyI,CAAAA,YAAa1H,CAAAA,GAAjB,CAAqB,OAArB,CACd,IAAI,CAACuH,EAAL,CAAY,KAAM,KAAIzG,CAAJ,CAAiB,0BAAjB,CAAN,CACZ,MAAO,CACNiH,UAAW9I,CAAI2I,CAAAA,QAAJ,EADL,CAEN3B,KAAAA,CAFM,CAGNsB,MAAAA,EAHM,CARkC,CAAnC,CAFmC,CA6DrCS,YAAM,CAAC/B,CAAD;AAAOC,CAAP,CAAiBC,CAAjB,CAA8B,CACzC,MAAO,KAAKH,CAAAA,cAAL,CAAoB,KAApB,CAA2BC,CAA3B,CAAiCC,CAAjC,CAA2CC,CAA3C,CADkC,CA8BpC8B,UAAI,CAACC,CAAD,CAAWC,CAAX,CAAmBjJ,CAAnB,CAA4B,CACrC,IAAIkJ,EAAS,IACb,OAAOA,EAAO/D,CAAAA,eAAP,CAAuB,KAAM,EAAN,EACtB,MAAM7D,CAAA,CAAK4H,CAAOpG,CAAAA,KAAZ,CAAoB,GAAEoG,CAAOnJ,CAAAA,GAAT,cAApB,CAAgD,CAC5D8G,SAAUqC,CAAOrC,CAAAA,QAD2C,CAE5DsC,UAAWH,CAFiD,CAG5DI,eAAgBH,CAH4C,CAI5DI,kBAAmBrJ,CAAA,GAAY,IAAZ,EAAoBA,CAApB,GAAgC,IAAK,EAArC,CAAyC,IAAK,EAA9C,CAAkDA,CAAQqJ,CAAAA,iBAJjB,CAAhD,CAKV,CAAExI,QAASqI,CAAOrI,CAAAA,OAAlB,CALU,CADP,CAF8B,CAsChCyI,UAAI,CAACN,CAAD,CAAWC,CAAX,CAAmBjJ,CAAnB,CAA4B,CACrC,IAAIuJ,EAAS,IACb,OAAOA,EAAOpE,CAAAA,eAAP,CAAuB,KAAM,EAAN,EACtB,EAAE4B,KAKwBmB,CALjB,MAAM5G,CAAA,CAAKiI,CAAOzG,CAAAA,KAAZ,CAAoB,GAAEyG,CAAOxJ,CAAAA,GAAT,cAApB,CAAgD,CACrE8G,SAAU0C,CAAO1C,CAAAA,QADoD,CAErEsC,UAAWH,CAF0D,CAGrEI,eAAgBH,CAHqD,CAIrEI,kBAAmBrJ,CAAA,GAAY,IAAZ,EAAoBA,CAApB,GAAgC,IAAK,EAArC,CAAyC,IAAK,EAA9C,CAAkDA,CAAQqJ,CAAAA,iBAJR,CAAhD;AAKnB,CAAExI,QAAS0I,CAAO1I,CAAAA,OAAlB,CALmB,CAKWqH,EAAAA,GAL1B,EADD,CAF8B,CA8DhCsB,qBAAe,CAACzC,CAAD,CAAO0C,CAAP,CAAkBzJ,CAAlB,CAA2B,CAC/C,IAAI0J,EAAS,IACb,OAAOA,EAAOvE,CAAAA,eAAP,CAAuB,KAAM,EAAN,EAAY,CACzC,IAAI0C,GAAQ6B,CAAO5B,CAAAA,aAAP,CAAqBf,CAArB,CACR7F,GAAAA,CAAO,MAAMI,CAAA,CAAKoI,CAAO5G,CAAAA,KAAZ,CAAoB,GAAE4G,CAAO3J,CAAAA,GAAT,gBAA4B8H,EAA5B,EAApB,CAAyDhJ,CAAA,CAAe,CAAE4K,UAAAA,CAAF,CAAf,CAA8B,CAACzJ,CAAA,GAAY,IAAZ,EAAoBA,CAApB,GAAgC,IAAK,EAArC,CAAyC,CAAzC,CAAkDA,CAAQ2J,CAAAA,SAA3D,EAAwE,CAAEA,UAAW3J,CAAQ2J,CAAAA,SAArB,CAAxE,CAA2G,EAAzI,CAAzD,CAAuM,CAAE9I,QAAS6I,CAAO7I,CAAAA,OAAlB,CAAvM,CAEjB,OAAO,CAAEgI,UAAWe,SAAA,CAAW,GAAEF,CAAO3J,CAAAA,GAAT,GAAemB,EAAK2I,CAAAA,SAApB,GADJC,CAAC9J,CAAA,GAAY,IAAZ,EAAoBA,CAApB,GAAgC,IAAK,EAArC,CAAyC,CAAzC,CAAkDA,CAAQ+J,CAAAA,QAA3DD,EAAwE,aAAY9J,CAAQ+J,CAAAA,QAAR,GAAqB,CAAA,CAArB,CAA4B,EAA5B,CAAiC/J,CAAQ+J,CAAAA,QAArD,EAAxED,CAA0I,EACtI,EAAX,CAAb,CAJkC,CAAnC,CAFwC,CA+C1CE,sBAAgB,CAACC,CAAD,CAAQR,CAAR,CAAmBzJ,CAAnB,CAA4B,CACjD,IAAIkK,EAAS,IACb,OAAOA,EAAO/E,CAAAA,eAAP,CAAuB,KAAM,EAAN,EAAY,CACzC,MAAMjE;AAAO,MAAMI,CAAA,CAAK4I,CAAOpH,CAAAA,KAAZ,CAAoB,GAAEoH,CAAOnK,CAAAA,GAAT,gBAA4BmK,CAAOrD,CAAAA,QAAnC,EAApB,CAAmE,CACrF4C,UAAAA,CADqF,CAErFQ,MAAAA,CAFqF,CAAnE,CAGhB,CAAEpJ,QAASqJ,CAAOrJ,CAAAA,OAAlB,CAHgB,CAAnB,CAIMiJ,GAAqB,CAAC9J,CAAA,GAAY,IAAZ,EAAoBA,CAApB,GAAgC,IAAK,EAArC,CAAyC,CAAzC,CAAkDA,CAAQ+J,CAAAA,QAA3D,EAAwE,aAAY/J,CAAQ+J,CAAAA,QAAR,GAAqB,CAAA,CAArB,CAA4B,EAA5B,CAAiC/J,CAAQ+J,CAAAA,QAArD,EAAxE,CAA0I,EACrK,OAAO7I,GAAKiC,CAAAA,GAAL,CAAUgH,EAAD,EAAWtL,CAAA,CAAeA,CAAA,CAAe,EAAf,CAAmBsL,EAAnB,CAAf,CAA0C,EAA1C,CAA8C,CAAEtB,UAAWsB,EAAMN,CAAAA,SAAN,CAAkBD,SAAA,CAAW,GAAEM,CAAOnK,CAAAA,GAAT,GAAeoK,EAAMN,CAAAA,SAArB,GAAiCC,EAAjC,EAAX,CAAlB,CAAsF,IAAnG,CAA9C,CAApB,CANkC,CAAnC,CAF0C,CAqElDC,QAAQ,CAAChD,CAAD,CAAO/G,CAAP,CAAgBC,CAAhB,CAA4B,CACnC,MAAMmK,EAAa,OAAQpK,CAAA,GAAY,IAAZ,EAAoBA,CAApB,GAAgC,IAAK,EAArC,CAAyC,IAAK,EAA9C,CAAkDA,CAAQ2J,CAAAA,SAAlE,CAAA,GAAiF,WAAjF,CAA+F,4BAA/F,CAA8H,QAAjJ,CAEMU,GAAc,CADdC,CACc,CADQ,IAAKC,CAAAA,0BAAL,EAAiCvK,CAAA,GAAY,IAAZ,EAAoBA,CAApB,GAAgC,IAAK,EAArC,CAAyC,IAAK,EAA9C,CAAkDA,CAAQ2J,CAAAA,SAA3F,GAAyG,EAAzG,CACR;AAAuB,IAAGW,CAAH,EAAvB,CAAkD,EAFtE,CAGMzC,GAAQ,IAAKC,CAAAA,aAAL,CAAmBf,CAAnB,CAKd,OAAO,KAAInB,EAAJ,CAJY,EAAAL,EAAMzE,CAAA,CAAI,IAAKgC,CAAAA,KAAT,CAAiB,GAAE,IAAK/C,CAAAA,GAAP,IAAcqK,CAAd,IAA4BvC,EAA5B,GAAoCwC,EAApC,EAAjB,CAAoE,CAC5FxJ,QAAS,IAAKA,CAAAA,OAD8E,CAE5FF,cAAe,CAAA,CAF6E,CAApE,CAGtBV,CAHsB,CAIlB,CAAoC,IAAK+E,CAAAA,kBAAzC,CAT4B,CA0B9BwF,UAAI,CAACzD,CAAD,CAAO,CAChB,IAAI0D,EAAU,IACd,OAAM5C,EAAQ4C,CAAQ3C,CAAAA,aAAR,CAAsBf,CAAtB,CACd,OAAO0D,EAAQtF,CAAAA,eAAR,CAAwB,KAAM,EAAN,EACvBpC,CAAA,CAAiB,MAAMjC,CAAA,CAAI2J,CAAQ3H,CAAAA,KAAZ,CAAoB,GAAE2H,CAAQ1K,CAAAA,GAAV,gBAA6B8H,CAA7B,EAApB,CAA0D,CAAEhH,QAAS4J,CAAQ5J,CAAAA,OAAnB,CAA1D,CAAvB,CADD,CAHS,CAsBX6J,YAAM,CAAC3D,CAAD,CAAO,CAEZc,CAAAA,CADQ8C,IACQ7C,CAAAA,aAAR,CAAsBf,CAAtB,CACd,IAAI,CAEH,MADA,OAAMvF,CAAA,CAHOmJ,IAGM7H,CAAAA,KAAb,CAAqB,GAHd6H,IAGwB5K,CAAAA,GAAV,WAAwB8H,CAAxB,EAArB,CAAsD,CAAEhH,QAHjD8J,IAGkE9J,CAAAA,OAAnB,CAAtD,CACC,CAAA,CACNK,KAAM,CAAA,CADA,CAEN1D,MAAO,IAFD,CAFJ,CAMF,MAAOA,CAAP,CAAc,CACf,GATamN,IASD3F,CAAAA,kBAAZ,CAAgC,KAAMxH,EAAN;AAChC,GAAID,CAAA,CAAeC,CAAf,CAAJ,EAA6BA,CAA7B,WAA8C4E,EAA9C,GACOC,CACF,CADkB7E,CAAM6E,CAAAA,aACxB,CAAA,CAAC,GAAD,CAAM,GAAN,CAAWrB,CAAAA,QAAX,CAAoBqB,CAAA,GAAkB,IAAlB,EAA0BA,CAA1B,GAA4C,IAAK,EAAjD,CAAqD,IAAK,EAA1D,CAA8DA,CAActB,CAAAA,MAAhG,CAFL,EAE8G,MAAO,CACnHG,KAAM,CAAA,CAD6G,CAEnH1D,MAAAA,CAFmH,CAKrH,MAAMA,EAAN,CATe,CATE,CAuEnBoN,YAAY,CAAC7D,CAAD,CAAO/G,CAAP,CAAgB,CACrB6H,CAAAA,CAAQ,IAAKC,CAAAA,aAAL,CAAmBf,CAAnB,CACd,OAAM8D,EAAe,EACrB,KAAMf,EAAqB,CAAC9J,CAAA,GAAY,IAAZ,EAAoBA,CAApB,GAAgC,IAAK,EAArC,CAAyC,CAAzC,CAAkDA,CAAQ+J,CAAAA,QAA3D,EAAwE,YAAW/J,CAAQ+J,CAAAA,QAAR,GAAqB,CAAA,CAArB,CAA4B,EAA5B,CAAiC/J,CAAQ+J,CAAAA,QAApD,EAAxE,CAAyI,EAChKD,EAAJ,GAA2B,EAA3B,EAA+Be,CAAalM,CAAAA,IAAb,CAAkBmL,CAAlB,CACzBM,EAAAA,CAAa,OAAQpK,CAAA,GAAY,IAAZ,EAAoBA,CAApB,GAAgC,IAAK,EAArC,CAAyC,IAAK,EAA9C,CAAkDA,CAAQ2J,CAAAA,SAAlE,CAAA,GAAiF,WAAjF,CAA+F,cAA/F,CAAgH,QAC7HW,EAAAA,CAAsB,IAAKC,CAAAA,0BAAL,EAAiCvK,CAAA,GAAY,IAAZ,EAAoBA,CAApB,GAAgC,IAAK,EAArC,CAAyC,IAAK,EAA9C,CAAkDA,CAAQ2J,CAAAA,SAA3F,GAAyG,EAAzG,CACxBW,EAAJ,GAA4B,EAA5B,EAAgCO,CAAalM,CAAAA,IAAb,CAAkB2L,CAAlB,CAC5BD,EAAAA,CAAcQ,CAAaC,CAAAA,IAAb,CAAkB,MAAlB,CACdT,EAAJ;AAAoB,EAApB,GAAwBA,CAAxB,CAAuC,IAAGA,CAAH,EAAvC,CACA,OAAO,CAAEnJ,KAAM,CAAE6J,UAAWnB,SAAA,CAAW,GAAE,IAAK7J,CAAAA,GAAP,IAAcqK,CAAd,WAAmCvC,CAAnC,GAA2CwC,CAA3C,EAAX,CAAb,CAAR,CAVoB,CAmCtB5I,YAAM,CAACwI,CAAD,CAAQ,CACnB,IAAIe,EAAU,IACd,OAAOA,EAAQ7F,CAAAA,eAAR,CAAwB,KAAM,EAAN,EACvB,MAAM1D,EAAA,CAAOuJ,CAAQlI,CAAAA,KAAf,CAAuB,GAAEkI,CAAQjL,CAAAA,GAAV,WAAwBiL,CAAQnE,CAAAA,QAAhC,EAAvB,CAAmE,CAAEoE,SAAUhB,CAAZ,CAAnE,CAAwF,CAAEpJ,QAASmK,CAAQnK,CAAAA,OAAnB,CAAxF,CADP,CAFY,CA0EdqK,UAAI,CAACnE,CAAD,CAAO/G,CAAP,CAAgBC,CAAhB,CAA4B,CACrC,IAAIkL,EAAU,IACd,OAAOA,EAAQhG,CAAAA,eAAR,CAAwB,KAAM,EAAN,EAAY,CAC1C,MAAMjF,GAAOrB,CAAA,CAAeA,CAAA,CAAeA,CAAA,CAAe,EAAf,CAAmBsH,CAAnB,CAAf,CAA2DnG,CAA3D,CAAf,CAAoF,EAApF,CAAwF,CAAEoL,OAAQrE,CAARqE,EAAgB,EAAlB,CAAxF,CACb,OAAO,OAAM9J,CAAA,CAAK6J,CAAQrI,CAAAA,KAAb,CAAqB,GAAEqI,CAAQpL,CAAAA,GAAV,gBAA6BoL,CAAQtE,CAAAA,QAArC,EAArB,CAAsE3G,EAAtE,CAA4E,CAAEW,QAASsK,CAAQtK,CAAAA,OAAnB,CAA5E,CAA0GZ,CAA1G,CAF6B,CAApC,CAF8B,CAchCoL,YAAM,CAACrL,CAAD,CAAUC,CAAV,CAAsB,CACjC,IAAIqL,EAAU,IACd,OAAOA,EAAQnG,CAAAA,eAAR,CAAwB,KAAM,EAAN,EAAY,CAC1C,MAAMjF,EAAOrB,CAAA,CAAe,EAAf;AAAmBmB,CAAnB,CACb,OAAO,OAAMsB,CAAA,CAAKgK,CAAQxI,CAAAA,KAAb,CAAqB,GAAEwI,CAAQvL,CAAAA,GAAV,mBAAgCuL,CAAQzE,CAAAA,QAAxC,EAArB,CAAyE3G,CAAzE,CAA+E,CAAEW,QAASyK,CAAQzK,CAAAA,OAAnB,CAA/E,CAA6GZ,CAA7G,CAF6B,CAApC,CAF0B,CAOlCqH,cAAc,CAACJ,CAAD,CAAW,CACxB,MAAO9C,KAAKC,CAAAA,SAAL,CAAe6C,CAAf,CADiB,CAGzBM,QAAQ,CAACtG,CAAD,CAAO,CACd,MAAI,OAAOQ,EAAX,GAAsB,WAAtB,CAA0CA,CAAO6J,CAAAA,IAAP,CAAYrK,CAAZ,CAAkBwH,CAAAA,QAAlB,CAA2B,QAA3B,CAA1C,CACO8C,IAAA,CAAKtK,CAAL,CAFO,CAIf4G,aAAa,CAACf,CAAD,CAAO,CACnB,MAAQ,GAAE,IAAKF,CAAAA,QAAP,IAAmBE,CAAKvD,CAAAA,OAAL,CAAa,MAAb,CAAqB,EAArB,CAAnB,EADW,CAGpBoE,mBAAmB,CAACb,CAAD,CAAO,CACzB,MAAOA,EAAKvD,CAAAA,OAAL,CAAa,UAAb,CAAyB,EAAzB,CAA6BA,CAAAA,OAA7B,CAAqC,MAArC,CAA6C,GAA7C,CADkB,CAG1B+G,0BAA0B,CAACZ,CAAD,CAAY,CACrC,MAAMnF,EAAS,EACXmF,EAAU8B,CAAAA,KAAd,EAAqBjH,CAAO7F,CAAAA,IAAP,CAAa,SAAQgL,CAAU8B,CAAAA,KAAlB,EAAb,CACjB9B,EAAU+B,CAAAA,MAAd,EAAsBlH,CAAO7F,CAAAA,IAAP,CAAa,UAASgL,CAAU+B,CAAAA,MAAnB,EAAb,CAClB/B,EAAUgC,CAAAA,MAAd,EAAsBnH,CAAO7F,CAAAA,IAAP,CAAa,UAASgL,CAAUgC,CAAAA,MAAnB,EAAb,CAClBhC;CAAUiC,CAAAA,MAAd,EAAsBpH,CAAO7F,CAAAA,IAAP,CAAa,UAASgL,CAAUiC,CAAAA,MAAnB,EAAb,CAClBjC,EAAUkC,CAAAA,OAAd,EAAuBrH,CAAO7F,CAAAA,IAAP,CAAa,WAAUgL,CAAUkC,CAAAA,OAApB,EAAb,CACvB,OAAOrH,EAAOsG,CAAAA,IAAP,CAAY,MAAZ,CAP8B,CA/uBlB,CAgwBrB,OAAMgB,GAAkB,CAAE,gBAAkB,mBAApB,CAIxB,KAAIC,GAAmB,aAAcjH,GAAd,CACtBhH,WAAW,CAACiC,CAAD,CAAMc,CAAA,CAAU,EAAhB,CAAoBkE,CAApB,CAA6BiH,CAA7B,CAAmC,CACvCC,CAAAA,CAAU,IAAI1D,GAAJ,CAAQxI,CAAR,CAChB,EAAIiM,CAAA,GAAS,IAAT,EAAiBA,CAAjB,GAA0B,IAAK,EAA/B,CAAmC,CAAnC,CAA4CA,CAAKE,CAAAA,cAArD,GACK,wBAAyBpI,CAAAA,IAAzB,CAA8BmI,CAAQE,CAAAA,QAAtC,CADL,EACwD,CAACF,CAAQE,CAAAA,QAASnL,CAAAA,QAAjB,CAA0B,mBAA1B,CADzD,GACyGiL,CAAQE,CAAAA,QADjH,CAC4HF,CAAQE,CAAAA,QAAS3I,CAAAA,OAAjB,CAAyB,WAAzB,CAAsC,mBAAtC,CAD5H,CAGM4I,EAAAA,CAAWH,CAAQI,CAAAA,IAAK7I,CAAAA,OAAb,CAAqB,KAArB,CAA4B,EAA5B,CACX8I,EAAAA,CAAezN,CAAA,CAAeA,CAAA,CAAe,EAAf,CAAmBiN,EAAnB,CAAf,CAAoDjL,CAApD,CACrB,MAAA,CAAMuL,CAAN,CAAgBE,CAAhB,CAA8BvH,CAA9B,CAAuC,SAAvC,CAP6C,CAyCxCwH,iBAAW,CAACvM,CAAD,CAAU,CAC1B,IAAIqF,EAAQ,IACZ;MAAOA,EAAMF,CAAAA,eAAN,CAAsB,KAAM,EAAN,EAAY,CACxC,MAAMkF,EAAchF,CAAMmH,CAAAA,8BAAN,CAAqCxM,CAArC,CACpB,OAAO,OAAMc,CAAA,CAAIuE,CAAMvC,CAAAA,KAAV,CAAkB,GAAEuC,CAAMtF,CAAAA,GAAR,UAAqBsK,CAArB,EAAlB,CAAsD,CAAExJ,QAASwE,CAAMxE,CAAAA,OAAjB,CAAtD,CAF2B,CAAlC,CAFmB,CAwCrB4L,eAAS,CAAC1E,CAAD,CAAK,CACnB,IAAI2E,EAAS,IACb,OAAOA,EAAOvH,CAAAA,eAAP,CAAuB,KAAM,EAAN,EACtB,MAAMrE,CAAA,CAAI4L,CAAO5J,CAAAA,KAAX,CAAmB,GAAE4J,CAAO3M,CAAAA,GAAT,WAAuBgI,CAAvB,EAAnB,CAAgD,CAAElH,QAAS6L,CAAO7L,CAAAA,OAAlB,CAAhD,CADP,CAFY,CA2Cd8L,kBAAY,CAAC5E,CAAD,CAAK/H,CAAA,CAAU,CAAE4M,OAAQ,CAAA,CAAV,CAAf,CAAkC,CACnD,IAAItE,EAAS,IACb,OAAOA,EAAOnD,CAAAA,eAAP,CAAuB,KAAM,EAAN,EACtB,MAAM7D,CAAA,CAAKgH,CAAOxF,CAAAA,KAAZ,CAAoB,GAAEwF,CAAOvI,CAAAA,GAAT,SAApB,CAA2C,CACvDgI,GAAAA,CADuD,CAEvD9F,KAAM8F,CAFiD,CAGvD8E,KAAM7M,CAAQ6M,CAAAA,IAHyC,CAIvDD,OAAQ5M,CAAQ4M,CAAAA,MAJuC,CAKvDE,gBAAiB9M,CAAQ+M,CAAAA,aAL8B,CAMvDC,mBAAoBhN,CAAQiN,CAAAA,gBAN2B,CAA3C,CAOV,CAAEpM,QAASyH,CAAOzH,CAAAA,OAAlB,CAPU,CADP,CAF4C,CAgD9CqM,kBAAY,CAACnF,CAAD;AAAK/H,CAAL,CAAc,CAC/B,IAAI4I,EAAS,IACb,OAAOA,EAAOzD,CAAAA,eAAP,CAAuB,KAAM,EAAN,EACtB,MAAM5D,CAAA,CAAIqH,CAAO9F,CAAAA,KAAX,CAAmB,GAAE8F,CAAO7I,CAAAA,GAAT,WAAuBgI,CAAvB,EAAnB,CAAgD,CAC5DA,GAAAA,CAD4D,CAE5D9F,KAAM8F,CAFsD,CAG5D6E,OAAQ5M,CAAQ4M,CAAAA,MAH4C,CAI5DE,gBAAiB9M,CAAQ+M,CAAAA,aAJmC,CAK5DC,mBAAoBhN,CAAQiN,CAAAA,gBALgC,CAAhD,CAMV,CAAEpM,QAAS+H,CAAO/H,CAAAA,OAAlB,CANU,CADP,CAFwB,CAoC1BsM,iBAAW,CAACpF,CAAD,CAAK,CACrB,IAAIqF,EAAS,IACb,OAAOA,EAAOjI,CAAAA,eAAP,CAAuB,KAAM,EAAN,EACtB,MAAM7D,CAAA,CAAK8L,CAAOtK,CAAAA,KAAZ,CAAoB,GAAEsK,CAAOrN,CAAAA,GAAT,WAAuBgI,CAAvB,QAApB,CAAuD,EAAvD,CAA2D,CAAElH,QAASuM,CAAOvM,CAAAA,OAAlB,CAA3D,CADP,CAFc,CA+BhBwM,kBAAY,CAACtF,CAAD,CAAK,CACtB,IAAImB,EAAS,IACb,OAAOA,EAAO/D,CAAAA,eAAP,CAAuB,KAAM,EAAN,EACtB,MAAM1D,EAAA,CAAOyH,CAAOpG,CAAAA,KAAd,CAAsB,GAAEoG,CAAOnJ,CAAAA,GAAT,WAAuBgI,CAAvB,EAAtB,CAAmD,EAAnD,CAAuD,CAAElH,QAASqI,CAAOrI,CAAAA,OAAlB,CAAvD,CADP,CAFe,CAMvB2L,8BAA8B,CAACxM,CAAD,CAAU,CACvC,MAAMwE;AAAS,EACXxE,EAAJ,GACK,OAIJ,EAJeA,EAIf,GAJwBwE,CAAO4B,CAAAA,KAI/B,CAJuC/G,MAAA,CAAOW,CAAQoG,CAAAA,KAAf,CAIvC,EAHI,QAGJ,EAHgBpG,EAGhB,GAHyBwE,CAAO6B,CAAAA,MAGhC,CAHyChH,MAAA,CAAOW,CAAQqG,CAAAA,MAAf,CAGzC,EAFIrG,CAAQsN,CAAAA,MAEZ,GAFoB9I,CAAO8I,CAAAA,MAE3B,CAFoCtN,CAAQsN,CAAAA,MAE5C,EADItN,CAAQuN,CAAAA,UACZ,GADwB/I,CAAO+I,CAAAA,UAC/B,CAD4CvN,CAAQuN,CAAAA,UACpD,EAAIvN,CAAQwN,CAAAA,SAAZ,GAAuBhJ,CAAOgJ,CAAAA,SAA9B,CAA0CxN,CAAQwN,CAAAA,SAAlD,CALD,CAOA,OAAOpP,OAAOC,CAAAA,IAAP,CAAYmG,CAAZ,CAAoBzF,CAAAA,MAApB,CAA6B,CAA7B,CAAiC,GAAjC,CAAmE2J,CAA5B,IAAI+E,eAAJ,CAAoBjJ,CAApB,CAA4BkE,EAAAA,QAA5B,EAAvC,CAAgF,EAThD,CAtPlB,CAAvB,CAyQIgF,GAAyB,aAAc5I,GAAd,CAkB5BhH,WAAW,CAACiC,CAAD,CAAMc,CAAA,CAAU,EAAhB,CAAoBkE,CAApB,CAA6B,CACjCqH,CAAAA,CAAWrM,CAAIyD,CAAAA,OAAJ,CAAY,KAAZ,CAAmB,EAAnB,CACX8I,EAAAA,CAAezN,CAAA,CAAeA,CAAA,CAAe,EAAf,CAAmBiN,EAAnB,CAAf,CAAoDjL,CAApD,CACrB,MAAA,CAAMuL,CAAN,CAAgBE,CAAhB,CAA8BvH,CAA9B,CAAuC,SAAvC,CAHuC,CAuClC4H,kBAAY,CAAC1K,CAAD,CAAO,CACxB,IAAIoD,EAAQ,IACZ,OAAOA,EAAMF,CAAAA,eAAN,CAAsB,KAAM,EAAN,EACrB,MAAM7D,CAAA,CAAK+D,CAAMvC,CAAAA,KAAX,CAAmB,GAAEuC,CAAMtF,CAAAA,GAAR,SAAnB,CAAyC,CAAEkC,KAAAA,CAAF,CAAzC,CAAmD,CAAEpB,QAASwE,CAAMxE,CAAAA,OAAjB,CAAnD,CADP,CAFiB,CAoDnB0L,iBAAW,CAACvM,CAAD,CAAU,CAC1B,IAAI0M;AAAS,IACb,OAAOA,EAAOvH,CAAAA,eAAP,CAAuB,KAAM,EAAN,EAAY,CACzC,IAAMwI,EAAc,IAAIF,eACxB,EAAKzN,CAAA,GAAY,IAAZ,EAAoBA,CAApB,GAAgC,IAAK,EAArC,CAAyC,IAAK,EAA9C,CAAkDA,CAAQoG,CAAAA,KAA/D,IAA0E,IAAK,EAA/E,EAAkFuH,CAAYlF,CAAAA,GAAZ,CAAgB,OAAhB,CAAyBzI,CAAQoG,CAAAA,KAAMsC,CAAAA,QAAd,EAAzB,CAClF,EAAK1I,CAAA,GAAY,IAAZ,EAAoBA,CAApB,GAAgC,IAAK,EAArC,CAAyC,IAAK,EAA9C,CAAkDA,CAAQqG,CAAAA,MAA/D,IAA2E,IAAK,EAAhF,EAAmFsH,CAAYlF,CAAAA,GAAZ,CAAgB,QAAhB,CAA0BzI,CAAQqG,CAAAA,MAAOqC,CAAAA,QAAf,EAA1B,CACnF,EAAI1I,CAAA,GAAY,IAAZ,EAAoBA,CAApB,GAAgC,IAAK,EAArC,CAAyC,CAAzC,CAAkDA,CAAQuN,CAAAA,UAA9D,GAA0EI,CAAYlF,CAAAA,GAAZ,CAAgB,YAAhB,CAA8BzI,CAAQuN,CAAAA,UAAtC,CAC1E,EAAIvN,CAAA,GAAY,IAAZ,EAAoBA,CAApB,GAAgC,IAAK,EAArC,CAAyC,CAAzC,CAAkDA,CAAQwN,CAAAA,SAA9D,GAAyEG,CAAYlF,CAAAA,GAAZ,CAAgB,WAAhB,CAA6BzI,CAAQwN,CAAAA,SAArC,CACzE,EAAIxN,CAAA,GAAY,IAAZ,EAAoBA,CAApB,GAAgC,IAAK,EAArC,CAAyC,CAAzC,CAAkDA,CAAQsN,CAAAA,MAA9D,GAAsEK,CAAYlF,CAAAA,GAAZ,CAAgB,QAAhB,CAA0BzI,CAAQsN,CAAAA,MAAlC,CAChEjD,EAAAA,CAAcsD,CAAYjF,CAAAA,QAAZ,EAEpB,OAAO,OAAM5H,CAAA,CAAI4L,CAAO5J,CAAAA,KAAX,CADDuH,CAAAtK,CAAe,GAAE2M,CAAO3M,CAAAA,GAAT,WAAuBsK,CAAvB,EAAftK,CAAuD,GAAE2M,CAAO3M,CAAAA,GAAT,SACtD;AAAuB,CAAEc,QAAS6L,CAAO7L,CAAAA,OAAlB,CAAvB,CAT4B,CAAnC,CAFmB,CA6CrBwM,kBAAY,CAACzJ,CAAD,CAAa,CAC9B,IAAI0E,EAAS,IACb,OAAOA,EAAOnD,CAAAA,eAAP,CAAuB,KAAM,EAAN,EACtB,MAAM1D,EAAA,CAAO6G,CAAOxF,CAAAA,KAAd,CAAsB,GAAEwF,CAAOvI,CAAAA,GAAT,WAAuB6D,CAAvB,EAAtB,CAA2D,EAA3D,CAA+D,CAAE/C,QAASyH,CAAOzH,CAAAA,OAAlB,CAA/D,CADP,CAFuB,CAiI/B0K,IAAI,CAAC3H,CAAD,CAAa,CAChB,IAAIgF,EAAS,IACb,IAAI,CAACjF,CAAA,CAAkBC,CAAlB,CAAL,CAAoC,KAAM,KAAIhC,CAAJ,CAAiB,oJAAjB,CAAN,CAC9BgM,CAAAA,CAAU,IAAIjM,CAAWkM,CAAAA,kBAAf,CAAkC,CACjD5B,QAAS,IAAKlM,CAAAA,GADmC,CAEjD+N,YAAalK,CAFoC,CAGjDmK,KAAM,CACLlB,KAAM,QADD,CAELmB,WAAYA,KAAM,EAANA,EAAYpF,CAAO/H,CAAAA,OAF1B,CAH2C,CAOjDiC,MAAO,IAAKA,CAAAA,KAPqC,CAAlC,CAShB,OAAMkC,EAAqB,IAAKA,CAAAA,kBAChC;MAAO,KAAIiJ,KAAJ,CAAUL,CAAV,CAAmB,CAAE9M,GAAG,CAACoN,CAAD,CAASC,EAAT,CAAe,CAC7C,MAAM5O,GAAQ2O,CAAA,CAAOC,EAAP,CACd,OAAI,OAAO5O,GAAX,GAAqB,UAArB,CAAwCA,EAAxC,CACO,KAAM,CAAC,GAAGsD,EAAJ,CAAN,EAAmB,CACzB,GAAI,CACH,MAAO,CACN3B,KAAM,MAAM3B,EAAMX,CAAAA,KAAN,CAAYsP,CAAZ,CAAoBrL,EAApB,CADN,CAENrF,MAAO,IAFD,CADJ,CAKF,MAAOA,EAAP,CAAc,CACf,GAAIwH,CAAJ,CAAwB,KAAMxH,GAAN,CACxB,MAAO,CACN0D,KAAM,IADA,CAEN1D,MAAAA,EAFM,CAFQ,CANS,CAHmB,CAApB,CAAnB,CAbS,CA3RW,CAoUzB4Q,EAAAA,CAAiB,aAActJ,GAAd,CAEpBhH,WAAW,CAACiC,CAAD,CAAMc,CAAA,CAAU,EAAhB,CAAoBkE,CAApB,CAA6B,CACjCqH,CAAAA,CAAWrM,CAAIyD,CAAAA,OAAJ,CAAY,KAAZ,CAAmB,EAAnB,CACX8I,EAAAA,CAAezN,CAAA,CAAeA,CAAA,CAAe,EAAf,CAAmBiN,EAAnB,CAAf,CAAoD,EAApD,CAAwD,CAAE,eAAgB,kBAAlB,CAAxD,CAAgGjL,CAAhG,CACrB,MAAA,CAAMuL,CAAN,CAAgBE,CAAhB,CAA8BvH,CAA9B,CAAuC,SAAvC,CAHuC,CAMlCsJ,iBAAW,CAACrO,CAAD,CAAU,CAC1B,IAAIqF,EAAQ,IACZ,OAAOA,EAAMF,CAAAA,eAAN,CAAsB,KAAM,EAAN,EACrB,MAAMN,EAAWvD,CAAAA,IAAX,CAAgB+D,CAAMvC,CAAAA,KAAtB,CAA8B,GAAEuC,CAAMtF,CAAAA,GAAR,cAA9B,CAAyDC,CAAzD,CAAkE,CAAEa,QAASwE,CAAMxE,CAAAA,OAAjB,CAAlE,CADe,EACkF,EADxG,CAFmB,CAOrByN,cAAQ,CAACC,CAAD,CAAmBC,CAAnB,CAA8B,CAC3C,IAAI9B;AAAS,IACb,OAAOA,EAAOvH,CAAAA,eAAP,CAAuB,KAAM,EAAN,EACtB,MAAMN,EAAWvD,CAAAA,IAAX,CAAgBoL,CAAO5J,CAAAA,KAAvB,CAA+B,GAAE4J,CAAO3M,CAAAA,GAAT,WAA/B,CAAwD,CACpEwO,iBAAAA,CADoE,CAEpEC,UAAAA,CAFoE,CAAxD,CAGV,CAAE3N,QAAS6L,CAAO7L,CAAAA,OAAlB,CAHU,CADP,CAFoC,CAUtC4N,iBAAW,CAACzO,CAAD,CAAU,CAC1B,IAAIsI,EAAS,IACb,OAAOA,EAAOnD,CAAAA,eAAP,CAAuB,KAAM,EAAN,EACtB,MAAMN,EAAWvD,CAAAA,IAAX,CAAgBgH,CAAOxF,CAAAA,KAAvB,CAA+B,GAAEwF,CAAOvI,CAAAA,GAAT,cAA/B,CAA2DC,CAA3D,CAAoE,CAAEa,QAASyH,CAAOzH,CAAAA,OAAlB,CAApE,CADP,CAFmB,CAOrB6N,iBAAW,CAACH,CAAD,CAAmBC,CAAnB,CAA8B,CAC9C,IAAI5F,EAAS,IACb,OAAOA,EAAOzD,CAAAA,eAAP,CAAuB,KAAM,EAAN,EACtB,MAAMN,EAAWvD,CAAAA,IAAX,CAAgBsH,CAAO9F,CAAAA,KAAvB,CAA+B,GAAE8F,CAAO7I,CAAAA,GAAT,cAA/B,CAA2D,CACvEwO,iBAAAA,CADuE,CAEvEC,UAAAA,CAFuE,CAA3D,CAGV,CAAE3N,QAAS+H,CAAO/H,CAAAA,OAAlB,CAHU,CADgB,EAIM,EAJ7B,CAFuC,CAhC3B,CAkDrB,KAAI8N,GAAgB,aAAc7J,GAAd,CAEnBhH,WAAW,CAACiC,CAAD,CAAMc,CAAA,CAAU,EAAhB,CAAoBkE,CAApB,CAA6B,CACjCqH,CAAAA,CAAWrM,CAAIyD,CAAAA,OAAJ,CAAY,KAAZ;AAAmB,EAAnB,CACX8I,EAAAA,CAAezN,CAAA,CAAeA,CAAA,CAAe,EAAf,CAAmBiN,EAAnB,CAAf,CAAoD,EAApD,CAAwD,CAAE,eAAgB,kBAAlB,CAAxD,CAAgGjL,CAAhG,CACrB,MAAA,CAAMuL,CAAN,CAAgBE,CAAhB,CAA8BvH,CAA9B,CAAuC,SAAvC,CAHuC,CAMlC6J,gBAAU,CAAC5O,CAAD,CAAU,CACzB,IAAIqF,EAAQ,IACZ,IAAIrF,CAAQ6O,CAAAA,OAAQ9P,CAAAA,MAApB,CAA6B,CAA7B,EAAkCiB,CAAQ6O,CAAAA,OAAQ9P,CAAAA,MAAlD,CAA2D,GAA3D,CAAgE,KAAU8C,MAAJ,CAAU,mDAAV,CAAN,CAChE,MAAOwD,EAAMF,CAAAA,eAAN,CAAsB,KAAM,EAAN,EACrB,MAAMN,EAAWvD,CAAAA,IAAX,CAAgB+D,CAAMvC,CAAAA,KAAtB,CAA8B,GAAEuC,CAAMtF,CAAAA,GAAR,aAA9B,CAAwDC,CAAxD,CAAiE,CAAEa,QAASwE,CAAMxE,CAAAA,OAAjB,CAAjE,CADe,EACiF,EADvG,CAHkB,CAQpBiO,gBAAU,CAAC9O,CAAD,CAAU,CACzB,IAAI0M,EAAS,IACb,OAAOA,EAAOvH,CAAAA,eAAP,CAAuB,KAAM,EAAN,EACtB,MAAMN,EAAWvD,CAAAA,IAAX,CAAgBoL,CAAO5J,CAAAA,KAAvB,CAA+B,GAAE4J,CAAO3M,CAAAA,GAAT,aAA/B,CAA0DC,CAA1D,CAAmE,CAAEa,QAAS6L,CAAO7L,CAAAA,OAAlB,CAAnE,CADP,CAFkB,CAOpBkO,iBAAW,CAAC/O,CAAD,CAAU,CAC1B,IAAIsI,EAAS,IACb,IAAItI,CAAQgP,CAAAA,YAAZ;AAA6B,IAAK,EAAlC,CAAqC,CACpC,GAAIhP,CAAQgP,CAAAA,YAAZ,CAA2B,CAA3B,EAAgChP,CAAQgP,CAAAA,YAAxC,CAAuD,EAAvD,CAA2D,KAAUnN,MAAJ,CAAU,uCAAV,CAAN,CAC3D,GAAI7B,CAAQiP,CAAAA,YAAZ,GAA6B,IAAK,EAAlC,GACKjP,CAAQiP,CAAAA,YADb,CAC4B,CAD5B,EACiCjP,CAAQiP,CAAAA,YADzC,EACyDjP,CAAQgP,CAAAA,YADjE,EAC+E,KAAUnN,MAAJ,CAAW,sCAAqC7B,CAAQgP,CAAAA,YAA7C,CAA4D,CAA5D,EAAX,CAAN,CAH3C,CAMrC,MAAO1G,EAAOnD,CAAAA,eAAP,CAAuB,KAAM,EAAN,EACtB,MAAMN,EAAWvD,CAAAA,IAAX,CAAgBgH,CAAOxF,CAAAA,KAAvB,CAA+B,GAAEwF,CAAOvI,CAAAA,GAAT,cAA/B,CAA2DC,CAA3D,CAAoE,CAAEa,QAASyH,CAAOzH,CAAAA,OAAlB,CAApE,CADP,CARmB,CAarBqO,kBAAY,CAAClP,CAAD,CAAU,CAC3B,IAAI4I,EAAS,IACb,OAAOA,EAAOzD,CAAAA,eAAP,CAAuB,KAAM,EAAN,EACtB,MAAMN,EAAWvD,CAAAA,IAAX,CAAgBsH,CAAO9F,CAAAA,KAAvB,CAA+B,GAAE8F,CAAO7I,CAAAA,GAAT,eAA/B,CAA4DC,CAA5D,CAAqE,CAAEa,QAAS+H,CAAO/H,CAAAA,OAAlB,CAArE,CADP,CAFoB,CAOtBsO,mBAAa,CAACnP,CAAD,CAAU,CAC5B,IAAIoN;AAAS,IACb,IAAIpN,CAAQ3B,CAAAA,IAAKU,CAAAA,MAAjB,CAA0B,CAA1B,EAA+BiB,CAAQ3B,CAAAA,IAAKU,CAAAA,MAA5C,CAAqD,GAArD,CAA0D,KAAU8C,MAAJ,CAAU,iDAAV,CAAN,CAC1D,MAAOuL,EAAOjI,CAAAA,eAAP,CAAuB,KAAM,EAAN,EACtB,MAAMN,EAAWvD,CAAAA,IAAX,CAAgB8L,CAAOtK,CAAAA,KAAvB,CAA+B,GAAEsK,CAAOrN,CAAAA,GAAT,gBAA/B,CAA6DC,CAA7D,CAAsE,CAAEa,QAASuM,CAAOvM,CAAAA,OAAlB,CAAtE,CADgB,EACsF,EAD7G,CAHqB,CA3CV,CA2DhBuO,GAAAA,CAAkB,aAActK,GAAd,CAErBhH,WAAW,CAACiC,CAAD,CAAMc,CAAA,CAAU,EAAhB,CAAoBkE,CAApB,CAA6B,CACjCqH,CAAAA,CAAWrM,CAAIyD,CAAAA,OAAJ,CAAY,KAAZ,CAAmB,EAAnB,CACX8I,EAAAA,CAAezN,CAAA,CAAeA,CAAA,CAAe,EAAf,CAAmBiN,EAAnB,CAAf,CAAoD,EAApD,CAAwD,CAAE,eAAgB,kBAAlB,CAAxD,CAAgGjL,CAAhG,CACrB,MAAA,CAAMuL,CAAN,CAAgBE,CAAhB,CAA8BvH,CAA9B,CAAuC,SAAvC,CAHuC,CAMlC4H,kBAAY,CAAC4B,CAAD,CAAmB,CACpC,IAAIlJ,EAAQ,IACZ,OAAOA,EAAMF,CAAAA,eAAN,CAAsB,KAAM,EAAN,EACrB,MAAMN,EAAWvD,CAAAA,IAAX,CAAgB+D,CAAMvC,CAAAA,KAAtB,CAA8B,GAAEuC,CAAMtF,CAAAA,GAAR,qBAA9B,CAAgE,CAAEwO,iBAAAA,CAAF,CAAhE,CAAsF,CAAE1N,QAASwE,CAAMxE,CAAAA,OAAjB,CAAtF,CADe;AACsG,EAD5H,CAF6B,CAO/B4L,eAAS,CAAC8B,CAAD,CAAmB,CACjC,IAAI7B,EAAS,IACb,OAAOA,EAAOvH,CAAAA,eAAP,CAAuB,KAAM,EAAN,EACtB,MAAMN,EAAWvD,CAAAA,IAAX,CAAgBoL,CAAO5J,CAAAA,KAAvB,CAA+B,GAAE4J,CAAO3M,CAAAA,GAAT,kBAA/B,CAA+D,CAAEwO,iBAAAA,CAAF,CAA/D,CAAqF,CAAE1N,QAAS6L,CAAO7L,CAAAA,OAAlB,CAArF,CADP,CAF0B,CAO5B0L,iBAAW,CAACvM,CAAA,CAAU,EAAX,CAAe,CAC/B,IAAIsI,EAAS,IACb,OAAOA,EAAOnD,CAAAA,eAAP,CAAuB,KAAM,EAAN,EACtB,MAAMN,EAAWvD,CAAAA,IAAX,CAAgBgH,CAAOxF,CAAAA,KAAvB,CAA+B,GAAEwF,CAAOvI,CAAAA,GAAT,oBAA/B,CAAiEC,CAAjE,CAA0E,CAAEa,QAASyH,CAAOzH,CAAAA,OAAlB,CAA1E,CADP,CAFwB,CAO1BwM,kBAAY,CAACkB,CAAD,CAAmB,CACpC,IAAI3F,EAAS,IACb,OAAOA,EAAOzD,CAAAA,eAAP,CAAuB,KAAM,EAAN,EACtB,MAAMN,EAAWvD,CAAAA,IAAX,CAAgBsH,CAAO9F,CAAAA,KAAvB,CAA+B,GAAE8F,CAAO7I,CAAAA,GAAT,qBAA/B,CAAkE,CAAEwO,iBAAAA,CAAF,CAAlE,CAAwF,CAAE1N,QAAS+H,CAAO/H,CAAAA,OAAlB,CAAxF,CADgB,EACwG,EAD/H,CAF6B,CA7BhB,CAiFtB,KAAIwO,GAAuB,aAAcD,GAAd,CAkB1BtR,WAAW,CAACiC,CAAD;AAAMC,CAAA,CAAU,EAAhB,CAAoB,CAC9B,KAAA,CAAMD,CAAN,CAAWC,CAAQa,CAAAA,OAAnB,EAA8B,EAA9B,CAAkCb,CAAQ8C,CAAAA,KAA1C,CAD8B,CAqB/ByI,IAAI,CAACgD,CAAD,CAAmB,CACtB,MAAO,KAAIe,CAAJ,CAAsB,IAAKvP,CAAAA,GAA3B,CAAgC,IAAKc,CAAAA,OAArC,CAA8C0N,CAA9C,CAAgE,IAAKzL,CAAAA,KAArE,CADe,CAwBjB6J,kBAAY,CAAC4B,CAAD,CAAmB,CAEpC,MADiCgB,CAAA,EAAAA,EAAM5C,KAAMA,CAAAA,YAAZ4C,CAC1B,EAA6BpQ,CAAAA,IAA7B,CAD4DkG,IAC5D,CAAyCkJ,CAAzC,CAF6B,CA0B/B9B,eAAS,CAAC8B,CAAD,CAAmB,CAEjC,MAD8BiB,CAAA,EAAAA,EAAM/C,KAAMA,CAAAA,SAAZ+C,CACvB,EAA0BrQ,CAAAA,IAA1B,CADuDuN,IACvD,CAAuC6B,CAAvC,CAF0B,CA4B5BhC,iBAAW,CAACvM,CAAA,CAAU,EAAX,CAAe,CAE/B,MADgCyP,CAAA,EAAAA,EAAMlD,KAAMA,CAAAA,WAAZkD,CACzB,EAA4BtQ,CAAAA,IAA5B,CAD2DmJ,IAC3D,CAAyCtI,CAAzC,CAFwB,CAyB1BqN,kBAAY,CAACkB,CAAD,CAAmB,CAEpC,MADiCmB,CAAA,EAAAA,EAAMrC,KAAMA,CAAAA,YAAZqC,CAC1B,EAA6BvQ,CAAAA,IAA7B,CAD6DyJ,IAC7D,CAA0C2F,CAA1C,CAF6B,CA9IX,CAA3B,CA4JIe,EAAoB,aAAclB,EAAd,CAcvBtQ,WAAW,CAACiC,CAAD,CAAMc,CAAN,CAAe0N,CAAf,CAAiCxJ,CAAjC,CAA0C,CACpD,KAAA,CAAMhF,CAAN,CAAWc,CAAX,CAAoBkE,CAApB,CACA,KAAKwJ,CAAAA,gBAAL,CAAwBA,CAF4B,CA+B/CF,iBAAW,CAACrO,CAAD,CAAU,CAE1B,MADgC2P,CAAA,EAAAA,EAAMtB,KAAMA,CAAAA,WAAZsB,CACzB,EAA4BxQ,CAAAA,IAA5B,CAD2DiO,IAC3D;AAAyCvO,CAAA,CAAeA,CAAA,CAAe,EAAf,CAAmBmB,CAAnB,CAAf,CAA4C,EAA5C,CAAgD,CAAEuO,iBADhCnB,IACyDmB,CAAAA,gBAA3B,CAAhD,CAAzC,CAFmB,CAuBrBE,iBAAW,CAACzO,CAAA,CAAU,EAAX,CAAe,CAE/B,MADgC4P,CAAA,EAAAA,EAAMnB,KAAMA,CAAAA,WAAZmB,CACzB,EAA4BzQ,CAAAA,IAA5B,CAD2D+J,IAC3D,CAAyCrK,CAAA,CAAeA,CAAA,CAAe,EAAf,CAAmBmB,CAAnB,CAAf,CAA4C,EAA5C,CAAgD,CAAEuO,iBADhCrF,IACyDqF,CAAAA,gBAA3B,CAAhD,CAAzC,CAFwB,CAwB1BD,cAAQ,CAACE,CAAD,CAAY,CAEzB,MAD6BqB,CAAA,EAAAA,EAAMvB,KAAMA,CAAAA,QAAZuB,CACtB,EAAyB1Q,CAAAA,IAAzB,CADqDoK,IACrD,CADqDA,IACRgF,CAAAA,gBAA7C,CAA+DC,CAA/D,CAFkB,CAuBpBE,iBAAW,CAACF,CAAD,CAAY,CAE5B,MADgCsB,CAAA,EAAAA,EAAMpB,KAAMA,CAAAA,WAAZoB,CACzB,EAA4B3Q,CAAAA,IAA5B,CAD2DuK,IAC3D,CAD2DA,IACX6E,CAAAA,gBAAhD,CAAkEC,CAAlE,CAFqB,CAmC7BuB,KAAK,CAACvB,CAAD,CAAY,CAChB,MAAO,KAAIwB,CAAJ,CAAqB,IAAKjQ,CAAAA,GAA1B,CAA+B,IAAKc,CAAAA,OAApC,CAA6C,IAAK0N,CAAAA,gBAAlD,CAAoEC,CAApE,CAA+E,IAAK1L,CAAAA,KAApF,CADS,CAtJM,CA5JxB,CA+TIkN,EAAmB,aAAcrB,GAAd,CAetB7Q,WAAW,CAACiC,CAAD,CAAMc,CAAN,CAAe0N,CAAf,CAAiCC,CAAjC,CAA4CzJ,EAA5C,CAAqD,CAC/D,KAAA,CAAMhF,CAAN,CAAWc,CAAX,CAAoBkE,EAApB,CACA,KAAKwJ,CAAAA,gBAAL;AAAwBA,CACxB,KAAKC,CAAAA,SAAL,CAAiBA,CAH8C,CAgC1DI,gBAAU,CAAC5O,CAAD,CAAU,CAEzB,MAD+BiQ,CAAA,EAAAA,EAAMrB,KAAMA,CAAAA,UAAZqB,CACxB,EAA2B9Q,CAAAA,IAA3B,CADyD+K,IACzD,CAAwCrL,CAAA,CAAeA,CAAA,CAAe,EAAf,CAAmBmB,CAAnB,CAAf,CAA4C,EAA5C,CAAgD,CAC9FuO,iBAF+DrE,IAEtCqE,CAAAA,gBADqE,CAE9FC,UAH+DtE,IAG7CsE,CAAAA,SAF4E,CAAhD,CAAxC,CAFkB,CA6BpBM,gBAAU,CAAC9O,CAAD,CAAU,CAEzB,MAD+BkQ,CAAA,EAAAA,EAAMpB,KAAMA,CAAAA,UAAZoB,CACxB,EAA2B/Q,CAAAA,IAA3B,CAD0DsL,IAC1D,CAAyC5L,CAAA,CAAeA,CAAA,CAAe,EAAf,CAAmBmB,CAAnB,CAAf,CAA4C,EAA5C,CAAgD,CAC/FuO,iBAFgE9D,IAEtC8D,CAAAA,gBADqE,CAE/FC,UAHgE/D,IAG7C+D,CAAAA,SAF4E,CAAhD,CAAzC,CAFkB,CA6BpBO,iBAAW,CAAC/O,CAAA,CAAU,EAAX,CAAe,CAE/B,MADgCmQ,CAAA,EAAAA,EAAMpB,KAAMA,CAAAA,WAAZoB,CACzB,EAA4BhR,CAAAA,IAA5B,CAD4DwL,IAC5D,CAA0C9L,CAAA,CAAeA,CAAA,CAAe,EAAf,CAAmBmB,CAAnB,CAAf,CAA4C,EAA5C,CAAgD,CAChGuO,iBAFkE5D,IAExC4D,CAAAA,gBADsE,CAEhGC,UAHkE7D,IAG/C6D,CAAAA,SAF6E,CAAhD,CAA1C,CAFwB,CAgC1BU,kBAAY,CAAClP,CAAD,CAAU,CAE3B,MADiCoQ,CAAA,EAAAA,EAAMlB,KAAMA,CAAAA,YAAZkB,CAC1B,EAA6BjR,CAAAA,IAA7B,CAD8D6L,IAC9D;AAA2CnM,CAAA,CAAeA,CAAA,CAAe,EAAf,CAAmBmB,CAAnB,CAAf,CAA4C,EAA5C,CAAgD,CACjGuO,iBAFoEvD,IAE1CuD,CAAAA,gBADuE,CAEjGC,UAHoExD,IAGjDwD,CAAAA,SAF8E,CAAhD,CAA3C,CAFoB,CA4BtBW,mBAAa,CAACnP,CAAD,CAAU,CAE5B,MADkCqQ,CAAA,EAAAA,EAAMlB,KAAMA,CAAAA,aAAZkB,CAC3B,EAA8BlR,CAAAA,IAA9B,CADgEgM,IAChE,CAA4CtM,CAAA,CAAeA,CAAA,CAAe,EAAf,CAAmBmB,CAAnB,CAAf,CAA4C,EAA5C,CAAgD,CAClGuO,iBAFsEpD,IAE5CoD,CAAAA,gBADwE,CAElGC,UAHsErD,IAGnDqD,CAAAA,SAF+E,CAAhD,CAA5C,CAFqB,CArKP,CAgLnB8B,GAAAA,CAAgB,aAAcvE,GAAd,CAenBjO,WAAW,CAACiC,CAAD,CAAMc,CAAA,CAAU,EAAhB,CAAoBkE,CAApB,CAA6BiH,CAA7B,CAAmC,CAC7C,KAAA,CAAMjM,CAAN,CAAWc,CAAX,CAAoBkE,CAApB,CAA6BiH,CAA7B,CAD6C,CAc9CT,IAAI,CAACxD,CAAD,CAAK,CACR,MAAO,KAAInB,CAAJ,CAAmB,IAAK7G,CAAAA,GAAxB,CAA6B,IAAKc,CAAAA,OAAlC,CAA2CkH,CAA3C,CAA+C,IAAKjF,CAAAA,KAApD,CADC,CAcL,WAAU,EAAA,CACb,MAAO,KAAIuM,EAAJ,CAAyB,IAAKtP,CAAAA,GAA9B,CAAoC,SAApC,CAA+C,CACrDc,QAAS,IAAKA,CAAAA,OADuC,CAErDiC,MAAO,IAAKA,CAAAA,KAFyC,CAA/C,CADM,CAiBV,aAAY,EAAA,CACf,MAAO,KAAI4K,EAAJ,CAA2B,IAAK3N,CAAAA,GAAhC,CAAsC,UAAtC,CAAkD,IAAKc,CAAAA,OAAvD,CAAgE,IAAKiC,CAAAA,KAArE,CADQ,CA5DG,CAkEpBxF;CAAQoQ,CAAAA,sBAAR,CAAiCA,EACjCpQ,EAAQ4E,CAAAA,eAAR,CAA0BA,CAC1B5E,EAAQgT,CAAAA,aAAR,CAAwBA,EACxBhT,EAAQsE,CAAAA,YAAR,CAAuBA,CACvBtE,EAAQ8E,CAAAA,mBAAR,CAA8BA,CAC9B9E,EAAQiF,CAAAA,sBAAR,CAAiCA,EACjCjF,EAAQ+R,CAAAA,oBAAR,CAA+BA,EAC/B/R,EAAQgF,CAAAA,mBAAR,CAA8BA,CAC9BhF,EAAQmF,CAAAA,uBAAR,CAAkCA,CAClCnF,EAAQkF,CAAAA,0BAAR,CAAqCA,CACrClF,EAAQ8R,CAAAA,eAAR,CAA0BA,EAC1B9R,EAAQgS,CAAAA,iBAAR,CAA4BA,CAC5BhS,EAAQqR,CAAAA,aAAR,CAAwBA,EACxBrR,EAAQ8Q,CAAAA,cAAR,CAAyBA,CACzB9Q,EAAQ0S,CAAAA,gBAAR,CAA2BA,CAC3B1S,EAAQC,CAAAA,cAAR,CAAyBA,CACzBD,EAAQiT,CAAAA,qBAAR,CAhiFAA,QAA8B,CAAC/S,CAAD,CAAQ,CACrC,MAAOD,EAAA,CAAeC,CAAf,CAAP,EAAgCA,CAAA,CAAA,SAAhC,GAAuD,SADlB,CAxEgB;\",\n\"sources\":[\"node_modules/@supabase/storage-js/dist/index.cjs\"],\n\"sourcesContent\":[\"shadow$provide[35] = function(require,module,exports) {\\nvar Buffer = require('buffer').Buffer;\\nlet iceberg_js = require(\\\"iceberg-js\\\");\\n\\n//#region src/lib/common/errors.ts\\n/**\\n* Base error class for all Storage errors\\n* Supports both 'storage' and 'vectors' namespaces\\n*/\\nvar StorageError = class extends Error {\\n\\tconstructor(message, namespace = \\\"storage\\\", status, statusCode) {\\n\\t\\tsuper(message);\\n\\t\\tthis.__isStorageError = true;\\n\\t\\tthis.namespace = namespace;\\n\\t\\tthis.name = namespace === \\\"vectors\\\" ? \\\"StorageVectorsError\\\" : \\\"StorageError\\\";\\n\\t\\tthis.status = status;\\n\\t\\tthis.statusCode = statusCode;\\n\\t}\\n};\\n/**\\n* Type guard to check if an error is a StorageError\\n* @param error - The error to check\\n* @returns True if the error is a StorageError\\n*/\\nfunction isStorageError(error) {\\n\\treturn typeof error === \\\"object\\\" && error !== null && \\\"__isStorageError\\\" in error;\\n}\\n/**\\n* API error returned from Storage service\\n* Includes HTTP status code and service-specific error code\\n*/\\nvar StorageApiError = class extends StorageError {\\n\\tconstructor(message, status, statusCode, namespace = \\\"storage\\\") {\\n\\t\\tsuper(message, namespace, status, statusCode);\\n\\t\\tthis.name = namespace === \\\"vectors\\\" ? \\\"StorageVectorsApiError\\\" : \\\"StorageApiError\\\";\\n\\t\\tthis.status = status;\\n\\t\\tthis.statusCode = statusCode;\\n\\t}\\n\\ttoJSON() {\\n\\t\\treturn {\\n\\t\\t\\tname: this.name,\\n\\t\\t\\tmessage: this.message,\\n\\t\\t\\tstatus: this.status,\\n\\t\\t\\tstatusCode: this.statusCode\\n\\t\\t};\\n\\t}\\n};\\n/**\\n* Unknown error that doesn't match expected error patterns\\n* Wraps the original error for debugging\\n*/\\nvar StorageUnknownError = class extends StorageError {\\n\\tconstructor(message, originalError, namespace = \\\"storage\\\") {\\n\\t\\tsuper(message, namespace);\\n\\t\\tthis.name = namespace === \\\"vectors\\\" ? \\\"StorageVectorsUnknownError\\\" : \\\"StorageUnknownError\\\";\\n\\t\\tthis.originalError = originalError;\\n\\t}\\n};\\n/**\\n* @deprecated Use StorageError with namespace='vectors' instead\\n* Alias for backward compatibility with existing vector storage code\\n*/\\nvar StorageVectorsError = class extends StorageError {\\n\\tconstructor(message) {\\n\\t\\tsuper(message, \\\"vectors\\\");\\n\\t}\\n};\\n/**\\n* Type guard to check if an error is a StorageVectorsError\\n* @param error - The error to check\\n* @returns True if the error is a StorageVectorsError\\n*/\\nfunction isStorageVectorsError(error) {\\n\\treturn isStorageError(error) && error[\\\"namespace\\\"] === \\\"vectors\\\";\\n}\\n/**\\n* @deprecated Use StorageApiError with namespace='vectors' instead\\n* Alias for backward compatibility with existing vector storage code\\n*/\\nvar StorageVectorsApiError = class extends StorageApiError {\\n\\tconstructor(message, status, statusCode) {\\n\\t\\tsuper(message, status, statusCode, \\\"vectors\\\");\\n\\t}\\n};\\n/**\\n* @deprecated Use StorageUnknownError with namespace='vectors' instead\\n* Alias for backward compatibility with existing vector storage code\\n*/\\nvar StorageVectorsUnknownError = class extends StorageUnknownError {\\n\\tconstructor(message, originalError) {\\n\\t\\tsuper(message, originalError, \\\"vectors\\\");\\n\\t}\\n};\\n/**\\n* Error codes specific to S3 Vectors API\\n* Maps AWS service errors to application-friendly error codes\\n*/\\nlet StorageVectorsErrorCode = /* @__PURE__ */ function(StorageVectorsErrorCode$1) {\\n\\t/** Internal server fault (HTTP 500) */\\n\\tStorageVectorsErrorCode$1[\\\"InternalError\\\"] = \\\"InternalError\\\";\\n\\t/** Resource already exists / conflict (HTTP 409) */\\n\\tStorageVectorsErrorCode$1[\\\"S3VectorConflictException\\\"] = \\\"S3VectorConflictException\\\";\\n\\t/** Resource not found (HTTP 404) */\\n\\tStorageVectorsErrorCode$1[\\\"S3VectorNotFoundException\\\"] = \\\"S3VectorNotFoundException\\\";\\n\\t/** Delete bucket while not empty (HTTP 400) */\\n\\tStorageVectorsErrorCode$1[\\\"S3VectorBucketNotEmpty\\\"] = \\\"S3VectorBucketNotEmpty\\\";\\n\\t/** Exceeds bucket quota/limit (HTTP 400) */\\n\\tStorageVectorsErrorCode$1[\\\"S3VectorMaxBucketsExceeded\\\"] = \\\"S3VectorMaxBucketsExceeded\\\";\\n\\t/** Exceeds index quota/limit (HTTP 400) */\\n\\tStorageVectorsErrorCode$1[\\\"S3VectorMaxIndexesExceeded\\\"] = \\\"S3VectorMaxIndexesExceeded\\\";\\n\\treturn StorageVectorsErrorCode$1;\\n}({});\\n\\n//#endregion\\n//#region src/lib/common/helpers.ts\\n/**\\n* Resolves the fetch implementation to use\\n* Uses custom fetch if provided, otherwise uses native fetch\\n*\\n* @param customFetch - Optional custom fetch implementation\\n* @returns Resolved fetch function\\n*/\\nconst resolveFetch = (customFetch) => {\\n\\tif (customFetch) return (...args) => customFetch(...args);\\n\\treturn (...args) => fetch(...args);\\n};\\n/**\\n* Determine if input is a plain object\\n* An object is plain if it's created by either {}, new Object(), or Object.create(null)\\n*\\n* @param value - Value to check\\n* @returns True if value is a plain object\\n* @source https://github.com/sindresorhus/is-plain-obj\\n*/\\nconst isPlainObject = (value) => {\\n\\tif (typeof value !== \\\"object\\\" || value === null) return false;\\n\\tconst prototype = Object.getPrototypeOf(value);\\n\\treturn (prototype === null || prototype === Object.prototype || Object.getPrototypeOf(prototype) === null) && !(Symbol.toStringTag in value) && !(Symbol.iterator in value);\\n};\\n/**\\n* Recursively converts object keys from snake_case to camelCase\\n* Used for normalizing API responses\\n*\\n* @param item - Object to convert\\n* @returns Converted object with camelCase keys\\n*/\\nconst recursiveToCamel = (item) => {\\n\\tif (Array.isArray(item)) return item.map((el) => recursiveToCamel(el));\\n\\telse if (typeof item === \\\"function\\\" || item !== Object(item)) return item;\\n\\tconst result = {};\\n\\tObject.entries(item).forEach(([key, value]) => {\\n\\t\\tconst newKey = key.replace(/([-_][a-z])/gi, (c) => c.toUpperCase().replace(/[-_]/g, \\\"\\\"));\\n\\t\\tresult[newKey] = recursiveToCamel(value);\\n\\t});\\n\\treturn result;\\n};\\n/**\\n* Validates if a given bucket name is valid according to Supabase Storage API rules\\n* Mirrors backend validation from: storage/src/storage/limits.ts:isValidBucketName()\\n*\\n* Rules:\\n* - Length: 1-100 characters\\n* - Allowed characters: alphanumeric (a-z, A-Z, 0-9), underscore (_), and safe special characters\\n* - Safe special characters: ! - . * ' ( ) space & $ @ = ; : + , ?\\n* - Forbidden: path separators (/, \\\\), path traversal (..), leading/trailing whitespace\\n*\\n* AWS S3 Reference: https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-keys.html\\n*\\n* @param bucketName - The bucket name to validate\\n* @returns true if valid, false otherwise\\n*/\\nconst isValidBucketName = (bucketName) => {\\n\\tif (!bucketName || typeof bucketName !== \\\"string\\\") return false;\\n\\tif (bucketName.length === 0 || bucketName.length > 100) return false;\\n\\tif (bucketName.trim() !== bucketName) return false;\\n\\tif (bucketName.includes(\\\"/\\\") || bucketName.includes(\\\"\\\\\\\\\\\")) return false;\\n\\treturn /^[\\\\w!.\\\\*'() &$@=;:+,?-]+$/.test(bucketName);\\n};\\n\\n//#endregion\\n//#region \\\\0@oxc-project+runtime@0.101.0/helpers/typeof.js\\nfunction _typeof(o) {\\n\\t\\\"@babel/helpers - typeof\\\";\\n\\treturn _typeof = \\\"function\\\" == typeof Symbol && \\\"symbol\\\" == typeof Symbol.iterator ? function(o$1) {\\n\\t\\treturn typeof o$1;\\n\\t} : function(o$1) {\\n\\t\\treturn o$1 && \\\"function\\\" == typeof Symbol && o$1.constructor === Symbol && o$1 !== Symbol.prototype ? \\\"symbol\\\" : typeof o$1;\\n\\t}, _typeof(o);\\n}\\n\\n//#endregion\\n//#region \\\\0@oxc-project+runtime@0.101.0/helpers/toPrimitive.js\\nfunction toPrimitive(t, r) {\\n\\tif (\\\"object\\\" != _typeof(t) || !t) return t;\\n\\tvar e = t[Symbol.toPrimitive];\\n\\tif (void 0 !== e) {\\n\\t\\tvar i = e.call(t, r || \\\"default\\\");\\n\\t\\tif (\\\"object\\\" != _typeof(i)) return i;\\n\\t\\tthrow new TypeError(\\\"@@toPrimitive must return a primitive value.\\\");\\n\\t}\\n\\treturn (\\\"string\\\" === r ? String : Number)(t);\\n}\\n\\n//#endregion\\n//#region \\\\0@oxc-project+runtime@0.101.0/helpers/toPropertyKey.js\\nfunction toPropertyKey(t) {\\n\\tvar i = toPrimitive(t, \\\"string\\\");\\n\\treturn \\\"symbol\\\" == _typeof(i) ? i : i + \\\"\\\";\\n}\\n\\n//#endregion\\n//#region \\\\0@oxc-project+runtime@0.101.0/helpers/defineProperty.js\\nfunction _defineProperty(e, r, t) {\\n\\treturn (r = toPropertyKey(r)) in e ? Object.defineProperty(e, r, {\\n\\t\\tvalue: t,\\n\\t\\tenumerable: !0,\\n\\t\\tconfigurable: !0,\\n\\t\\twritable: !0\\n\\t}) : e[r] = t, e;\\n}\\n\\n//#endregion\\n//#region \\\\0@oxc-project+runtime@0.101.0/helpers/objectSpread2.js\\nfunction ownKeys(e, r) {\\n\\tvar t = Object.keys(e);\\n\\tif (Object.getOwnPropertySymbols) {\\n\\t\\tvar o = Object.getOwnPropertySymbols(e);\\n\\t\\tr && (o = o.filter(function(r$1) {\\n\\t\\t\\treturn Object.getOwnPropertyDescriptor(e, r$1).enumerable;\\n\\t\\t})), t.push.apply(t, o);\\n\\t}\\n\\treturn t;\\n}\\nfunction _objectSpread2(e) {\\n\\tfor (var r = 1; r < arguments.length; r++) {\\n\\t\\tvar t = null != arguments[r] ? arguments[r] : {};\\n\\t\\tr % 2 ? ownKeys(Object(t), !0).forEach(function(r$1) {\\n\\t\\t\\t_defineProperty(e, r$1, t[r$1]);\\n\\t\\t}) : Object.getOwnPropertyDescriptors ? Object.defineProperties(e, Object.getOwnPropertyDescriptors(t)) : ownKeys(Object(t)).forEach(function(r$1) {\\n\\t\\t\\tObject.defineProperty(e, r$1, Object.getOwnPropertyDescriptor(t, r$1));\\n\\t\\t});\\n\\t}\\n\\treturn e;\\n}\\n\\n//#endregion\\n//#region src/lib/common/fetch.ts\\n/**\\n* Extracts error message from various error response formats\\n* @param err - Error object from API\\n* @returns Human-readable error message\\n*/\\nconst _getErrorMessage = (err) => {\\n\\tvar _err$error;\\n\\treturn err.msg || err.message || err.error_description || (typeof err.error === \\\"string\\\" ? err.error : (_err$error = err.error) === null || _err$error === void 0 ? void 0 : _err$error.message) || JSON.stringify(err);\\n};\\n/**\\n* Handles fetch errors and converts them to Storage error types\\n* @param error - The error caught from fetch\\n* @param reject - Promise rejection function\\n* @param options - Fetch options that may affect error handling\\n* @param namespace - Error namespace ('storage' or 'vectors')\\n*/\\nconst handleError = async (error, reject, options, namespace) => {\\n\\tif (error && typeof error === \\\"object\\\" && \\\"status\\\" in error && \\\"ok\\\" in error && typeof error.status === \\\"number\\\" && !(options === null || options === void 0 ? void 0 : options.noResolveJson)) {\\n\\t\\tconst responseError = error;\\n\\t\\tconst status = responseError.status || 500;\\n\\t\\tif (typeof responseError.json === \\\"function\\\") responseError.json().then((err) => {\\n\\t\\t\\tconst statusCode = (err === null || err === void 0 ? void 0 : err.statusCode) || (err === null || err === void 0 ? void 0 : err.code) || status + \\\"\\\";\\n\\t\\t\\treject(new StorageApiError(_getErrorMessage(err), status, statusCode, namespace));\\n\\t\\t}).catch(() => {\\n\\t\\t\\tif (namespace === \\\"vectors\\\") {\\n\\t\\t\\t\\tconst statusCode = status + \\\"\\\";\\n\\t\\t\\t\\treject(new StorageApiError(responseError.statusText || `HTTP ${status} error`, status, statusCode, namespace));\\n\\t\\t\\t} else {\\n\\t\\t\\t\\tconst statusCode = status + \\\"\\\";\\n\\t\\t\\t\\treject(new StorageApiError(responseError.statusText || `HTTP ${status} error`, status, statusCode, namespace));\\n\\t\\t\\t}\\n\\t\\t});\\n\\t\\telse {\\n\\t\\t\\tconst statusCode = status + \\\"\\\";\\n\\t\\t\\treject(new StorageApiError(responseError.statusText || `HTTP ${status} error`, status, statusCode, namespace));\\n\\t\\t}\\n\\t} else reject(new StorageUnknownError(_getErrorMessage(error), error, namespace));\\n};\\n/**\\n* Builds request parameters for fetch calls\\n* @param method - HTTP method\\n* @param options - Custom fetch options\\n* @param parameters - Additional fetch parameters like AbortSignal\\n* @param body - Request body (will be JSON stringified if plain object)\\n* @returns Complete fetch request parameters\\n*/\\nconst _getRequestParams = (method, options, parameters, body) => {\\n\\tconst params = {\\n\\t\\tmethod,\\n\\t\\theaders: (options === null || options === void 0 ? void 0 : options.headers) || {}\\n\\t};\\n\\tif (method === \\\"GET\\\" || method === \\\"HEAD\\\" || !body) return _objectSpread2(_objectSpread2({}, params), parameters);\\n\\tif (isPlainObject(body)) {\\n\\t\\tparams.headers = _objectSpread2({ \\\"Content-Type\\\": \\\"application/json\\\" }, options === null || options === void 0 ? void 0 : options.headers);\\n\\t\\tparams.body = JSON.stringify(body);\\n\\t} else params.body = body;\\n\\tif (options === null || options === void 0 ? void 0 : options.duplex) params.duplex = options.duplex;\\n\\treturn _objectSpread2(_objectSpread2({}, params), parameters);\\n};\\n/**\\n* Internal request handler that wraps fetch with error handling\\n* @param fetcher - Fetch function to use\\n* @param method - HTTP method\\n* @param url - Request URL\\n* @param options - Custom fetch options\\n* @param parameters - Additional fetch parameters\\n* @param body - Request body\\n* @param namespace - Error namespace ('storage' or 'vectors')\\n* @returns Promise with parsed response or error\\n*/\\nasync function _handleRequest(fetcher, method, url, options, parameters, body, namespace) {\\n\\treturn new Promise((resolve, reject) => {\\n\\t\\tfetcher(url, _getRequestParams(method, options, parameters, body)).then((result) => {\\n\\t\\t\\tif (!result.ok) throw result;\\n\\t\\t\\tif (options === null || options === void 0 ? void 0 : options.noResolveJson) return result;\\n\\t\\t\\tif (namespace === \\\"vectors\\\") {\\n\\t\\t\\t\\tconst contentType = result.headers.get(\\\"content-type\\\");\\n\\t\\t\\t\\tif (result.headers.get(\\\"content-length\\\") === \\\"0\\\" || result.status === 204) return {};\\n\\t\\t\\t\\tif (!contentType || !contentType.includes(\\\"application/json\\\")) return {};\\n\\t\\t\\t}\\n\\t\\t\\treturn result.json();\\n\\t\\t}).then((data) => resolve(data)).catch((error) => handleError(error, reject, options, namespace));\\n\\t});\\n}\\n/**\\n* Creates a fetch API with the specified namespace\\n* @param namespace - Error namespace ('storage' or 'vectors')\\n* @returns Object with HTTP method functions\\n*/\\nfunction createFetchApi(namespace = \\\"storage\\\") {\\n\\treturn {\\n\\t\\tget: async (fetcher, url, options, parameters) => {\\n\\t\\t\\treturn _handleRequest(fetcher, \\\"GET\\\", url, options, parameters, void 0, namespace);\\n\\t\\t},\\n\\t\\tpost: async (fetcher, url, body, options, parameters) => {\\n\\t\\t\\treturn _handleRequest(fetcher, \\\"POST\\\", url, options, parameters, body, namespace);\\n\\t\\t},\\n\\t\\tput: async (fetcher, url, body, options, parameters) => {\\n\\t\\t\\treturn _handleRequest(fetcher, \\\"PUT\\\", url, options, parameters, body, namespace);\\n\\t\\t},\\n\\t\\thead: async (fetcher, url, options, parameters) => {\\n\\t\\t\\treturn _handleRequest(fetcher, \\\"HEAD\\\", url, _objectSpread2(_objectSpread2({}, options), {}, { noResolveJson: true }), parameters, void 0, namespace);\\n\\t\\t},\\n\\t\\tremove: async (fetcher, url, body, options, parameters) => {\\n\\t\\t\\treturn _handleRequest(fetcher, \\\"DELETE\\\", url, options, parameters, body, namespace);\\n\\t\\t}\\n\\t};\\n}\\nconst defaultApi = createFetchApi(\\\"storage\\\");\\nconst { get, post, put, head, remove } = defaultApi;\\nconst vectorsApi = createFetchApi(\\\"vectors\\\");\\n\\n//#endregion\\n//#region src/lib/common/BaseApiClient.ts\\n/**\\n* @ignore\\n* Base API client class for all Storage API classes\\n* Provides common infrastructure for error handling and configuration\\n*\\n* @typeParam TError - The error type (StorageError or subclass)\\n*/\\nvar BaseApiClient = class {\\n\\t/**\\n\\t* Creates a new BaseApiClient instance\\n\\t* @param url - Base URL for API requests\\n\\t* @param headers - Default headers for API requests\\n\\t* @param fetch - Optional custom fetch implementation\\n\\t* @param namespace - Error namespace ('storage' or 'vectors')\\n\\t*/\\n\\tconstructor(url, headers = {}, fetch$1, namespace = \\\"storage\\\") {\\n\\t\\tthis.shouldThrowOnError = false;\\n\\t\\tthis.url = url;\\n\\t\\tthis.headers = headers;\\n\\t\\tthis.fetch = resolveFetch(fetch$1);\\n\\t\\tthis.namespace = namespace;\\n\\t}\\n\\t/**\\n\\t* Enable throwing errors instead of returning them.\\n\\t* When enabled, errors are thrown instead of returned in { data, error } format.\\n\\t*\\n\\t* @returns this - For method chaining\\n\\t*/\\n\\tthrowOnError() {\\n\\t\\tthis.shouldThrowOnError = true;\\n\\t\\treturn this;\\n\\t}\\n\\t/**\\n\\t* Set an HTTP header for the request.\\n\\t* Creates a shallow copy of headers to avoid mutating shared state.\\n\\t*\\n\\t* @param name - Header name\\n\\t* @param value - Header value\\n\\t* @returns this - For method chaining\\n\\t*/\\n\\tsetHeader(name, value) {\\n\\t\\tthis.headers = _objectSpread2(_objectSpread2({}, this.headers), {}, { [name]: value });\\n\\t\\treturn this;\\n\\t}\\n\\t/**\\n\\t* Handles API operation with standardized error handling\\n\\t* Eliminates repetitive try-catch blocks across all API methods\\n\\t*\\n\\t* This wrapper:\\n\\t* 1. Executes the operation\\n\\t* 2. Returns { data, error: null } on success\\n\\t* 3. Returns { data: null, error } on failure (if shouldThrowOnError is false)\\n\\t* 4. Throws error on failure (if shouldThrowOnError is true)\\n\\t*\\n\\t* @typeParam T - The expected data type from the operation\\n\\t* @param operation - Async function that performs the API call\\n\\t* @returns Promise with { data, error } tuple\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* async listBuckets() {\\n\\t*   return this.handleOperation(async () => {\\n\\t*     return await get(this.fetch, `${this.url}/bucket`, {\\n\\t*       headers: this.headers,\\n\\t*     })\\n\\t*   })\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync handleOperation(operation) {\\n\\t\\tvar _this = this;\\n\\t\\ttry {\\n\\t\\t\\treturn {\\n\\t\\t\\t\\tdata: await operation(),\\n\\t\\t\\t\\terror: null\\n\\t\\t\\t};\\n\\t\\t} catch (error) {\\n\\t\\t\\tif (_this.shouldThrowOnError) throw error;\\n\\t\\t\\tif (isStorageError(error)) return {\\n\\t\\t\\t\\tdata: null,\\n\\t\\t\\t\\terror\\n\\t\\t\\t};\\n\\t\\t\\tthrow error;\\n\\t\\t}\\n\\t}\\n};\\n\\n//#endregion\\n//#region src/packages/StreamDownloadBuilder.ts\\nvar StreamDownloadBuilder = class {\\n\\tconstructor(downloadFn, shouldThrowOnError) {\\n\\t\\tthis.downloadFn = downloadFn;\\n\\t\\tthis.shouldThrowOnError = shouldThrowOnError;\\n\\t}\\n\\tthen(onfulfilled, onrejected) {\\n\\t\\treturn this.execute().then(onfulfilled, onrejected);\\n\\t}\\n\\tasync execute() {\\n\\t\\tvar _this = this;\\n\\t\\ttry {\\n\\t\\t\\treturn {\\n\\t\\t\\t\\tdata: (await _this.downloadFn()).body,\\n\\t\\t\\t\\terror: null\\n\\t\\t\\t};\\n\\t\\t} catch (error) {\\n\\t\\t\\tif (_this.shouldThrowOnError) throw error;\\n\\t\\t\\tif (isStorageError(error)) return {\\n\\t\\t\\t\\tdata: null,\\n\\t\\t\\t\\terror\\n\\t\\t\\t};\\n\\t\\t\\tthrow error;\\n\\t\\t}\\n\\t}\\n};\\n\\n//#endregion\\n//#region src/packages/BlobDownloadBuilder.ts\\nlet _Symbol$toStringTag;\\n_Symbol$toStringTag = Symbol.toStringTag;\\nvar BlobDownloadBuilder = class {\\n\\tconstructor(downloadFn, shouldThrowOnError) {\\n\\t\\tthis.downloadFn = downloadFn;\\n\\t\\tthis.shouldThrowOnError = shouldThrowOnError;\\n\\t\\tthis[_Symbol$toStringTag] = \\\"BlobDownloadBuilder\\\";\\n\\t\\tthis.promise = null;\\n\\t}\\n\\tasStream() {\\n\\t\\treturn new StreamDownloadBuilder(this.downloadFn, this.shouldThrowOnError);\\n\\t}\\n\\tthen(onfulfilled, onrejected) {\\n\\t\\treturn this.getPromise().then(onfulfilled, onrejected);\\n\\t}\\n\\tcatch(onrejected) {\\n\\t\\treturn this.getPromise().catch(onrejected);\\n\\t}\\n\\tfinally(onfinally) {\\n\\t\\treturn this.getPromise().finally(onfinally);\\n\\t}\\n\\tgetPromise() {\\n\\t\\tif (!this.promise) this.promise = this.execute();\\n\\t\\treturn this.promise;\\n\\t}\\n\\tasync execute() {\\n\\t\\tvar _this = this;\\n\\t\\ttry {\\n\\t\\t\\treturn {\\n\\t\\t\\t\\tdata: await (await _this.downloadFn()).blob(),\\n\\t\\t\\t\\terror: null\\n\\t\\t\\t};\\n\\t\\t} catch (error) {\\n\\t\\t\\tif (_this.shouldThrowOnError) throw error;\\n\\t\\t\\tif (isStorageError(error)) return {\\n\\t\\t\\t\\tdata: null,\\n\\t\\t\\t\\terror\\n\\t\\t\\t};\\n\\t\\t\\tthrow error;\\n\\t\\t}\\n\\t}\\n};\\n\\n//#endregion\\n//#region src/packages/StorageFileApi.ts\\nconst DEFAULT_SEARCH_OPTIONS = {\\n\\tlimit: 100,\\n\\toffset: 0,\\n\\tsortBy: {\\n\\t\\tcolumn: \\\"name\\\",\\n\\t\\torder: \\\"asc\\\"\\n\\t}\\n};\\nconst DEFAULT_FILE_OPTIONS = {\\n\\tcacheControl: \\\"3600\\\",\\n\\tcontentType: \\\"text/plain;charset=UTF-8\\\",\\n\\tupsert: false\\n};\\nvar StorageFileApi = class extends BaseApiClient {\\n\\tconstructor(url, headers = {}, bucketId, fetch$1) {\\n\\t\\tsuper(url, headers, fetch$1, \\\"storage\\\");\\n\\t\\tthis.bucketId = bucketId;\\n\\t}\\n\\t/**\\n\\t* Uploads a file to an existing bucket or replaces an existing file at the specified path with a new one.\\n\\t*\\n\\t* @param method HTTP method.\\n\\t* @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\\n\\t* @param fileBody The body of the file to be stored in the bucket.\\n\\t*/\\n\\tasync uploadOrUpdate(method, path, fileBody, fileOptions) {\\n\\t\\tvar _this = this;\\n\\t\\treturn _this.handleOperation(async () => {\\n\\t\\t\\tlet body;\\n\\t\\t\\tconst options = _objectSpread2(_objectSpread2({}, DEFAULT_FILE_OPTIONS), fileOptions);\\n\\t\\t\\tlet headers = _objectSpread2(_objectSpread2({}, _this.headers), method === \\\"POST\\\" && { \\\"x-upsert\\\": String(options.upsert) });\\n\\t\\t\\tconst metadata = options.metadata;\\n\\t\\t\\tif (typeof Blob !== \\\"undefined\\\" && fileBody instanceof Blob) {\\n\\t\\t\\t\\tbody = new FormData();\\n\\t\\t\\t\\tbody.append(\\\"cacheControl\\\", options.cacheControl);\\n\\t\\t\\t\\tif (metadata) body.append(\\\"metadata\\\", _this.encodeMetadata(metadata));\\n\\t\\t\\t\\tbody.append(\\\"\\\", fileBody);\\n\\t\\t\\t} else if (typeof FormData !== \\\"undefined\\\" && fileBody instanceof FormData) {\\n\\t\\t\\t\\tbody = fileBody;\\n\\t\\t\\t\\tif (!body.has(\\\"cacheControl\\\")) body.append(\\\"cacheControl\\\", options.cacheControl);\\n\\t\\t\\t\\tif (metadata && !body.has(\\\"metadata\\\")) body.append(\\\"metadata\\\", _this.encodeMetadata(metadata));\\n\\t\\t\\t} else {\\n\\t\\t\\t\\tbody = fileBody;\\n\\t\\t\\t\\theaders[\\\"cache-control\\\"] = `max-age=${options.cacheControl}`;\\n\\t\\t\\t\\theaders[\\\"content-type\\\"] = options.contentType;\\n\\t\\t\\t\\tif (metadata) headers[\\\"x-metadata\\\"] = _this.toBase64(_this.encodeMetadata(metadata));\\n\\t\\t\\t\\tif ((typeof ReadableStream !== \\\"undefined\\\" && body instanceof ReadableStream || body && typeof body === \\\"object\\\" && \\\"pipe\\\" in body && typeof body.pipe === \\\"function\\\") && !options.duplex) options.duplex = \\\"half\\\";\\n\\t\\t\\t}\\n\\t\\t\\tif (fileOptions === null || fileOptions === void 0 ? void 0 : fileOptions.headers) headers = _objectSpread2(_objectSpread2({}, headers), fileOptions.headers);\\n\\t\\t\\tconst cleanPath = _this._removeEmptyFolders(path);\\n\\t\\t\\tconst _path = _this._getFinalPath(cleanPath);\\n\\t\\t\\tconst data = await (method == \\\"PUT\\\" ? put : post)(_this.fetch, `${_this.url}/object/${_path}`, body, _objectSpread2({ headers }, (options === null || options === void 0 ? void 0 : options.duplex) ? { duplex: options.duplex } : {}));\\n\\t\\t\\treturn {\\n\\t\\t\\t\\tpath: cleanPath,\\n\\t\\t\\t\\tid: data.Id,\\n\\t\\t\\t\\tfullPath: data.Key\\n\\t\\t\\t};\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Uploads a file to an existing bucket.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\\n\\t* @param fileBody The body of the file to be stored in the bucket.\\n\\t* @param fileOptions Optional file upload options including cacheControl, contentType, upsert, and metadata.\\n\\t* @returns Promise with response containing file path, id, and fullPath or error\\n\\t*\\n\\t* @example Upload file\\n\\t* ```js\\n\\t* const avatarFile = event.target.files[0]\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .upload('public/avatar1.png', avatarFile, {\\n\\t*     cacheControl: '3600',\\n\\t*     upsert: false\\n\\t*   })\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"path\\\": \\\"public/avatar1.png\\\",\\n\\t*     \\\"fullPath\\\": \\\"avatars/public/avatar1.png\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*\\n\\t* @example Upload file using `ArrayBuffer` from base64 file data\\n\\t* ```js\\n\\t* import { decode } from 'base64-arraybuffer'\\n\\t*\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .upload('public/avatar1.png', decode('base64FileData'), {\\n\\t*     contentType: 'image/png'\\n\\t*   })\\n\\t* ```\\n\\t*/\\n\\tasync upload(path, fileBody, fileOptions) {\\n\\t\\treturn this.uploadOrUpdate(\\\"POST\\\", path, fileBody, fileOptions);\\n\\t}\\n\\t/**\\n\\t* Upload a file with a token generated from `createSignedUploadUrl`.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\\n\\t* @param token The token generated from `createSignedUploadUrl`\\n\\t* @param fileBody The body of the file to be stored in the bucket.\\n\\t* @param fileOptions HTTP headers (cacheControl, contentType, etc.).\\n\\t* **Note:** The `upsert` option has no effect here. To enable upsert behavior,\\n\\t* pass `{ upsert: true }` when calling `createSignedUploadUrl()` instead.\\n\\t* @returns Promise with response containing file path and fullPath or error\\n\\t*\\n\\t* @example Upload to a signed URL\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .uploadToSignedUrl('folder/cat.jpg', 'token-from-createSignedUploadUrl', file)\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"path\\\": \\\"folder/cat.jpg\\\",\\n\\t*     \\\"fullPath\\\": \\\"avatars/folder/cat.jpg\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync uploadToSignedUrl(path, token, fileBody, fileOptions) {\\n\\t\\tvar _this3 = this;\\n\\t\\tconst cleanPath = _this3._removeEmptyFolders(path);\\n\\t\\tconst _path = _this3._getFinalPath(cleanPath);\\n\\t\\tconst url = new URL(_this3.url + `/object/upload/sign/${_path}`);\\n\\t\\turl.searchParams.set(\\\"token\\\", token);\\n\\t\\treturn _this3.handleOperation(async () => {\\n\\t\\t\\tlet body;\\n\\t\\t\\tconst options = _objectSpread2({ upsert: DEFAULT_FILE_OPTIONS.upsert }, fileOptions);\\n\\t\\t\\tconst headers = _objectSpread2(_objectSpread2({}, _this3.headers), { \\\"x-upsert\\\": String(options.upsert) });\\n\\t\\t\\tif (typeof Blob !== \\\"undefined\\\" && fileBody instanceof Blob) {\\n\\t\\t\\t\\tbody = new FormData();\\n\\t\\t\\t\\tbody.append(\\\"cacheControl\\\", options.cacheControl);\\n\\t\\t\\t\\tbody.append(\\\"\\\", fileBody);\\n\\t\\t\\t} else if (typeof FormData !== \\\"undefined\\\" && fileBody instanceof FormData) {\\n\\t\\t\\t\\tbody = fileBody;\\n\\t\\t\\t\\tbody.append(\\\"cacheControl\\\", options.cacheControl);\\n\\t\\t\\t} else {\\n\\t\\t\\t\\tbody = fileBody;\\n\\t\\t\\t\\theaders[\\\"cache-control\\\"] = `max-age=${options.cacheControl}`;\\n\\t\\t\\t\\theaders[\\\"content-type\\\"] = options.contentType;\\n\\t\\t\\t}\\n\\t\\t\\treturn {\\n\\t\\t\\t\\tpath: cleanPath,\\n\\t\\t\\t\\tfullPath: (await put(_this3.fetch, url.toString(), body, { headers })).Key\\n\\t\\t\\t};\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Creates a signed upload URL.\\n\\t* Signed upload URLs can be used to upload files to the bucket without further authentication.\\n\\t* They are valid for 2 hours.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param path The file path, including the current file name. For example `folder/image.png`.\\n\\t* @param options.upsert If set to true, allows the file to be overwritten if it already exists.\\n\\t* @returns Promise with response containing signed upload URL, token, and path or error\\n\\t*\\n\\t* @example Create Signed Upload URL\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .createSignedUploadUrl('folder/cat.jpg')\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"signedUrl\\\": \\\"https://example.supabase.co/storage/v1/object/upload/sign/avatars/folder/cat.jpg?token=<TOKEN>\\\",\\n\\t*     \\\"path\\\": \\\"folder/cat.jpg\\\",\\n\\t*     \\\"token\\\": \\\"<TOKEN>\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync createSignedUploadUrl(path, options) {\\n\\t\\tvar _this4 = this;\\n\\t\\treturn _this4.handleOperation(async () => {\\n\\t\\t\\tlet _path = _this4._getFinalPath(path);\\n\\t\\t\\tconst headers = _objectSpread2({}, _this4.headers);\\n\\t\\t\\tif (options === null || options === void 0 ? void 0 : options.upsert) headers[\\\"x-upsert\\\"] = \\\"true\\\";\\n\\t\\t\\tconst data = await post(_this4.fetch, `${_this4.url}/object/upload/sign/${_path}`, {}, { headers });\\n\\t\\t\\tconst url = new URL(_this4.url + data.url);\\n\\t\\t\\tconst token = url.searchParams.get(\\\"token\\\");\\n\\t\\t\\tif (!token) throw new StorageError(\\\"No token returned by API\\\");\\n\\t\\t\\treturn {\\n\\t\\t\\t\\tsignedUrl: url.toString(),\\n\\t\\t\\t\\tpath,\\n\\t\\t\\t\\ttoken\\n\\t\\t\\t};\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Replaces an existing file at the specified path with a new one.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to update.\\n\\t* @param fileBody The body of the file to be stored in the bucket.\\n\\t* @param fileOptions Optional file upload options including cacheControl, contentType, upsert, and metadata.\\n\\t* @returns Promise with response containing file path, id, and fullPath or error\\n\\t*\\n\\t* @example Update file\\n\\t* ```js\\n\\t* const avatarFile = event.target.files[0]\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .update('public/avatar1.png', avatarFile, {\\n\\t*     cacheControl: '3600',\\n\\t*     upsert: true\\n\\t*   })\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"path\\\": \\\"public/avatar1.png\\\",\\n\\t*     \\\"fullPath\\\": \\\"avatars/public/avatar1.png\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*\\n\\t* @example Update file using `ArrayBuffer` from base64 file data\\n\\t* ```js\\n\\t* import {decode} from 'base64-arraybuffer'\\n\\t*\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .update('public/avatar1.png', decode('base64FileData'), {\\n\\t*     contentType: 'image/png'\\n\\t*   })\\n\\t* ```\\n\\t*/\\n\\tasync update(path, fileBody, fileOptions) {\\n\\t\\treturn this.uploadOrUpdate(\\\"PUT\\\", path, fileBody, fileOptions);\\n\\t}\\n\\t/**\\n\\t* Moves an existing file to a new path in the same bucket.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param fromPath The original file path, including the current file name. For example `folder/image.png`.\\n\\t* @param toPath The new file path, including the new file name. For example `folder/image-new.png`.\\n\\t* @param options The destination options.\\n\\t* @returns Promise with response containing success message or error\\n\\t*\\n\\t* @example Move file\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .move('public/avatar1.png', 'private/avatar2.png')\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"message\\\": \\\"Successfully moved\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync move(fromPath, toPath, options) {\\n\\t\\tvar _this6 = this;\\n\\t\\treturn _this6.handleOperation(async () => {\\n\\t\\t\\treturn await post(_this6.fetch, `${_this6.url}/object/move`, {\\n\\t\\t\\t\\tbucketId: _this6.bucketId,\\n\\t\\t\\t\\tsourceKey: fromPath,\\n\\t\\t\\t\\tdestinationKey: toPath,\\n\\t\\t\\t\\tdestinationBucket: options === null || options === void 0 ? void 0 : options.destinationBucket\\n\\t\\t\\t}, { headers: _this6.headers });\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Copies an existing file to a new path in the same bucket.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param fromPath The original file path, including the current file name. For example `folder/image.png`.\\n\\t* @param toPath The new file path, including the new file name. For example `folder/image-copy.png`.\\n\\t* @param options The destination options.\\n\\t* @returns Promise with response containing copied file path or error\\n\\t*\\n\\t* @example Copy file\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .copy('public/avatar1.png', 'private/avatar2.png')\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"path\\\": \\\"avatars/private/avatar2.png\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync copy(fromPath, toPath, options) {\\n\\t\\tvar _this7 = this;\\n\\t\\treturn _this7.handleOperation(async () => {\\n\\t\\t\\treturn { path: (await post(_this7.fetch, `${_this7.url}/object/copy`, {\\n\\t\\t\\t\\tbucketId: _this7.bucketId,\\n\\t\\t\\t\\tsourceKey: fromPath,\\n\\t\\t\\t\\tdestinationKey: toPath,\\n\\t\\t\\t\\tdestinationBucket: options === null || options === void 0 ? void 0 : options.destinationBucket\\n\\t\\t\\t}, { headers: _this7.headers })).Key };\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Creates a signed URL. Use a signed URL to share a file for a fixed amount of time.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param path The file path, including the current file name. For example `folder/image.png`.\\n\\t* @param expiresIn The number of seconds until the signed URL expires. For example, `60` for a URL which is valid for one minute.\\n\\t* @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\\n\\t* @param options.transform Transform the asset before serving it to the client.\\n\\t* @returns Promise with response containing signed URL or error\\n\\t*\\n\\t* @example Create Signed URL\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .createSignedUrl('folder/avatar1.png', 60)\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"signedUrl\\\": \\\"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*\\n\\t* @example Create a signed URL for an asset with transformations\\n\\t* ```js\\n\\t* const { data } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .createSignedUrl('folder/avatar1.png', 60, {\\n\\t*     transform: {\\n\\t*       width: 100,\\n\\t*       height: 100,\\n\\t*     }\\n\\t*   })\\n\\t* ```\\n\\t*\\n\\t* @example Create a signed URL which triggers the download of the asset\\n\\t* ```js\\n\\t* const { data } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .createSignedUrl('folder/avatar1.png', 60, {\\n\\t*     download: true,\\n\\t*   })\\n\\t* ```\\n\\t*/\\n\\tasync createSignedUrl(path, expiresIn, options) {\\n\\t\\tvar _this8 = this;\\n\\t\\treturn _this8.handleOperation(async () => {\\n\\t\\t\\tlet _path = _this8._getFinalPath(path);\\n\\t\\t\\tlet data = await post(_this8.fetch, `${_this8.url}/object/sign/${_path}`, _objectSpread2({ expiresIn }, (options === null || options === void 0 ? void 0 : options.transform) ? { transform: options.transform } : {}), { headers: _this8.headers });\\n\\t\\t\\tconst downloadQueryParam = (options === null || options === void 0 ? void 0 : options.download) ? `&download=${options.download === true ? \\\"\\\" : options.download}` : \\\"\\\";\\n\\t\\t\\treturn { signedUrl: encodeURI(`${_this8.url}${data.signedURL}${downloadQueryParam}`) };\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Creates multiple signed URLs. Use a signed URL to share a file for a fixed amount of time.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param paths The file paths to be downloaded, including the current file names. For example `['folder/image.png', 'folder2/image2.png']`.\\n\\t* @param expiresIn The number of seconds until the signed URLs expire. For example, `60` for URLs which are valid for one minute.\\n\\t* @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\\n\\t* @returns Promise with response containing array of objects with signedUrl, path, and error or error\\n\\t*\\n\\t* @example Create Signed URLs\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .createSignedUrls(['folder/avatar1.png', 'folder/avatar2.png'], 60)\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": [\\n\\t*     {\\n\\t*       \\\"error\\\": null,\\n\\t*       \\\"path\\\": \\\"folder/avatar1.png\\\",\\n\\t*       \\\"signedURL\\\": \\\"/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\\\",\\n\\t*       \\\"signedUrl\\\": \\\"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\\\"\\n\\t*     },\\n\\t*     {\\n\\t*       \\\"error\\\": null,\\n\\t*       \\\"path\\\": \\\"folder/avatar2.png\\\",\\n\\t*       \\\"signedURL\\\": \\\"/object/sign/avatars/folder/avatar2.png?token=<TOKEN>\\\",\\n\\t*       \\\"signedUrl\\\": \\\"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar2.png?token=<TOKEN>\\\"\\n\\t*     }\\n\\t*   ],\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync createSignedUrls(paths, expiresIn, options) {\\n\\t\\tvar _this9 = this;\\n\\t\\treturn _this9.handleOperation(async () => {\\n\\t\\t\\tconst data = await post(_this9.fetch, `${_this9.url}/object/sign/${_this9.bucketId}`, {\\n\\t\\t\\t\\texpiresIn,\\n\\t\\t\\t\\tpaths\\n\\t\\t\\t}, { headers: _this9.headers });\\n\\t\\t\\tconst downloadQueryParam = (options === null || options === void 0 ? void 0 : options.download) ? `&download=${options.download === true ? \\\"\\\" : options.download}` : \\\"\\\";\\n\\t\\t\\treturn data.map((datum) => _objectSpread2(_objectSpread2({}, datum), {}, { signedUrl: datum.signedURL ? encodeURI(`${_this9.url}${datum.signedURL}${downloadQueryParam}`) : null }));\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Downloads a file from a private bucket. For public buckets, make a request to the URL returned from `getPublicUrl` instead.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param path The full path and file name of the file to be downloaded. For example `folder/image.png`.\\n\\t* @param options.transform Transform the asset before serving it to the client.\\n\\t* @param parameters Additional fetch parameters like signal for cancellation. Supports standard fetch options including cache control.\\n\\t* @returns BlobDownloadBuilder instance for downloading the file\\n\\t*\\n\\t* @example Download file\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .download('folder/avatar1.png')\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": <BLOB>,\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*\\n\\t* @example Download file with transformations\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .download('folder/avatar1.png', {\\n\\t*     transform: {\\n\\t*       width: 100,\\n\\t*       height: 100,\\n\\t*       quality: 80\\n\\t*     }\\n\\t*   })\\n\\t* ```\\n\\t*\\n\\t* @example Download with cache control (useful in Edge Functions)\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .download('folder/avatar1.png', {}, { cache: 'no-store' })\\n\\t* ```\\n\\t*\\n\\t* @example Download with abort signal\\n\\t* ```js\\n\\t* const controller = new AbortController()\\n\\t* setTimeout(() => controller.abort(), 5000)\\n\\t*\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .download('folder/avatar1.png', {}, { signal: controller.signal })\\n\\t* ```\\n\\t*/\\n\\tdownload(path, options, parameters) {\\n\\t\\tconst renderPath = typeof (options === null || options === void 0 ? void 0 : options.transform) !== \\\"undefined\\\" ? \\\"render/image/authenticated\\\" : \\\"object\\\";\\n\\t\\tconst transformationQuery = this.transformOptsToQueryString((options === null || options === void 0 ? void 0 : options.transform) || {});\\n\\t\\tconst queryString = transformationQuery ? `?${transformationQuery}` : \\\"\\\";\\n\\t\\tconst _path = this._getFinalPath(path);\\n\\t\\tconst downloadFn = () => get(this.fetch, `${this.url}/${renderPath}/${_path}${queryString}`, {\\n\\t\\t\\theaders: this.headers,\\n\\t\\t\\tnoResolveJson: true\\n\\t\\t}, parameters);\\n\\t\\treturn new BlobDownloadBuilder(downloadFn, this.shouldThrowOnError);\\n\\t}\\n\\t/**\\n\\t* Retrieves the details of an existing file.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param path The file path, including the file name. For example `folder/image.png`.\\n\\t* @returns Promise with response containing file metadata or error\\n\\t*\\n\\t* @example Get file info\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .info('folder/avatar1.png')\\n\\t* ```\\n\\t*/\\n\\tasync info(path) {\\n\\t\\tvar _this10 = this;\\n\\t\\tconst _path = _this10._getFinalPath(path);\\n\\t\\treturn _this10.handleOperation(async () => {\\n\\t\\t\\treturn recursiveToCamel(await get(_this10.fetch, `${_this10.url}/object/info/${_path}`, { headers: _this10.headers }));\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Checks the existence of a file.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param path The file path, including the file name. For example `folder/image.png`.\\n\\t* @returns Promise with response containing boolean indicating file existence or error\\n\\t*\\n\\t* @example Check file existence\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .exists('folder/avatar1.png')\\n\\t* ```\\n\\t*/\\n\\tasync exists(path) {\\n\\t\\tvar _this11 = this;\\n\\t\\tconst _path = _this11._getFinalPath(path);\\n\\t\\ttry {\\n\\t\\t\\tawait head(_this11.fetch, `${_this11.url}/object/${_path}`, { headers: _this11.headers });\\n\\t\\t\\treturn {\\n\\t\\t\\t\\tdata: true,\\n\\t\\t\\t\\terror: null\\n\\t\\t\\t};\\n\\t\\t} catch (error) {\\n\\t\\t\\tif (_this11.shouldThrowOnError) throw error;\\n\\t\\t\\tif (isStorageError(error) && error instanceof StorageUnknownError) {\\n\\t\\t\\t\\tconst originalError = error.originalError;\\n\\t\\t\\t\\tif ([400, 404].includes(originalError === null || originalError === void 0 ? void 0 : originalError.status)) return {\\n\\t\\t\\t\\t\\tdata: false,\\n\\t\\t\\t\\t\\terror\\n\\t\\t\\t\\t};\\n\\t\\t\\t}\\n\\t\\t\\tthrow error;\\n\\t\\t}\\n\\t}\\n\\t/**\\n\\t* A simple convenience function to get the URL for an asset in a public bucket. If you do not want to use this function, you can construct the public URL by concatenating the bucket URL with the path to the asset.\\n\\t* This function does not verify if the bucket is public. If a public URL is created for a bucket which is not public, you will not be able to download the asset.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param path The path and name of the file to generate the public URL for. For example `folder/image.png`.\\n\\t* @param options.download Triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\\n\\t* @param options.transform Transform the asset before serving it to the client.\\n\\t* @returns Object with public URL\\n\\t*\\n\\t* @example Returns the URL for an asset in a public bucket\\n\\t* ```js\\n\\t* const { data } = supabase\\n\\t*   .storage\\n\\t*   .from('public-bucket')\\n\\t*   .getPublicUrl('folder/avatar1.png')\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"publicUrl\\\": \\\"https://example.supabase.co/storage/v1/object/public/public-bucket/folder/avatar1.png\\\"\\n\\t*   }\\n\\t* }\\n\\t* ```\\n\\t*\\n\\t* @example Returns the URL for an asset in a public bucket with transformations\\n\\t* ```js\\n\\t* const { data } = supabase\\n\\t*   .storage\\n\\t*   .from('public-bucket')\\n\\t*   .getPublicUrl('folder/avatar1.png', {\\n\\t*     transform: {\\n\\t*       width: 100,\\n\\t*       height: 100,\\n\\t*     }\\n\\t*   })\\n\\t* ```\\n\\t*\\n\\t* @example Returns the URL which triggers the download of an asset in a public bucket\\n\\t* ```js\\n\\t* const { data } = supabase\\n\\t*   .storage\\n\\t*   .from('public-bucket')\\n\\t*   .getPublicUrl('folder/avatar1.png', {\\n\\t*     download: true,\\n\\t*   })\\n\\t* ```\\n\\t*/\\n\\tgetPublicUrl(path, options) {\\n\\t\\tconst _path = this._getFinalPath(path);\\n\\t\\tconst _queryString = [];\\n\\t\\tconst downloadQueryParam = (options === null || options === void 0 ? void 0 : options.download) ? `download=${options.download === true ? \\\"\\\" : options.download}` : \\\"\\\";\\n\\t\\tif (downloadQueryParam !== \\\"\\\") _queryString.push(downloadQueryParam);\\n\\t\\tconst renderPath = typeof (options === null || options === void 0 ? void 0 : options.transform) !== \\\"undefined\\\" ? \\\"render/image\\\" : \\\"object\\\";\\n\\t\\tconst transformationQuery = this.transformOptsToQueryString((options === null || options === void 0 ? void 0 : options.transform) || {});\\n\\t\\tif (transformationQuery !== \\\"\\\") _queryString.push(transformationQuery);\\n\\t\\tlet queryString = _queryString.join(\\\"&\\\");\\n\\t\\tif (queryString !== \\\"\\\") queryString = `?${queryString}`;\\n\\t\\treturn { data: { publicUrl: encodeURI(`${this.url}/${renderPath}/public/${_path}${queryString}`) } };\\n\\t}\\n\\t/**\\n\\t* Deletes files within the same bucket\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param paths An array of files to delete, including the path and file name. For example [`'folder/image.png'`].\\n\\t* @returns Promise with response containing array of deleted file objects or error\\n\\t*\\n\\t* @example Delete file\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .remove(['folder/avatar1.png'])\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": [],\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync remove(paths) {\\n\\t\\tvar _this12 = this;\\n\\t\\treturn _this12.handleOperation(async () => {\\n\\t\\t\\treturn await remove(_this12.fetch, `${_this12.url}/object/${_this12.bucketId}`, { prefixes: paths }, { headers: _this12.headers });\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Get file metadata\\n\\t* @param id the file id to retrieve metadata\\n\\t*/\\n\\t/**\\n\\t* Update file metadata\\n\\t* @param id the file id to update metadata\\n\\t* @param meta the new file metadata\\n\\t*/\\n\\t/**\\n\\t* Lists all the files and folders within a path of the bucket.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param path The folder path.\\n\\t* @param options Search options including limit (defaults to 100), offset, sortBy, and search\\n\\t* @param parameters Optional fetch parameters including signal for cancellation\\n\\t* @returns Promise with response containing array of files or error\\n\\t*\\n\\t* @example List files in a bucket\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .list('folder', {\\n\\t*     limit: 100,\\n\\t*     offset: 0,\\n\\t*     sortBy: { column: 'name', order: 'asc' },\\n\\t*   })\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": [\\n\\t*     {\\n\\t*       \\\"name\\\": \\\"avatar1.png\\\",\\n\\t*       \\\"id\\\": \\\"e668cf7f-821b-4a2f-9dce-7dfa5dd1cfd2\\\",\\n\\t*       \\\"updated_at\\\": \\\"2024-05-22T23:06:05.580Z\\\",\\n\\t*       \\\"created_at\\\": \\\"2024-05-22T23:04:34.443Z\\\",\\n\\t*       \\\"last_accessed_at\\\": \\\"2024-05-22T23:04:34.443Z\\\",\\n\\t*       \\\"metadata\\\": {\\n\\t*         \\\"eTag\\\": \\\"\\\\\\\"c5e8c553235d9af30ef4f6e280790b92\\\\\\\"\\\",\\n\\t*         \\\"size\\\": 32175,\\n\\t*         \\\"mimetype\\\": \\\"image/png\\\",\\n\\t*         \\\"cacheControl\\\": \\\"max-age=3600\\\",\\n\\t*         \\\"lastModified\\\": \\\"2024-05-22T23:06:05.574Z\\\",\\n\\t*         \\\"contentLength\\\": 32175,\\n\\t*         \\\"httpStatusCode\\\": 200\\n\\t*       }\\n\\t*     }\\n\\t*   ],\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*\\n\\t* @example Search files in a bucket\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .from('avatars')\\n\\t*   .list('folder', {\\n\\t*     limit: 100,\\n\\t*     offset: 0,\\n\\t*     sortBy: { column: 'name', order: 'asc' },\\n\\t*     search: 'jon'\\n\\t*   })\\n\\t* ```\\n\\t*/\\n\\tasync list(path, options, parameters) {\\n\\t\\tvar _this13 = this;\\n\\t\\treturn _this13.handleOperation(async () => {\\n\\t\\t\\tconst body = _objectSpread2(_objectSpread2(_objectSpread2({}, DEFAULT_SEARCH_OPTIONS), options), {}, { prefix: path || \\\"\\\" });\\n\\t\\t\\treturn await post(_this13.fetch, `${_this13.url}/object/list/${_this13.bucketId}`, body, { headers: _this13.headers }, parameters);\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* @experimental this method signature might change in the future\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param options search options\\n\\t* @param parameters\\n\\t*/\\n\\tasync listV2(options, parameters) {\\n\\t\\tvar _this14 = this;\\n\\t\\treturn _this14.handleOperation(async () => {\\n\\t\\t\\tconst body = _objectSpread2({}, options);\\n\\t\\t\\treturn await post(_this14.fetch, `${_this14.url}/object/list-v2/${_this14.bucketId}`, body, { headers: _this14.headers }, parameters);\\n\\t\\t});\\n\\t}\\n\\tencodeMetadata(metadata) {\\n\\t\\treturn JSON.stringify(metadata);\\n\\t}\\n\\ttoBase64(data) {\\n\\t\\tif (typeof Buffer !== \\\"undefined\\\") return Buffer.from(data).toString(\\\"base64\\\");\\n\\t\\treturn btoa(data);\\n\\t}\\n\\t_getFinalPath(path) {\\n\\t\\treturn `${this.bucketId}/${path.replace(/^\\\\/+/, \\\"\\\")}`;\\n\\t}\\n\\t_removeEmptyFolders(path) {\\n\\t\\treturn path.replace(/^\\\\/|\\\\/$/g, \\\"\\\").replace(/\\\\/+/g, \\\"/\\\");\\n\\t}\\n\\ttransformOptsToQueryString(transform) {\\n\\t\\tconst params = [];\\n\\t\\tif (transform.width) params.push(`width=${transform.width}`);\\n\\t\\tif (transform.height) params.push(`height=${transform.height}`);\\n\\t\\tif (transform.resize) params.push(`resize=${transform.resize}`);\\n\\t\\tif (transform.format) params.push(`format=${transform.format}`);\\n\\t\\tif (transform.quality) params.push(`quality=${transform.quality}`);\\n\\t\\treturn params.join(\\\"&\\\");\\n\\t}\\n};\\n\\n//#endregion\\n//#region src/lib/version.ts\\nconst version = \\\"2.97.0\\\";\\n\\n//#endregion\\n//#region src/lib/constants.ts\\nconst DEFAULT_HEADERS = { \\\"X-Client-Info\\\": `storage-js/${version}` };\\n\\n//#endregion\\n//#region src/packages/StorageBucketApi.ts\\nvar StorageBucketApi = class extends BaseApiClient {\\n\\tconstructor(url, headers = {}, fetch$1, opts) {\\n\\t\\tconst baseUrl = new URL(url);\\n\\t\\tif (opts === null || opts === void 0 ? void 0 : opts.useNewHostname) {\\n\\t\\t\\tif (/supabase\\\\.(co|in|red)$/.test(baseUrl.hostname) && !baseUrl.hostname.includes(\\\"storage.supabase.\\\")) baseUrl.hostname = baseUrl.hostname.replace(\\\"supabase.\\\", \\\"storage.supabase.\\\");\\n\\t\\t}\\n\\t\\tconst finalUrl = baseUrl.href.replace(/\\\\/$/, \\\"\\\");\\n\\t\\tconst finalHeaders = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), headers);\\n\\t\\tsuper(finalUrl, finalHeaders, fetch$1, \\\"storage\\\");\\n\\t}\\n\\t/**\\n\\t* Retrieves the details of all Storage buckets within an existing project.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param options Query parameters for listing buckets\\n\\t* @param options.limit Maximum number of buckets to return\\n\\t* @param options.offset Number of buckets to skip\\n\\t* @param options.sortColumn Column to sort by ('id', 'name', 'created_at', 'updated_at')\\n\\t* @param options.sortOrder Sort order ('asc' or 'desc')\\n\\t* @param options.search Search term to filter bucket names\\n\\t* @returns Promise with response containing array of buckets or error\\n\\t*\\n\\t* @example List buckets\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .listBuckets()\\n\\t* ```\\n\\t*\\n\\t* @example List buckets with options\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .listBuckets({\\n\\t*     limit: 10,\\n\\t*     offset: 0,\\n\\t*     sortColumn: 'created_at',\\n\\t*     sortOrder: 'desc',\\n\\t*     search: 'prod'\\n\\t*   })\\n\\t* ```\\n\\t*/\\n\\tasync listBuckets(options) {\\n\\t\\tvar _this = this;\\n\\t\\treturn _this.handleOperation(async () => {\\n\\t\\t\\tconst queryString = _this.listBucketOptionsToQueryString(options);\\n\\t\\t\\treturn await get(_this.fetch, `${_this.url}/bucket${queryString}`, { headers: _this.headers });\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Retrieves the details of an existing Storage bucket.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param id The unique identifier of the bucket you would like to retrieve.\\n\\t* @returns Promise with response containing bucket details or error\\n\\t*\\n\\t* @example Get bucket\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .getBucket('avatars')\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"id\\\": \\\"avatars\\\",\\n\\t*     \\\"name\\\": \\\"avatars\\\",\\n\\t*     \\\"owner\\\": \\\"\\\",\\n\\t*     \\\"public\\\": false,\\n\\t*     \\\"file_size_limit\\\": 1024,\\n\\t*     \\\"allowed_mime_types\\\": [\\n\\t*       \\\"image/png\\\"\\n\\t*     ],\\n\\t*     \\\"created_at\\\": \\\"2024-05-22T22:26:05.100Z\\\",\\n\\t*     \\\"updated_at\\\": \\\"2024-05-22T22:26:05.100Z\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync getBucket(id) {\\n\\t\\tvar _this2 = this;\\n\\t\\treturn _this2.handleOperation(async () => {\\n\\t\\t\\treturn await get(_this2.fetch, `${_this2.url}/bucket/${id}`, { headers: _this2.headers });\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Creates a new Storage bucket\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param id A unique identifier for the bucket you are creating.\\n\\t* @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations. By default, buckets are private.\\n\\t* @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\\n\\t* The global file size limit takes precedence over this value.\\n\\t* The default value is null, which doesn't set a per bucket file size limit.\\n\\t* @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\\n\\t* The default value is null, which allows files with all mime types to be uploaded.\\n\\t* Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\\n\\t* @param options.type (private-beta) specifies the bucket type. see `BucketType` for more details.\\n\\t*   - default bucket type is `STANDARD`\\n\\t* @returns Promise with response containing newly created bucket name or error\\n\\t*\\n\\t* @example Create bucket\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .createBucket('avatars', {\\n\\t*     public: false,\\n\\t*     allowedMimeTypes: ['image/png'],\\n\\t*     fileSizeLimit: 1024\\n\\t*   })\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"name\\\": \\\"avatars\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync createBucket(id, options = { public: false }) {\\n\\t\\tvar _this3 = this;\\n\\t\\treturn _this3.handleOperation(async () => {\\n\\t\\t\\treturn await post(_this3.fetch, `${_this3.url}/bucket`, {\\n\\t\\t\\t\\tid,\\n\\t\\t\\t\\tname: id,\\n\\t\\t\\t\\ttype: options.type,\\n\\t\\t\\t\\tpublic: options.public,\\n\\t\\t\\t\\tfile_size_limit: options.fileSizeLimit,\\n\\t\\t\\t\\tallowed_mime_types: options.allowedMimeTypes\\n\\t\\t\\t}, { headers: _this3.headers });\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Updates a Storage bucket\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param id A unique identifier for the bucket you are updating.\\n\\t* @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations.\\n\\t* @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\\n\\t* The global file size limit takes precedence over this value.\\n\\t* The default value is null, which doesn't set a per bucket file size limit.\\n\\t* @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\\n\\t* The default value is null, which allows files with all mime types to be uploaded.\\n\\t* Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\\n\\t* @returns Promise with response containing success message or error\\n\\t*\\n\\t* @example Update bucket\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .updateBucket('avatars', {\\n\\t*     public: false,\\n\\t*     allowedMimeTypes: ['image/png'],\\n\\t*     fileSizeLimit: 1024\\n\\t*   })\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"message\\\": \\\"Successfully updated\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync updateBucket(id, options) {\\n\\t\\tvar _this4 = this;\\n\\t\\treturn _this4.handleOperation(async () => {\\n\\t\\t\\treturn await put(_this4.fetch, `${_this4.url}/bucket/${id}`, {\\n\\t\\t\\t\\tid,\\n\\t\\t\\t\\tname: id,\\n\\t\\t\\t\\tpublic: options.public,\\n\\t\\t\\t\\tfile_size_limit: options.fileSizeLimit,\\n\\t\\t\\t\\tallowed_mime_types: options.allowedMimeTypes\\n\\t\\t\\t}, { headers: _this4.headers });\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Removes all objects inside a single bucket.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param id The unique identifier of the bucket you would like to empty.\\n\\t* @returns Promise with success message or error\\n\\t*\\n\\t* @example Empty bucket\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .emptyBucket('avatars')\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"message\\\": \\\"Successfully emptied\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync emptyBucket(id) {\\n\\t\\tvar _this5 = this;\\n\\t\\treturn _this5.handleOperation(async () => {\\n\\t\\t\\treturn await post(_this5.fetch, `${_this5.url}/bucket/${id}/empty`, {}, { headers: _this5.headers });\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* Deletes an existing bucket. A bucket can't be deleted with existing objects inside it.\\n\\t* You must first `empty()` the bucket.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param id The unique identifier of the bucket you would like to delete.\\n\\t* @returns Promise with success message or error\\n\\t*\\n\\t* @example Delete bucket\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .deleteBucket('avatars')\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"message\\\": \\\"Successfully deleted\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync deleteBucket(id) {\\n\\t\\tvar _this6 = this;\\n\\t\\treturn _this6.handleOperation(async () => {\\n\\t\\t\\treturn await remove(_this6.fetch, `${_this6.url}/bucket/${id}`, {}, { headers: _this6.headers });\\n\\t\\t});\\n\\t}\\n\\tlistBucketOptionsToQueryString(options) {\\n\\t\\tconst params = {};\\n\\t\\tif (options) {\\n\\t\\t\\tif (\\\"limit\\\" in options) params.limit = String(options.limit);\\n\\t\\t\\tif (\\\"offset\\\" in options) params.offset = String(options.offset);\\n\\t\\t\\tif (options.search) params.search = options.search;\\n\\t\\t\\tif (options.sortColumn) params.sortColumn = options.sortColumn;\\n\\t\\t\\tif (options.sortOrder) params.sortOrder = options.sortOrder;\\n\\t\\t}\\n\\t\\treturn Object.keys(params).length > 0 ? \\\"?\\\" + new URLSearchParams(params).toString() : \\\"\\\";\\n\\t}\\n};\\n\\n//#endregion\\n//#region src/packages/StorageAnalyticsClient.ts\\n/**\\n* Client class for managing Analytics Buckets using Iceberg tables\\n* Provides methods for creating, listing, and deleting analytics buckets\\n*/\\nvar StorageAnalyticsClient = class extends BaseApiClient {\\n\\t/**\\n\\t* @alpha\\n\\t*\\n\\t* Creates a new StorageAnalyticsClient instance\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Analytics Buckets\\n\\t* @param url - The base URL for the storage API\\n\\t* @param headers - HTTP headers to include in requests\\n\\t* @param fetch - Optional custom fetch implementation\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const client = new StorageAnalyticsClient(url, headers)\\n\\t* ```\\n\\t*/\\n\\tconstructor(url, headers = {}, fetch$1) {\\n\\t\\tconst finalUrl = url.replace(/\\\\/$/, \\\"\\\");\\n\\t\\tconst finalHeaders = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), headers);\\n\\t\\tsuper(finalUrl, finalHeaders, fetch$1, \\\"storage\\\");\\n\\t}\\n\\t/**\\n\\t* @alpha\\n\\t*\\n\\t* Creates a new analytics bucket using Iceberg tables\\n\\t* Analytics buckets are optimized for analytical queries and data processing\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Analytics Buckets\\n\\t* @param name A unique name for the bucket you are creating\\n\\t* @returns Promise with response containing newly created analytics bucket or error\\n\\t*\\n\\t* @example Create analytics bucket\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .analytics\\n\\t*   .createBucket('analytics-data')\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"name\\\": \\\"analytics-data\\\",\\n\\t*     \\\"type\\\": \\\"ANALYTICS\\\",\\n\\t*     \\\"format\\\": \\\"iceberg\\\",\\n\\t*     \\\"created_at\\\": \\\"2024-05-22T22:26:05.100Z\\\",\\n\\t*     \\\"updated_at\\\": \\\"2024-05-22T22:26:05.100Z\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync createBucket(name) {\\n\\t\\tvar _this = this;\\n\\t\\treturn _this.handleOperation(async () => {\\n\\t\\t\\treturn await post(_this.fetch, `${_this.url}/bucket`, { name }, { headers: _this.headers });\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* @alpha\\n\\t*\\n\\t* Retrieves the details of all Analytics Storage buckets within an existing project\\n\\t* Only returns buckets of type 'ANALYTICS'\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Analytics Buckets\\n\\t* @param options Query parameters for listing buckets\\n\\t* @param options.limit Maximum number of buckets to return\\n\\t* @param options.offset Number of buckets to skip\\n\\t* @param options.sortColumn Column to sort by ('name', 'created_at', 'updated_at')\\n\\t* @param options.sortOrder Sort order ('asc' or 'desc')\\n\\t* @param options.search Search term to filter bucket names\\n\\t* @returns Promise with response containing array of analytics buckets or error\\n\\t*\\n\\t* @example List analytics buckets\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .analytics\\n\\t*   .listBuckets({\\n\\t*     limit: 10,\\n\\t*     offset: 0,\\n\\t*     sortColumn: 'created_at',\\n\\t*     sortOrder: 'desc'\\n\\t*   })\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": [\\n\\t*     {\\n\\t*       \\\"name\\\": \\\"analytics-data\\\",\\n\\t*       \\\"type\\\": \\\"ANALYTICS\\\",\\n\\t*       \\\"format\\\": \\\"iceberg\\\",\\n\\t*       \\\"created_at\\\": \\\"2024-05-22T22:26:05.100Z\\\",\\n\\t*       \\\"updated_at\\\": \\\"2024-05-22T22:26:05.100Z\\\"\\n\\t*     }\\n\\t*   ],\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync listBuckets(options) {\\n\\t\\tvar _this2 = this;\\n\\t\\treturn _this2.handleOperation(async () => {\\n\\t\\t\\tconst queryParams = new URLSearchParams();\\n\\t\\t\\tif ((options === null || options === void 0 ? void 0 : options.limit) !== void 0) queryParams.set(\\\"limit\\\", options.limit.toString());\\n\\t\\t\\tif ((options === null || options === void 0 ? void 0 : options.offset) !== void 0) queryParams.set(\\\"offset\\\", options.offset.toString());\\n\\t\\t\\tif (options === null || options === void 0 ? void 0 : options.sortColumn) queryParams.set(\\\"sortColumn\\\", options.sortColumn);\\n\\t\\t\\tif (options === null || options === void 0 ? void 0 : options.sortOrder) queryParams.set(\\\"sortOrder\\\", options.sortOrder);\\n\\t\\t\\tif (options === null || options === void 0 ? void 0 : options.search) queryParams.set(\\\"search\\\", options.search);\\n\\t\\t\\tconst queryString = queryParams.toString();\\n\\t\\t\\tconst url = queryString ? `${_this2.url}/bucket?${queryString}` : `${_this2.url}/bucket`;\\n\\t\\t\\treturn await get(_this2.fetch, url, { headers: _this2.headers });\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* @alpha\\n\\t*\\n\\t* Deletes an existing analytics bucket\\n\\t* A bucket can't be deleted with existing objects inside it\\n\\t* You must first empty the bucket before deletion\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Analytics Buckets\\n\\t* @param bucketName The unique identifier of the bucket you would like to delete\\n\\t* @returns Promise with response containing success message or error\\n\\t*\\n\\t* @example Delete analytics bucket\\n\\t* ```js\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .analytics\\n\\t*   .deleteBucket('analytics-data')\\n\\t* ```\\n\\t*\\n\\t* Response:\\n\\t* ```json\\n\\t* {\\n\\t*   \\\"data\\\": {\\n\\t*     \\\"message\\\": \\\"Successfully deleted\\\"\\n\\t*   },\\n\\t*   \\\"error\\\": null\\n\\t* }\\n\\t* ```\\n\\t*/\\n\\tasync deleteBucket(bucketName) {\\n\\t\\tvar _this3 = this;\\n\\t\\treturn _this3.handleOperation(async () => {\\n\\t\\t\\treturn await remove(_this3.fetch, `${_this3.url}/bucket/${bucketName}`, {}, { headers: _this3.headers });\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t* @alpha\\n\\t*\\n\\t* Get an Iceberg REST Catalog client configured for a specific analytics bucket\\n\\t* Use this to perform advanced table and namespace operations within the bucket\\n\\t* The returned client provides full access to the Apache Iceberg REST Catalog API\\n\\t* with the Supabase `{ data, error }` pattern for consistent error handling on all operations.\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Analytics Buckets\\n\\t* @param bucketName - The name of the analytics bucket (warehouse) to connect to\\n\\t* @returns The wrapped Iceberg catalog client\\n\\t* @throws {StorageError} If the bucket name is invalid\\n\\t*\\n\\t* @example Get catalog and create table\\n\\t* ```js\\n\\t* // First, create an analytics bucket\\n\\t* const { data: bucket, error: bucketError } = await supabase\\n\\t*   .storage\\n\\t*   .analytics\\n\\t*   .createBucket('analytics-data')\\n\\t*\\n\\t* // Get the Iceberg catalog for that bucket\\n\\t* const catalog = supabase.storage.analytics.from('analytics-data')\\n\\t*\\n\\t* // Create a namespace\\n\\t* const { error: nsError } = await catalog.createNamespace({ namespace: ['default'] })\\n\\t*\\n\\t* // Create a table with schema\\n\\t* const { data: tableMetadata, error: tableError } = await catalog.createTable(\\n\\t*   { namespace: ['default'] },\\n\\t*   {\\n\\t*     name: 'events',\\n\\t*     schema: {\\n\\t*       type: 'struct',\\n\\t*       fields: [\\n\\t*         { id: 1, name: 'id', type: 'long', required: true },\\n\\t*         { id: 2, name: 'timestamp', type: 'timestamp', required: true },\\n\\t*         { id: 3, name: 'user_id', type: 'string', required: false }\\n\\t*       ],\\n\\t*       'schema-id': 0,\\n\\t*       'identifier-field-ids': [1]\\n\\t*     },\\n\\t*     'partition-spec': {\\n\\t*       'spec-id': 0,\\n\\t*       fields: []\\n\\t*     },\\n\\t*     'write-order': {\\n\\t*       'order-id': 0,\\n\\t*       fields: []\\n\\t*     },\\n\\t*     properties: {\\n\\t*       'write.format.default': 'parquet'\\n\\t*     }\\n\\t*   }\\n\\t* )\\n\\t* ```\\n\\t*\\n\\t* @example List tables in namespace\\n\\t* ```js\\n\\t* const catalog = supabase.storage.analytics.from('analytics-data')\\n\\t*\\n\\t* // List all tables in the default namespace\\n\\t* const { data: tables, error: listError } = await catalog.listTables({ namespace: ['default'] })\\n\\t* if (listError) {\\n\\t*   if (listError.isNotFound()) {\\n\\t*     console.log('Namespace not found')\\n\\t*   }\\n\\t*   return\\n\\t* }\\n\\t* console.log(tables) // [{ namespace: ['default'], name: 'events' }]\\n\\t* ```\\n\\t*\\n\\t* @example Working with namespaces\\n\\t* ```js\\n\\t* const catalog = supabase.storage.analytics.from('analytics-data')\\n\\t*\\n\\t* // List all namespaces\\n\\t* const { data: namespaces } = await catalog.listNamespaces()\\n\\t*\\n\\t* // Create namespace with properties\\n\\t* await catalog.createNamespace(\\n\\t*   { namespace: ['production'] },\\n\\t*   { properties: { owner: 'data-team', env: 'prod' } }\\n\\t* )\\n\\t* ```\\n\\t*\\n\\t* @example Cleanup operations\\n\\t* ```js\\n\\t* const catalog = supabase.storage.analytics.from('analytics-data')\\n\\t*\\n\\t* // Drop table with purge option (removes all data)\\n\\t* const { error: dropError } = await catalog.dropTable(\\n\\t*   { namespace: ['default'], name: 'events' },\\n\\t*   { purge: true }\\n\\t* )\\n\\t*\\n\\t* if (dropError?.isNotFound()) {\\n\\t*   console.log('Table does not exist')\\n\\t* }\\n\\t*\\n\\t* // Drop namespace (must be empty)\\n\\t* await catalog.dropNamespace({ namespace: ['default'] })\\n\\t* ```\\n\\t*\\n\\t* @remarks\\n\\t* This method provides a bridge between Supabase's bucket management and the standard\\n\\t* Apache Iceberg REST Catalog API. The bucket name maps to the Iceberg warehouse parameter.\\n\\t* All authentication and configuration is handled automatically using your Supabase credentials.\\n\\t*\\n\\t* **Error Handling**: Invalid bucket names throw immediately. All catalog\\n\\t* operations return `{ data, error }` where errors are `IcebergError` instances from iceberg-js.\\n\\t* Use helper methods like `error.isNotFound()` or check `error.status` for specific error handling.\\n\\t* Use `.throwOnError()` on the analytics client if you prefer exceptions for catalog operations.\\n\\t*\\n\\t* **Cleanup Operations**: When using `dropTable`, the `purge: true` option permanently\\n\\t* deletes all table data. Without it, the table is marked as deleted but data remains.\\n\\t*\\n\\t* **Library Dependency**: The returned catalog wraps `IcebergRestCatalog` from iceberg-js.\\n\\t* For complete API documentation and advanced usage, refer to the\\n\\t* [iceberg-js documentation](https://supabase.github.io/iceberg-js/).\\n\\t*/\\n\\tfrom(bucketName) {\\n\\t\\tvar _this4 = this;\\n\\t\\tif (!isValidBucketName(bucketName)) throw new StorageError(\\\"Invalid bucket name: File, folder, and bucket names must follow AWS object key naming guidelines and should avoid the use of any other characters.\\\");\\n\\t\\tconst catalog = new iceberg_js.IcebergRestCatalog({\\n\\t\\t\\tbaseUrl: this.url,\\n\\t\\t\\tcatalogName: bucketName,\\n\\t\\t\\tauth: {\\n\\t\\t\\t\\ttype: \\\"custom\\\",\\n\\t\\t\\t\\tgetHeaders: async () => _this4.headers\\n\\t\\t\\t},\\n\\t\\t\\tfetch: this.fetch\\n\\t\\t});\\n\\t\\tconst shouldThrowOnError = this.shouldThrowOnError;\\n\\t\\treturn new Proxy(catalog, { get(target, prop) {\\n\\t\\t\\tconst value = target[prop];\\n\\t\\t\\tif (typeof value !== \\\"function\\\") return value;\\n\\t\\t\\treturn async (...args) => {\\n\\t\\t\\t\\ttry {\\n\\t\\t\\t\\t\\treturn {\\n\\t\\t\\t\\t\\t\\tdata: await value.apply(target, args),\\n\\t\\t\\t\\t\\t\\terror: null\\n\\t\\t\\t\\t\\t};\\n\\t\\t\\t\\t} catch (error) {\\n\\t\\t\\t\\t\\tif (shouldThrowOnError) throw error;\\n\\t\\t\\t\\t\\treturn {\\n\\t\\t\\t\\t\\t\\tdata: null,\\n\\t\\t\\t\\t\\t\\terror\\n\\t\\t\\t\\t\\t};\\n\\t\\t\\t\\t}\\n\\t\\t\\t};\\n\\t\\t} });\\n\\t}\\n};\\n\\n//#endregion\\n//#region src/packages/VectorIndexApi.ts\\n/**\\n* @hidden\\n* Base implementation for vector index operations.\\n* Use {@link VectorBucketScope} via `supabase.storage.vectors.from('bucket')` instead.\\n*/\\nvar VectorIndexApi = class extends BaseApiClient {\\n\\t/** Creates a new VectorIndexApi instance */\\n\\tconstructor(url, headers = {}, fetch$1) {\\n\\t\\tconst finalUrl = url.replace(/\\\\/$/, \\\"\\\");\\n\\t\\tconst finalHeaders = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), {}, { \\\"Content-Type\\\": \\\"application/json\\\" }, headers);\\n\\t\\tsuper(finalUrl, finalHeaders, fetch$1, \\\"vectors\\\");\\n\\t}\\n\\t/** Creates a new vector index within a bucket */\\n\\tasync createIndex(options) {\\n\\t\\tvar _this = this;\\n\\t\\treturn _this.handleOperation(async () => {\\n\\t\\t\\treturn await vectorsApi.post(_this.fetch, `${_this.url}/CreateIndex`, options, { headers: _this.headers }) || {};\\n\\t\\t});\\n\\t}\\n\\t/** Retrieves metadata for a specific vector index */\\n\\tasync getIndex(vectorBucketName, indexName) {\\n\\t\\tvar _this2 = this;\\n\\t\\treturn _this2.handleOperation(async () => {\\n\\t\\t\\treturn await vectorsApi.post(_this2.fetch, `${_this2.url}/GetIndex`, {\\n\\t\\t\\t\\tvectorBucketName,\\n\\t\\t\\t\\tindexName\\n\\t\\t\\t}, { headers: _this2.headers });\\n\\t\\t});\\n\\t}\\n\\t/** Lists vector indexes within a bucket with optional filtering and pagination */\\n\\tasync listIndexes(options) {\\n\\t\\tvar _this3 = this;\\n\\t\\treturn _this3.handleOperation(async () => {\\n\\t\\t\\treturn await vectorsApi.post(_this3.fetch, `${_this3.url}/ListIndexes`, options, { headers: _this3.headers });\\n\\t\\t});\\n\\t}\\n\\t/** Deletes a vector index and all its data */\\n\\tasync deleteIndex(vectorBucketName, indexName) {\\n\\t\\tvar _this4 = this;\\n\\t\\treturn _this4.handleOperation(async () => {\\n\\t\\t\\treturn await vectorsApi.post(_this4.fetch, `${_this4.url}/DeleteIndex`, {\\n\\t\\t\\t\\tvectorBucketName,\\n\\t\\t\\t\\tindexName\\n\\t\\t\\t}, { headers: _this4.headers }) || {};\\n\\t\\t});\\n\\t}\\n};\\n\\n//#endregion\\n//#region src/packages/VectorDataApi.ts\\n/**\\n* @hidden\\n* Base implementation for vector data operations.\\n* Use {@link VectorIndexScope} via `supabase.storage.vectors.from('bucket').index('idx')` instead.\\n*/\\nvar VectorDataApi = class extends BaseApiClient {\\n\\t/** Creates a new VectorDataApi instance */\\n\\tconstructor(url, headers = {}, fetch$1) {\\n\\t\\tconst finalUrl = url.replace(/\\\\/$/, \\\"\\\");\\n\\t\\tconst finalHeaders = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), {}, { \\\"Content-Type\\\": \\\"application/json\\\" }, headers);\\n\\t\\tsuper(finalUrl, finalHeaders, fetch$1, \\\"vectors\\\");\\n\\t}\\n\\t/** Inserts or updates vectors in batch (1-500 per request) */\\n\\tasync putVectors(options) {\\n\\t\\tvar _this = this;\\n\\t\\tif (options.vectors.length < 1 || options.vectors.length > 500) throw new Error(\\\"Vector batch size must be between 1 and 500 items\\\");\\n\\t\\treturn _this.handleOperation(async () => {\\n\\t\\t\\treturn await vectorsApi.post(_this.fetch, `${_this.url}/PutVectors`, options, { headers: _this.headers }) || {};\\n\\t\\t});\\n\\t}\\n\\t/** Retrieves vectors by their keys in batch */\\n\\tasync getVectors(options) {\\n\\t\\tvar _this2 = this;\\n\\t\\treturn _this2.handleOperation(async () => {\\n\\t\\t\\treturn await vectorsApi.post(_this2.fetch, `${_this2.url}/GetVectors`, options, { headers: _this2.headers });\\n\\t\\t});\\n\\t}\\n\\t/** Lists vectors in an index with pagination */\\n\\tasync listVectors(options) {\\n\\t\\tvar _this3 = this;\\n\\t\\tif (options.segmentCount !== void 0) {\\n\\t\\t\\tif (options.segmentCount < 1 || options.segmentCount > 16) throw new Error(\\\"segmentCount must be between 1 and 16\\\");\\n\\t\\t\\tif (options.segmentIndex !== void 0) {\\n\\t\\t\\t\\tif (options.segmentIndex < 0 || options.segmentIndex >= options.segmentCount) throw new Error(`segmentIndex must be between 0 and ${options.segmentCount - 1}`);\\n\\t\\t\\t}\\n\\t\\t}\\n\\t\\treturn _this3.handleOperation(async () => {\\n\\t\\t\\treturn await vectorsApi.post(_this3.fetch, `${_this3.url}/ListVectors`, options, { headers: _this3.headers });\\n\\t\\t});\\n\\t}\\n\\t/** Queries for similar vectors using approximate nearest neighbor search */\\n\\tasync queryVectors(options) {\\n\\t\\tvar _this4 = this;\\n\\t\\treturn _this4.handleOperation(async () => {\\n\\t\\t\\treturn await vectorsApi.post(_this4.fetch, `${_this4.url}/QueryVectors`, options, { headers: _this4.headers });\\n\\t\\t});\\n\\t}\\n\\t/** Deletes vectors by their keys in batch (1-500 per request) */\\n\\tasync deleteVectors(options) {\\n\\t\\tvar _this5 = this;\\n\\t\\tif (options.keys.length < 1 || options.keys.length > 500) throw new Error(\\\"Keys batch size must be between 1 and 500 items\\\");\\n\\t\\treturn _this5.handleOperation(async () => {\\n\\t\\t\\treturn await vectorsApi.post(_this5.fetch, `${_this5.url}/DeleteVectors`, options, { headers: _this5.headers }) || {};\\n\\t\\t});\\n\\t}\\n};\\n\\n//#endregion\\n//#region src/packages/VectorBucketApi.ts\\n/**\\n* @hidden\\n* Base implementation for vector bucket operations.\\n* Use {@link StorageVectorsClient} via `supabase.storage.vectors` instead.\\n*/\\nvar VectorBucketApi = class extends BaseApiClient {\\n\\t/** Creates a new VectorBucketApi instance */\\n\\tconstructor(url, headers = {}, fetch$1) {\\n\\t\\tconst finalUrl = url.replace(/\\\\/$/, \\\"\\\");\\n\\t\\tconst finalHeaders = _objectSpread2(_objectSpread2({}, DEFAULT_HEADERS), {}, { \\\"Content-Type\\\": \\\"application/json\\\" }, headers);\\n\\t\\tsuper(finalUrl, finalHeaders, fetch$1, \\\"vectors\\\");\\n\\t}\\n\\t/** Creates a new vector bucket */\\n\\tasync createBucket(vectorBucketName) {\\n\\t\\tvar _this = this;\\n\\t\\treturn _this.handleOperation(async () => {\\n\\t\\t\\treturn await vectorsApi.post(_this.fetch, `${_this.url}/CreateVectorBucket`, { vectorBucketName }, { headers: _this.headers }) || {};\\n\\t\\t});\\n\\t}\\n\\t/** Retrieves metadata for a specific vector bucket */\\n\\tasync getBucket(vectorBucketName) {\\n\\t\\tvar _this2 = this;\\n\\t\\treturn _this2.handleOperation(async () => {\\n\\t\\t\\treturn await vectorsApi.post(_this2.fetch, `${_this2.url}/GetVectorBucket`, { vectorBucketName }, { headers: _this2.headers });\\n\\t\\t});\\n\\t}\\n\\t/** Lists vector buckets with optional filtering and pagination */\\n\\tasync listBuckets(options = {}) {\\n\\t\\tvar _this3 = this;\\n\\t\\treturn _this3.handleOperation(async () => {\\n\\t\\t\\treturn await vectorsApi.post(_this3.fetch, `${_this3.url}/ListVectorBuckets`, options, { headers: _this3.headers });\\n\\t\\t});\\n\\t}\\n\\t/** Deletes a vector bucket (must be empty first) */\\n\\tasync deleteBucket(vectorBucketName) {\\n\\t\\tvar _this4 = this;\\n\\t\\treturn _this4.handleOperation(async () => {\\n\\t\\t\\treturn await vectorsApi.post(_this4.fetch, `${_this4.url}/DeleteVectorBucket`, { vectorBucketName }, { headers: _this4.headers }) || {};\\n\\t\\t});\\n\\t}\\n};\\n\\n//#endregion\\n//#region src/packages/StorageVectorsClient.ts\\n/**\\n*\\n* @alpha\\n*\\n* Main client for interacting with S3 Vectors API\\n* Provides access to bucket, index, and vector data operations\\n*\\n* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n*\\n* **Usage Patterns:**\\n*\\n* ```typescript\\n* const { data, error } = await supabase\\n*  .storage\\n*  .vectors\\n*  .createBucket('embeddings-prod')\\n*\\n* // Access index operations via buckets\\n* const bucket = supabase.storage.vectors.from('embeddings-prod')\\n* await bucket.createIndex({\\n*   indexName: 'documents',\\n*   dataType: 'float32',\\n*   dimension: 1536,\\n*   distanceMetric: 'cosine'\\n* })\\n*\\n* // Access vector operations via index\\n* const index = bucket.index('documents')\\n* await index.putVectors({\\n*   vectors: [\\n*     { key: 'doc-1', data: { float32: [...] }, metadata: { title: 'Intro' } }\\n*   ]\\n* })\\n*\\n* // Query similar vectors\\n* const { data } = await index.queryVectors({\\n*   queryVector: { float32: [...] },\\n*   topK: 5,\\n*   returnDistance: true\\n* })\\n* ```\\n*/\\nvar StorageVectorsClient = class extends VectorBucketApi {\\n\\t/**\\n\\t* @alpha\\n\\t*\\n\\t* Creates a StorageVectorsClient that can manage buckets, indexes, and vectors.\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param url - Base URL of the Storage Vectors REST API.\\n\\t* @param options.headers - Optional headers (for example `Authorization`) applied to every request.\\n\\t* @param options.fetch - Optional custom `fetch` implementation for non-browser runtimes.\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const client = new StorageVectorsClient(url, options)\\n\\t* ```\\n\\t*/\\n\\tconstructor(url, options = {}) {\\n\\t\\tsuper(url, options.headers || {}, options.fetch);\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Access operations for a specific vector bucket\\n\\t* Returns a scoped client for index and vector operations within the bucket\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param vectorBucketName - Name of the vector bucket\\n\\t* @returns Bucket-scoped client with index and vector operations\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const bucket = supabase.storage.vectors.from('embeddings-prod')\\n\\t* ```\\n\\t*/\\n\\tfrom(vectorBucketName) {\\n\\t\\treturn new VectorBucketScope(this.url, this.headers, vectorBucketName, this.fetch);\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Creates a new vector bucket\\n\\t* Vector buckets are containers for vector indexes and their data\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param vectorBucketName - Unique name for the vector bucket\\n\\t* @returns Promise with empty response on success or error\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .vectors\\n\\t*   .createBucket('embeddings-prod')\\n\\t* ```\\n\\t*/\\n\\tasync createBucket(vectorBucketName) {\\n\\t\\tvar _superprop_getCreateBucket = () => super.createBucket, _this = this;\\n\\t\\treturn _superprop_getCreateBucket().call(_this, vectorBucketName);\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Retrieves metadata for a specific vector bucket\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param vectorBucketName - Name of the vector bucket\\n\\t* @returns Promise with bucket metadata or error\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .vectors\\n\\t*   .getBucket('embeddings-prod')\\n\\t*\\n\\t* console.log('Bucket created:', data?.vectorBucket.creationTime)\\n\\t* ```\\n\\t*/\\n\\tasync getBucket(vectorBucketName) {\\n\\t\\tvar _superprop_getGetBucket = () => super.getBucket, _this2 = this;\\n\\t\\treturn _superprop_getGetBucket().call(_this2, vectorBucketName);\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Lists all vector buckets with optional filtering and pagination\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param options - Optional filters (prefix, maxResults, nextToken)\\n\\t* @returns Promise with list of buckets or error\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .vectors\\n\\t*   .listBuckets({ prefix: 'embeddings-' })\\n\\t*\\n\\t* data?.vectorBuckets.forEach(bucket => {\\n\\t*   console.log(bucket.vectorBucketName)\\n\\t* })\\n\\t* ```\\n\\t*/\\n\\tasync listBuckets(options = {}) {\\n\\t\\tvar _superprop_getListBuckets = () => super.listBuckets, _this3 = this;\\n\\t\\treturn _superprop_getListBuckets().call(_this3, options);\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Deletes a vector bucket (bucket must be empty)\\n\\t* All indexes must be deleted before deleting the bucket\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param vectorBucketName - Name of the vector bucket to delete\\n\\t* @returns Promise with empty response on success or error\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const { data, error } = await supabase\\n\\t*   .storage\\n\\t*   .vectors\\n\\t*   .deleteBucket('embeddings-old')\\n\\t* ```\\n\\t*/\\n\\tasync deleteBucket(vectorBucketName) {\\n\\t\\tvar _superprop_getDeleteBucket = () => super.deleteBucket, _this4 = this;\\n\\t\\treturn _superprop_getDeleteBucket().call(_this4, vectorBucketName);\\n\\t}\\n};\\n/**\\n*\\n* @alpha\\n*\\n* Scoped client for operations within a specific vector bucket\\n* Provides index management and access to vector operations\\n*\\n* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n*/\\nvar VectorBucketScope = class extends VectorIndexApi {\\n\\t/**\\n\\t* @alpha\\n\\t*\\n\\t* Creates a helper that automatically scopes all index operations to the provided bucket.\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @example\\n\\t* ```typescript\\n\\t* const bucket = supabase.storage.vectors.from('embeddings-prod')\\n\\t* ```\\n\\t*/\\n\\tconstructor(url, headers, vectorBucketName, fetch$1) {\\n\\t\\tsuper(url, headers, fetch$1);\\n\\t\\tthis.vectorBucketName = vectorBucketName;\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Creates a new vector index in this bucket\\n\\t* Convenience method that automatically includes the bucket name\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param options - Index configuration (vectorBucketName is automatically set)\\n\\t* @returns Promise with empty response on success or error\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const bucket = supabase.storage.vectors.from('embeddings-prod')\\n\\t* await bucket.createIndex({\\n\\t*   indexName: 'documents-openai',\\n\\t*   dataType: 'float32',\\n\\t*   dimension: 1536,\\n\\t*   distanceMetric: 'cosine',\\n\\t*   metadataConfiguration: {\\n\\t*     nonFilterableMetadataKeys: ['raw_text']\\n\\t*   }\\n\\t* })\\n\\t* ```\\n\\t*/\\n\\tasync createIndex(options) {\\n\\t\\tvar _superprop_getCreateIndex = () => super.createIndex, _this5 = this;\\n\\t\\treturn _superprop_getCreateIndex().call(_this5, _objectSpread2(_objectSpread2({}, options), {}, { vectorBucketName: _this5.vectorBucketName }));\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Lists indexes in this bucket\\n\\t* Convenience method that automatically includes the bucket name\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param options - Listing options (vectorBucketName is automatically set)\\n\\t* @returns Promise with response containing indexes array and pagination token or error\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const bucket = supabase.storage.vectors.from('embeddings-prod')\\n\\t* const { data } = await bucket.listIndexes({ prefix: 'documents-' })\\n\\t* ```\\n\\t*/\\n\\tasync listIndexes(options = {}) {\\n\\t\\tvar _superprop_getListIndexes = () => super.listIndexes, _this6 = this;\\n\\t\\treturn _superprop_getListIndexes().call(_this6, _objectSpread2(_objectSpread2({}, options), {}, { vectorBucketName: _this6.vectorBucketName }));\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Retrieves metadata for a specific index in this bucket\\n\\t* Convenience method that automatically includes the bucket name\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param indexName - Name of the index to retrieve\\n\\t* @returns Promise with index metadata or error\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const bucket = supabase.storage.vectors.from('embeddings-prod')\\n\\t* const { data } = await bucket.getIndex('documents-openai')\\n\\t* console.log('Dimension:', data?.index.dimension)\\n\\t* ```\\n\\t*/\\n\\tasync getIndex(indexName) {\\n\\t\\tvar _superprop_getGetIndex = () => super.getIndex, _this7 = this;\\n\\t\\treturn _superprop_getGetIndex().call(_this7, _this7.vectorBucketName, indexName);\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Deletes an index from this bucket\\n\\t* Convenience method that automatically includes the bucket name\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param indexName - Name of the index to delete\\n\\t* @returns Promise with empty response on success or error\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const bucket = supabase.storage.vectors.from('embeddings-prod')\\n\\t* await bucket.deleteIndex('old-index')\\n\\t* ```\\n\\t*/\\n\\tasync deleteIndex(indexName) {\\n\\t\\tvar _superprop_getDeleteIndex = () => super.deleteIndex, _this8 = this;\\n\\t\\treturn _superprop_getDeleteIndex().call(_this8, _this8.vectorBucketName, indexName);\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Access operations for a specific index within this bucket\\n\\t* Returns a scoped client for vector data operations\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param indexName - Name of the index\\n\\t* @returns Index-scoped client with vector data operations\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\\n\\t*\\n\\t* // Insert vectors\\n\\t* await index.putVectors({\\n\\t*   vectors: [\\n\\t*     { key: 'doc-1', data: { float32: [...] }, metadata: { title: 'Intro' } }\\n\\t*   ]\\n\\t* })\\n\\t*\\n\\t* // Query similar vectors\\n\\t* const { data } = await index.queryVectors({\\n\\t*   queryVector: { float32: [...] },\\n\\t*   topK: 5\\n\\t* })\\n\\t* ```\\n\\t*/\\n\\tindex(indexName) {\\n\\t\\treturn new VectorIndexScope(this.url, this.headers, this.vectorBucketName, indexName, this.fetch);\\n\\t}\\n};\\n/**\\n*\\n* @alpha\\n*\\n* Scoped client for operations within a specific vector index\\n* Provides vector data operations (put, get, list, query, delete)\\n*\\n* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n*/\\nvar VectorIndexScope = class extends VectorDataApi {\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Creates a helper that automatically scopes all vector operations to the provided bucket/index names.\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @example\\n\\t* ```typescript\\n\\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\\n\\t* ```\\n\\t*/\\n\\tconstructor(url, headers, vectorBucketName, indexName, fetch$1) {\\n\\t\\tsuper(url, headers, fetch$1);\\n\\t\\tthis.vectorBucketName = vectorBucketName;\\n\\t\\tthis.indexName = indexName;\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Inserts or updates vectors in this index\\n\\t* Convenience method that automatically includes bucket and index names\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param options - Vector insertion options (bucket and index names automatically set)\\n\\t* @returns Promise with empty response on success or error\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\\n\\t* await index.putVectors({\\n\\t*   vectors: [\\n\\t*     {\\n\\t*       key: 'doc-1',\\n\\t*       data: { float32: [0.1, 0.2, ...] },\\n\\t*       metadata: { title: 'Introduction', page: 1 }\\n\\t*     }\\n\\t*   ]\\n\\t* })\\n\\t* ```\\n\\t*/\\n\\tasync putVectors(options) {\\n\\t\\tvar _superprop_getPutVectors = () => super.putVectors, _this9 = this;\\n\\t\\treturn _superprop_getPutVectors().call(_this9, _objectSpread2(_objectSpread2({}, options), {}, {\\n\\t\\t\\tvectorBucketName: _this9.vectorBucketName,\\n\\t\\t\\tindexName: _this9.indexName\\n\\t\\t}));\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Retrieves vectors by keys from this index\\n\\t* Convenience method that automatically includes bucket and index names\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param options - Vector retrieval options (bucket and index names automatically set)\\n\\t* @returns Promise with response containing vectors array or error\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\\n\\t* const { data } = await index.getVectors({\\n\\t*   keys: ['doc-1', 'doc-2'],\\n\\t*   returnMetadata: true\\n\\t* })\\n\\t* ```\\n\\t*/\\n\\tasync getVectors(options) {\\n\\t\\tvar _superprop_getGetVectors = () => super.getVectors, _this10 = this;\\n\\t\\treturn _superprop_getGetVectors().call(_this10, _objectSpread2(_objectSpread2({}, options), {}, {\\n\\t\\t\\tvectorBucketName: _this10.vectorBucketName,\\n\\t\\t\\tindexName: _this10.indexName\\n\\t\\t}));\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Lists vectors in this index with pagination\\n\\t* Convenience method that automatically includes bucket and index names\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param options - Listing options (bucket and index names automatically set)\\n\\t* @returns Promise with response containing vectors array and pagination token or error\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\\n\\t* const { data } = await index.listVectors({\\n\\t*   maxResults: 500,\\n\\t*   returnMetadata: true\\n\\t* })\\n\\t* ```\\n\\t*/\\n\\tasync listVectors(options = {}) {\\n\\t\\tvar _superprop_getListVectors = () => super.listVectors, _this11 = this;\\n\\t\\treturn _superprop_getListVectors().call(_this11, _objectSpread2(_objectSpread2({}, options), {}, {\\n\\t\\t\\tvectorBucketName: _this11.vectorBucketName,\\n\\t\\t\\tindexName: _this11.indexName\\n\\t\\t}));\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Queries for similar vectors in this index\\n\\t* Convenience method that automatically includes bucket and index names\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param options - Query options (bucket and index names automatically set)\\n\\t* @returns Promise with response containing matches array of similar vectors ordered by distance or error\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\\n\\t* const { data } = await index.queryVectors({\\n\\t*   queryVector: { float32: [0.1, 0.2, ...] },\\n\\t*   topK: 5,\\n\\t*   filter: { category: 'technical' },\\n\\t*   returnDistance: true,\\n\\t*   returnMetadata: true\\n\\t* })\\n\\t* ```\\n\\t*/\\n\\tasync queryVectors(options) {\\n\\t\\tvar _superprop_getQueryVectors = () => super.queryVectors, _this12 = this;\\n\\t\\treturn _superprop_getQueryVectors().call(_this12, _objectSpread2(_objectSpread2({}, options), {}, {\\n\\t\\t\\tvectorBucketName: _this12.vectorBucketName,\\n\\t\\t\\tindexName: _this12.indexName\\n\\t\\t}));\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Deletes vectors by keys from this index\\n\\t* Convenience method that automatically includes bucket and index names\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @param options - Deletion options (bucket and index names automatically set)\\n\\t* @returns Promise with empty response on success or error\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\\n\\t* await index.deleteVectors({\\n\\t*   keys: ['doc-1', 'doc-2', 'doc-3']\\n\\t* })\\n\\t* ```\\n\\t*/\\n\\tasync deleteVectors(options) {\\n\\t\\tvar _superprop_getDeleteVectors = () => super.deleteVectors, _this13 = this;\\n\\t\\treturn _superprop_getDeleteVectors().call(_this13, _objectSpread2(_objectSpread2({}, options), {}, {\\n\\t\\t\\tvectorBucketName: _this13.vectorBucketName,\\n\\t\\t\\tindexName: _this13.indexName\\n\\t\\t}));\\n\\t}\\n};\\n\\n//#endregion\\n//#region src/StorageClient.ts\\nvar StorageClient = class extends StorageBucketApi {\\n\\t/**\\n\\t* Creates a client for Storage buckets, files, analytics, and vectors.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @example\\n\\t* ```ts\\n\\t* import { StorageClient } from '@supabase/storage-js'\\n\\t*\\n\\t* const storage = new StorageClient('https://xyzcompany.supabase.co/storage/v1', {\\n\\t*   apikey: 'public-anon-key',\\n\\t* })\\n\\t* const avatars = storage.from('avatars')\\n\\t* ```\\n\\t*/\\n\\tconstructor(url, headers = {}, fetch$1, opts) {\\n\\t\\tsuper(url, headers, fetch$1, opts);\\n\\t}\\n\\t/**\\n\\t* Perform file operation in a bucket.\\n\\t*\\n\\t* @category File Buckets\\n\\t* @param id The bucket id to operate on.\\n\\t*\\n\\t* @example\\n\\t* ```typescript\\n\\t* const avatars = supabase.storage.from('avatars')\\n\\t* ```\\n\\t*/\\n\\tfrom(id) {\\n\\t\\treturn new StorageFileApi(this.url, this.headers, id, this.fetch);\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Access vector storage operations.\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Vector Buckets\\n\\t* @returns A StorageVectorsClient instance configured with the current storage settings.\\n\\t*/\\n\\tget vectors() {\\n\\t\\treturn new StorageVectorsClient(this.url + \\\"/vector\\\", {\\n\\t\\t\\theaders: this.headers,\\n\\t\\t\\tfetch: this.fetch\\n\\t\\t});\\n\\t}\\n\\t/**\\n\\t*\\n\\t* @alpha\\n\\t*\\n\\t* Access analytics storage operations using Iceberg tables.\\n\\t*\\n\\t* **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\\n\\t*\\n\\t* @category Analytics Buckets\\n\\t* @returns A StorageAnalyticsClient instance configured with the current storage settings.\\n\\t*/\\n\\tget analytics() {\\n\\t\\treturn new StorageAnalyticsClient(this.url + \\\"/iceberg\\\", this.headers, this.fetch);\\n\\t}\\n};\\n\\n//#endregion\\nexports.StorageAnalyticsClient = StorageAnalyticsClient;\\nexports.StorageApiError = StorageApiError;\\nexports.StorageClient = StorageClient;\\nexports.StorageError = StorageError;\\nexports.StorageUnknownError = StorageUnknownError;\\nexports.StorageVectorsApiError = StorageVectorsApiError;\\nexports.StorageVectorsClient = StorageVectorsClient;\\nexports.StorageVectorsError = StorageVectorsError;\\nexports.StorageVectorsErrorCode = StorageVectorsErrorCode;\\nexports.StorageVectorsUnknownError = StorageVectorsUnknownError;\\nexports.VectorBucketApi = VectorBucketApi;\\nexports.VectorBucketScope = VectorBucketScope;\\nexports.VectorDataApi = VectorDataApi;\\nexports.VectorIndexApi = VectorIndexApi;\\nexports.VectorIndexScope = VectorIndexScope;\\nexports.isStorageError = isStorageError;\\nexports.isStorageVectorsError = isStorageVectorsError;\\n//# sourceMappingURL=index.cjs.map\\n};\"],\n\"names\":[\"shadow$provide\",\"require\",\"module\",\"exports\",\"isStorageError\",\"error\",\"_typeof\",\"o\",\"Symbol\",\"iterator\",\"o$1\",\"constructor\",\"prototype\",\"ownKeys\",\"e\",\"r\",\"t\",\"Object\",\"keys\",\"getOwnPropertySymbols\",\"filter\",\"r$1\",\"getOwnPropertyDescriptor\",\"enumerable\",\"push\",\"apply\",\"_objectSpread2\",\"arguments\",\"length\",\"forEach\",\"toPrimitive\",\"i\",\"call\",\"TypeError\",\"String\",\"defineProperty\",\"value\",\"configurable\",\"writable\",\"getOwnPropertyDescriptors\",\"defineProperties\",\"_handleRequest\",\"fetcher\",\"method\",\"url\",\"options\",\"parameters\",\"body\",\"namespace\",\"Promise\",\"resolve\",\"reject\",\"_getRequestParams\",\"then\",\"result\",\"ok\",\"noResolveJson\",\"contentType\",\"headers\",\"get\",\"status\",\"includes\",\"json\",\"data\",\"catch\",\"handleError\",\"createFetchApi\",\"post\",\"put\",\"head\",\"remove\",\"Buffer\",\"iceberg_js\",\"StorageError\",\"Error\",\"message\",\"statusCode\",\"__isStorageError\",\"name\",\"StorageApiError\",\"toJSON\",\"StorageUnknownError\",\"originalError\",\"StorageVectorsError\",\"StorageVectorsApiError\",\"StorageVectorsUnknownError\",\"StorageVectorsErrorCode\",\"StorageVectorsErrorCode$1\",\"resolveFetch\",\"customFetch\",\"args\",\"fetch\",\"recursiveToCamel\",\"item\",\"Array\",\"isArray\",\"map\",\"el\",\"entries\",\"key\",\"newKey\",\"replace\",\"c\",\"toUpperCase\",\"isValidBucketName\",\"bucketName\",\"trim\",\"test\",\"_getErrorMessage\",\"err\",\"_err$error\",\"msg\",\"error_description\",\"JSON\",\"stringify\",\"code\",\"statusText\",\"params\",\"getPrototypeOf\",\"toStringTag\",\"duplex\",\"defaultApi\",\"vectorsApi\",\"BaseApiClient\",\"fetch$1\",\"shouldThrowOnError\",\"throwOnError\",\"setHeader\",\"handleOperation\",\"operation\",\"_this\",\"StreamDownloadBuilder\",\"downloadFn\",\"onfulfilled\",\"onrejected\",\"execute\",\"_Symbol$toStringTag\",\"BlobDownloadBuilder\",\"promise\",\"asStream\",\"getPromise\",\"finally\",\"onfinally\",\"blob\",\"DEFAULT_SEARCH_OPTIONS\",\"limit\",\"offset\",\"sortBy\",\"column\",\"order\",\"DEFAULT_FILE_OPTIONS\",\"cacheControl\",\"upsert\",\"StorageFileApi\",\"bucketId\",\"uploadOrUpdate\",\"path\",\"fileBody\",\"fileOptions\",\"metadata\",\"Blob\",\"FormData\",\"append\",\"encodeMetadata\",\"has\",\"toBase64\",\"ReadableStream\",\"pipe\",\"cleanPath\",\"_removeEmptyFolders\",\"_path\",\"_getFinalPath\",\"id\",\"Id\",\"fullPath\",\"Key\",\"upload\",\"uploadToSignedUrl\",\"token\",\"_this3\",\"URL\",\"searchParams\",\"set\",\"toString\",\"createSignedUploadUrl\",\"_this4\",\"signedUrl\",\"update\",\"move\",\"fromPath\",\"toPath\",\"_this6\",\"sourceKey\",\"destinationKey\",\"destinationBucket\",\"copy\",\"_this7\",\"createSignedUrl\",\"expiresIn\",\"_this8\",\"transform\",\"encodeURI\",\"signedURL\",\"downloadQueryParam\",\"download\",\"createSignedUrls\",\"paths\",\"_this9\",\"datum\",\"renderPath\",\"queryString\",\"transformationQuery\",\"transformOptsToQueryString\",\"info\",\"_this10\",\"exists\",\"_this11\",\"getPublicUrl\",\"_queryString\",\"join\",\"publicUrl\",\"_this12\",\"prefixes\",\"list\",\"_this13\",\"prefix\",\"listV2\",\"_this14\",\"from\",\"btoa\",\"width\",\"height\",\"resize\",\"format\",\"quality\",\"DEFAULT_HEADERS\",\"StorageBucketApi\",\"opts\",\"baseUrl\",\"useNewHostname\",\"hostname\",\"finalUrl\",\"href\",\"finalHeaders\",\"listBuckets\",\"listBucketOptionsToQueryString\",\"getBucket\",\"_this2\",\"createBucket\",\"public\",\"type\",\"file_size_limit\",\"fileSizeLimit\",\"allowed_mime_types\",\"allowedMimeTypes\",\"updateBucket\",\"emptyBucket\",\"_this5\",\"deleteBucket\",\"search\",\"sortColumn\",\"sortOrder\",\"URLSearchParams\",\"StorageAnalyticsClient\",\"queryParams\",\"catalog\",\"IcebergRestCatalog\",\"catalogName\",\"auth\",\"getHeaders\",\"Proxy\",\"target\",\"prop\",\"VectorIndexApi\",\"createIndex\",\"getIndex\",\"vectorBucketName\",\"indexName\",\"listIndexes\",\"deleteIndex\",\"VectorDataApi\",\"putVectors\",\"vectors\",\"getVectors\",\"listVectors\",\"segmentCount\",\"segmentIndex\",\"queryVectors\",\"deleteVectors\",\"VectorBucketApi\",\"StorageVectorsClient\",\"VectorBucketScope\",\"_superprop_getCreateBucket\",\"_superprop_getGetBucket\",\"_superprop_getListBuckets\",\"_superprop_getDeleteBucket\",\"_superprop_getCreateIndex\",\"_superprop_getListIndexes\",\"_superprop_getGetIndex\",\"_superprop_getDeleteIndex\",\"index\",\"VectorIndexScope\",\"_superprop_getPutVectors\",\"_superprop_getGetVectors\",\"_superprop_getListVectors\",\"_superprop_getQueryVectors\",\"_superprop_getDeleteVectors\",\"StorageClient\",\"isStorageVectorsError\"]\n}\n"]